{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee4fe6380cfa41059592d100e6783c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55571416c7fe4a7f82a422091f2671ef",
              "IPY_MODEL_2303087e5ffe479ba7c4017376031399",
              "IPY_MODEL_dcffa29d8f7743ea9d3365fc7e1aef33"
            ],
            "layout": "IPY_MODEL_be3f3af9277e413b8014b23f1fe756c3"
          }
        },
        "55571416c7fe4a7f82a422091f2671ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ade185587bc041bb90bbdbe8cc18eefc",
            "placeholder": "​",
            "style": "IPY_MODEL_d99a6c81a10b4660b80e95a93ad54d13",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2303087e5ffe479ba7c4017376031399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d04c0a314545a5b9b7e15b7e9d9d85",
            "max": 289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58eb71a52ba8413686b851b12f02598d",
            "value": 289
          }
        },
        "dcffa29d8f7743ea9d3365fc7e1aef33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f0f9b3d3654d1d9ab0917fc3be3184",
            "placeholder": "​",
            "style": "IPY_MODEL_8d4756de0bb3437593ef801741a9bfcb",
            "value": " 289/289 [00:00&lt;00:00, 25.9kB/s]"
          }
        },
        "be3f3af9277e413b8014b23f1fe756c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade185587bc041bb90bbdbe8cc18eefc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99a6c81a10b4660b80e95a93ad54d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9d04c0a314545a5b9b7e15b7e9d9d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58eb71a52ba8413686b851b12f02598d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30f0f9b3d3654d1d9ab0917fc3be3184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d4756de0bb3437593ef801741a9bfcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d74c869fe5b4cf3baf78458b85f2e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74dcaa10659740a7adde0fb8861f79c3",
              "IPY_MODEL_3fe0dba858864ca5a6ed892f99bdf6d7",
              "IPY_MODEL_4b556dd8d77a4265a8080a15ec2ff8d8"
            ],
            "layout": "IPY_MODEL_d3c669076e3942fe80479d6fbfa94a8a"
          }
        },
        "74dcaa10659740a7adde0fb8861f79c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e5eeb56e8b4f2e9ab44d98e7cb06fb",
            "placeholder": "​",
            "style": "IPY_MODEL_5708970ac9ff40b8a52faec62895bf38",
            "value": "vocab.txt: "
          }
        },
        "3fe0dba858864ca5a6ed892f99bdf6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cccba80de7df4a90b95e5fdfe9e2f39e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0784562e2db0415fb8776df72abe138c",
            "value": 1
          }
        },
        "4b556dd8d77a4265a8080a15ec2ff8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98908a2ba0cb49a8a22dc6cca22d95e0",
            "placeholder": "​",
            "style": "IPY_MODEL_a01f83769fe74ae1819568a5c58ade35",
            "value": " 248k/? [00:00&lt;00:00, 14.8MB/s]"
          }
        },
        "d3c669076e3942fe80479d6fbfa94a8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e5eeb56e8b4f2e9ab44d98e7cb06fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5708970ac9ff40b8a52faec62895bf38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cccba80de7df4a90b95e5fdfe9e2f39e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0784562e2db0415fb8776df72abe138c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98908a2ba0cb49a8a22dc6cca22d95e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01f83769fe74ae1819568a5c58ade35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c97c51f7b1d6492598b518c24681f274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c9c4a1dfe434e638af23b1c0e406e1c",
              "IPY_MODEL_cf9b7f6d92ab4f62a65b2eeb678f1b61",
              "IPY_MODEL_6a84c39e40b84e7786740936633f5563"
            ],
            "layout": "IPY_MODEL_b011cd3926f9406e9f108cadc6aac2c0"
          }
        },
        "7c9c4a1dfe434e638af23b1c0e406e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e211af258c48ab8d7e9ee6c58087ab",
            "placeholder": "​",
            "style": "IPY_MODEL_61cd3459661e4dce8d032313a47380f5",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "cf9b7f6d92ab4f62a65b2eeb678f1b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d239bf3b51e47db8a690c24667f71a4",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_460d793e7c42474583e889c37ac373c8",
            "value": 125
          }
        },
        "6a84c39e40b84e7786740936633f5563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15c17dbcd64f42c2a702b00c78bc4a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_41462de28de84155b57da69d220c194e",
            "value": " 125/125 [00:00&lt;00:00, 10.5kB/s]"
          }
        },
        "b011cd3926f9406e9f108cadc6aac2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e211af258c48ab8d7e9ee6c58087ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61cd3459661e4dce8d032313a47380f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d239bf3b51e47db8a690c24667f71a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460d793e7c42474583e889c37ac373c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15c17dbcd64f42c2a702b00c78bc4a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41462de28de84155b57da69d220c194e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0a8426cc21744f39720f94fe0a68cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11fcdad624d847ae8d3cc3a0667e8f76",
              "IPY_MODEL_ee157d87d33542ad88b8b9d1c5a6af27",
              "IPY_MODEL_c017109fe0f64929b977d0df30bdc739"
            ],
            "layout": "IPY_MODEL_41a646b6038b460f8b8708232719e555"
          }
        },
        "11fcdad624d847ae8d3cc3a0667e8f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb5e094a7f6c4dac90db036655e15438",
            "placeholder": "​",
            "style": "IPY_MODEL_9f8ac7fab5404a00a5773e8cf558d534",
            "value": "tokenizer.json: "
          }
        },
        "ee157d87d33542ad88b8b9d1c5a6af27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaec9c8ab45c48329a2ab96b2c92dea3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93c785ad4a87419ab2aaa0efced25351",
            "value": 1
          }
        },
        "c017109fe0f64929b977d0df30bdc739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba6d22db716b4c88823ce68e9121df31",
            "placeholder": "​",
            "style": "IPY_MODEL_d92ca7deec164792bd47d4ea30b8e863",
            "value": " 495k/? [00:00&lt;00:00, 26.1MB/s]"
          }
        },
        "41a646b6038b460f8b8708232719e555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb5e094a7f6c4dac90db036655e15438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8ac7fab5404a00a5773e8cf558d534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaec9c8ab45c48329a2ab96b2c92dea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "93c785ad4a87419ab2aaa0efced25351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba6d22db716b4c88823ce68e9121df31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92ca7deec164792bd47d4ea30b8e863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a34720f2e49c453681ce744acbfc35ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c66a487a41a4c909f3ef040fab204c7",
              "IPY_MODEL_4b7b9c5100c7480d887be4f66a9968e0",
              "IPY_MODEL_091cc89b25c742a6b249367ae8e3fdbf"
            ],
            "layout": "IPY_MODEL_4b5db9c417a24432ab94fb69538f3b29"
          }
        },
        "5c66a487a41a4c909f3ef040fab204c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d81ba0f6edd4cf1b875aafa960b2b8d",
            "placeholder": "​",
            "style": "IPY_MODEL_e0dde19dcea5441d8f96a292a143b7c3",
            "value": "config.json: 100%"
          }
        },
        "4b7b9c5100c7480d887be4f66a9968e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8794e4a42a3844f099a2c13acaa431a1",
            "max": 425,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4245ded8bf864cf994ade7f527494563",
            "value": 425
          }
        },
        "091cc89b25c742a6b249367ae8e3fdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a21899a6f843da89a9f487faf11fe8",
            "placeholder": "​",
            "style": "IPY_MODEL_c1deb2b6d25541c5a53c82ffaa17a1a3",
            "value": " 425/425 [00:00&lt;00:00, 46.1kB/s]"
          }
        },
        "4b5db9c417a24432ab94fb69538f3b29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d81ba0f6edd4cf1b875aafa960b2b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0dde19dcea5441d8f96a292a143b7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8794e4a42a3844f099a2c13acaa431a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4245ded8bf864cf994ade7f527494563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60a21899a6f843da89a9f487faf11fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1deb2b6d25541c5a53c82ffaa17a1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a3b05439da441bebaefa9ece9bd6d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fde1b76c5e564c2abb4aa08a794ed020",
              "IPY_MODEL_22659d65bcfb4dbba347ce5476675887",
              "IPY_MODEL_1b79d6c01d284db68e3a7022b39a6753"
            ],
            "layout": "IPY_MODEL_a89648d3623c4e52983c51c106397a6a"
          }
        },
        "fde1b76c5e564c2abb4aa08a794ed020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8829e5746bd4c5e81b95753db46fcd5",
            "placeholder": "​",
            "style": "IPY_MODEL_3781f03ed5a04e1f9dcd7c679f8253e9",
            "value": "model.safetensors: 100%"
          }
        },
        "22659d65bcfb4dbba347ce5476675887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65fd4c6003664385be901a17d3922ef9",
            "max": 445000316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53200b64d2564e628da04b17629867c7",
            "value": 445000316
          }
        },
        "1b79d6c01d284db68e3a7022b39a6753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47c9da1c4604d2593491f79884811e3",
            "placeholder": "​",
            "style": "IPY_MODEL_52357a4c8a9642be94a0541eefe9c779",
            "value": " 445M/445M [00:04&lt;00:00, 198MB/s]"
          }
        },
        "a89648d3623c4e52983c51c106397a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8829e5746bd4c5e81b95753db46fcd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3781f03ed5a04e1f9dcd7c679f8253e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65fd4c6003664385be901a17d3922ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53200b64d2564e628da04b17629867c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b47c9da1c4604d2593491f79884811e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52357a4c8a9642be94a0541eefe9c779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/Insight-Sogang-Univ/insight-14th/blob/main/advanced/template/session05/assignment_languagemodel.ipynb\" target=\"_parent\">\n",
        "      <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "8BzWQexmpCCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔍 이론 문제"
      ],
      "metadata": {
        "id": "oaPYWHM5Y0Qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. SLM(통계적 언어모델)의 한계에 대해 설명하세요."
      ],
      "metadata": {
        "id": "dafmjcvzoMh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[1번 문제 정답]**\n",
        "\n",
        "SLM의 한계는 가지고 있는 데이터가 부족해서 언어를 정확하게 모델링하지 못하는 문제, 즉 희소 문제를 갖고 있다는 점입니다.\n"
      ],
      "metadata": {
        "id": "YdXgXdCqoQgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. BERT에 대한 설명이 아닌 것은?\n",
        "\n",
        "a) 사전 학습 모델\n",
        "\n",
        "b) 양방향 문맥 이해\n",
        "\n",
        "c) 트랜스포머의 디코더를 쌓아 올린 구조\n",
        "\n",
        "d) 이후 RoBERTa와 ALBERT로 발전"
      ],
      "metadata": {
        "id": "U8cvXUjfoY0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[2번 문제 정답]**\n",
        "\n",
        "***여기에 정답을 써주세요!*** \\\n",
        "[정답] c"
      ],
      "metadata": {
        "id": "MuSdngcrob_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. BERT와 GPT의 학습 방식 차이를 간단히 설명하세요."
      ],
      "metadata": {
        "id": "AavVEOYMoiXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[3번 문제 정답]**\n",
        "\n",
        "***여기에 정답을 써주세요!*** \\\n",
        "[정답]BERT는 양방향 인코더로 문맥을 이해하는 데 최적화된 모델이고, GPT는 디코더 기반으로 다음 단어를 생성하는 데 최적화된 모델이다."
      ],
      "metadata": {
        "id": "fkhYXD6jolM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. LLM이 지닌 한계와 RAG의 필요성에 대해 간단히 서술하세요."
      ],
      "metadata": {
        "id": "F36oD9dOouGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[4번 문제 정답]**\n",
        "\n",
        "***여기에 정답을 써주세요!*** \\\n",
        "[정답] LLM의 가장 큰 한계는 환각이라고 생각합니다. RAG는 관련된 정보를 검색하여 먼저 찾고, 이를 LLM에 같이 넣어 최종 답변을 생성하기에LLM의 한계를 극복할 수 있는 하나의 파이프라인입니다"
      ],
      "metadata": {
        "id": "Ra1jp2PfoxSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. LLM을 경량화한 모델인 sLM을 만들기 위해 사용되는 대표적인 기술 3가지를 적으세요.(단답형)"
      ],
      "metadata": {
        "id": "ci0-WuuQo2pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[5번 문제 정답]**\n",
        "\n",
        "***여기에 정답을 써주세요!*** \\\n",
        "[정답] 가지치기, 양자화, 지식 증류"
      ],
      "metadata": {
        "id": "ZCb-JWJVo5mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✍ 언어 모델 과제"
      ],
      "metadata": {
        "id": "6InYiHirZzVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧮 GPU 사용하기"
      ],
      "metadata": {
        "id": "XFWRcK_cZ9sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "# PyTorch GPU 상태\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"✅ [PyTorch] Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "\n",
        "# TensorFlow GPU 상태\n",
        "print(\"\\n✅ [TensorFlow] GPU Devices:\")\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "YJaw3Bh7aBhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d86409ec-ec72-4d29-bad5-31783ec18019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ [PyTorch] Using device: cpu\n",
            "\n",
            "✅ [TensorFlow] GPU Devices:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsVU927lLs2Z"
      },
      "source": [
        "# 🔍 1. BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMZ40xeWMFIu"
      },
      "source": [
        "**BERT (Bidirectional Encoder Representations from Transformers)**\n",
        "- 문장 분류(스팸 메일 탐지), 질의응답 시스템(챗봇, 검색 엔진), 번역(다국어 지원), 텍스트 요약(뉴스 요약) 등 다양한 NLP 작업에 사용\n",
        "- 문맥을 양방향으로 이해하여 텍스트의 의미를 정밀하게 파악하며, 사전 학습된 모델을 기반으로 빠르게 응용 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inLp1BtKM_e7"
      },
      "source": [
        "### 1-1. 모델과 tokenizer 초기화\n",
        "- tokenizer를 통해 문장을 토큰으로 나누고, 이를 정수 인덱스로 변환하여 모델이 이해할 수 있도록 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395,
          "referenced_widgets": [
            "ee4fe6380cfa41059592d100e6783c2c",
            "55571416c7fe4a7f82a422091f2671ef",
            "2303087e5ffe479ba7c4017376031399",
            "dcffa29d8f7743ea9d3365fc7e1aef33",
            "be3f3af9277e413b8014b23f1fe756c3",
            "ade185587bc041bb90bbdbe8cc18eefc",
            "d99a6c81a10b4660b80e95a93ad54d13",
            "c9d04c0a314545a5b9b7e15b7e9d9d85",
            "58eb71a52ba8413686b851b12f02598d",
            "30f0f9b3d3654d1d9ab0917fc3be3184",
            "8d4756de0bb3437593ef801741a9bfcb",
            "3d74c869fe5b4cf3baf78458b85f2e5a",
            "74dcaa10659740a7adde0fb8861f79c3",
            "3fe0dba858864ca5a6ed892f99bdf6d7",
            "4b556dd8d77a4265a8080a15ec2ff8d8",
            "d3c669076e3942fe80479d6fbfa94a8a",
            "95e5eeb56e8b4f2e9ab44d98e7cb06fb",
            "5708970ac9ff40b8a52faec62895bf38",
            "cccba80de7df4a90b95e5fdfe9e2f39e",
            "0784562e2db0415fb8776df72abe138c",
            "98908a2ba0cb49a8a22dc6cca22d95e0",
            "a01f83769fe74ae1819568a5c58ade35",
            "c97c51f7b1d6492598b518c24681f274",
            "7c9c4a1dfe434e638af23b1c0e406e1c",
            "cf9b7f6d92ab4f62a65b2eeb678f1b61",
            "6a84c39e40b84e7786740936633f5563",
            "b011cd3926f9406e9f108cadc6aac2c0",
            "42e211af258c48ab8d7e9ee6c58087ab",
            "61cd3459661e4dce8d032313a47380f5",
            "0d239bf3b51e47db8a690c24667f71a4",
            "460d793e7c42474583e889c37ac373c8",
            "15c17dbcd64f42c2a702b00c78bc4a5d",
            "41462de28de84155b57da69d220c194e",
            "b0a8426cc21744f39720f94fe0a68cef",
            "11fcdad624d847ae8d3cc3a0667e8f76",
            "ee157d87d33542ad88b8b9d1c5a6af27",
            "c017109fe0f64929b977d0df30bdc739",
            "41a646b6038b460f8b8708232719e555",
            "eb5e094a7f6c4dac90db036655e15438",
            "9f8ac7fab5404a00a5773e8cf558d534",
            "eaec9c8ab45c48329a2ab96b2c92dea3",
            "93c785ad4a87419ab2aaa0efced25351",
            "ba6d22db716b4c88823ce68e9121df31",
            "d92ca7deec164792bd47d4ea30b8e863",
            "a34720f2e49c453681ce744acbfc35ae",
            "5c66a487a41a4c909f3ef040fab204c7",
            "4b7b9c5100c7480d887be4f66a9968e0",
            "091cc89b25c742a6b249367ae8e3fdbf",
            "4b5db9c417a24432ab94fb69538f3b29",
            "8d81ba0f6edd4cf1b875aafa960b2b8d",
            "e0dde19dcea5441d8f96a292a143b7c3",
            "8794e4a42a3844f099a2c13acaa431a1",
            "4245ded8bf864cf994ade7f527494563",
            "60a21899a6f843da89a9f487faf11fe8",
            "c1deb2b6d25541c5a53c82ffaa17a1a3",
            "2a3b05439da441bebaefa9ece9bd6d4e",
            "fde1b76c5e564c2abb4aa08a794ed020",
            "22659d65bcfb4dbba347ce5476675887",
            "1b79d6c01d284db68e3a7022b39a6753",
            "a89648d3623c4e52983c51c106397a6a",
            "c8829e5746bd4c5e81b95753db46fcd5",
            "3781f03ed5a04e1f9dcd7c679f8253e9",
            "65fd4c6003664385be901a17d3922ef9",
            "53200b64d2564e628da04b17629867c7",
            "b47c9da1c4604d2593491f79884811e3",
            "52357a4c8a9642be94a0541eefe9c779"
          ]
        },
        "id": "r1m1YLY3GNM0",
        "outputId": "96fa0bef-74cb-4650-8ba9-8abda012303d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee4fe6380cfa41059592d100e6783c2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d74c869fe5b4cf3baf78458b85f2e5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c97c51f7b1d6492598b518c24681f274"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0a8426cc21744f39720f94fe0a68cef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a34720f2e49c453681ce744acbfc35ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a3b05439da441bebaefa9ece9bd6d4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# BERT 모델과 tokenizer 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base') # base : 모델크기, (uncased : 소문자 학습)\n",
        "model = BertForMaskedLM.from_pretrained('klue/bert-base') # base : 모델크기, (uncased : 소문자 학습)\n",
        "# tokenizer : raw text를 개별 토큰으로 분리(Wordpiece). 토크나이저 사전에 따라 고유한 정수 인덱스(고정값)를 매핑함.\n",
        "\n",
        "# tokenizer를 통해 생성된 정수 인덱스 : 텍스트를 모델이 읽을 수 있도록 숫자화\n",
        "# Embedding vector : 단어의 의미적, 문맥적 특성을 모델링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ4zRzObNqAd"
      },
      "source": [
        "### 1-2. 입력 텍스트 준비 및 토큰화\n",
        "- [MASK] 토큰을 삽입한 문장을 설정하고, `tokenizer.tokenize()`로 텍스트 토큰화\n",
        "- [MASK]를 활용하여 문맥 속에서 특정 단어를 추론하는 상황을 만들고, 이를 모델이 학습한 패턴과 비교하도록 함\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKUXDaU1GRwy",
        "outputId": "c821d0c6-2da4-49a5-a156-4b93136a0a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '열', '##여', '##덟', ',', '우리', '##는', '서로', '##의', '이름', '##을', '처음', '불렀', '##다', '.', '그리고', '스물', '하나', ',', '우린', '[MASK]', '을', '했', '##다', '.', '[SEP]']\n",
            "[2, 1432, 2173, 3542, 16, 3616, 2259, 4084, 2079, 3934, 2069, 3790, 6895, 2062, 18, 3673, 10514, 3657, 16, 8983, 4, 1498, 1902, 2062, 18, 3]\n"
          ]
        }
      ],
      "source": [
        "# 테스트할 문장\n",
        "text = \"[CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\"\n",
        "\n",
        "# 문장을 토큰으로 변환\n",
        "tokenized_text = tokenizer.tokenize(text) # text(문장)을 토큰으로 변환해 tokenized_text에 저장합시다!\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) # 토큰을 index로 변환하는 코드!\n",
        "\n",
        "print(tokenized_text) # 토큰이 출력됩니다.\n",
        "print(indexed_tokens) # 인덱스가 출력됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nrWA_XEN4I3"
      },
      "source": [
        "### 1-3. MASK된 위치 확인\n",
        "- [MASK] 토큰의 위치를 탐지해 해당 위치에서 모델이 단어를 예측하도록 지정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAOGhKOrKrRC",
        "outputId": "873ba6e4-0a8a-4458-99e5-a593d435b243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ],
      "source": [
        "# 마스킹된 위치 찾기\n",
        "masked_index = tokenized_text.index(\"[MASK]\") # 토큰화된 결과물에서 index 메서드를 통해 [MASK]의 위치를 확인해봅시다!\n",
        "print(masked_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oqIAqDOEo_"
      },
      "source": [
        "### 1-4. 정수화된 토큰 인덱스를 tensor로 변환 후 모델 예측 실행\n",
        "- 모델은 **텐서 데이터 구조**를 필요로 하므로, **입력값을 변환**하여 적합한 형식으로 만듦.\n",
        "   - `torch.tensor(입력값 리스트 또는 입력값 ndarray)`를 통해 tensor 구조로 변환 가능!\n",
        "- **역전파를 비활성화**하고, 모델이 **각 토큰에 대해 가능한 모든 단어 점수 출력**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2T3XriDKuJD",
        "outputId": "cc870ba4-67df-4faa-e715-eabd41700d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ -6.0337,   4.5526,  -5.6312,  ...,  -7.3959,  -7.4220,  -5.8337],\n",
            "         [ -6.1762,   4.7585,  -7.3973,  ...,  -7.6209, -12.2124,  -6.0998],\n",
            "         [ -7.4194,   3.9148,  -6.1517,  ...,  -6.8162,  -9.5421,  -3.0473],\n",
            "         ...,\n",
            "         [ -7.3761,   8.6972,  -5.4904,  ...,  -8.7202,  -9.1403,  -5.8566],\n",
            "         [ -5.6347,  10.3884,  -4.3374,  ...,  -8.6900,  -7.4171,  -3.5043],\n",
            "         [ -5.6652,  10.3407,  -4.4099,  ...,  -8.7521,  -7.4286,  -3.6681]]])\n"
          ]
        }
      ],
      "source": [
        "# 토큰화된 텍스트 -> 정수인덱스(ID) -> Pytorch 텐서\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) # 토큰을 index로 변환하는 코드!\n",
        "tokens_tensor = torch.tensor([indexed_tokens]) # 입력값(토큰 인덱스 리스트)을 tensor 구조로 변환해봅시다!\n",
        "\n",
        "# 모델에 토큰 텐서를 전달하고 예측 실행\n",
        "with torch.no_grad(): # 가중치 업데이트 없으므로 자동미분연산은 끔\n",
        "    outputs = model(tokens_tensor) # 예측. 모델은 각 토큰위치에 대한 예측 결과를 반환.\n",
        "    predictions = outputs[0] # logits (각 토큰위치에서 가능한 모든 토큰들의 원시점수)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIkvkAL5Oalc"
      },
      "source": [
        "### 1-5. MASK된 토큰 예측\n",
        "- [MASK] 위치에서 가장 높은 점수를 받은 토큰의 인덱스를 추출하고, 이를 단어로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO5B91p4KwI0",
        "outputId": "b735913a-f285-4cb1-8eba-f16a6a8491ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: [CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\n",
            "Masked: ['[CLS]', '열', '##여', '##덟', ',', '우리', '##는', '서로', '##의', '이름', '##을', '처음', '불렀', '##다', '.', '그리고', '스물', '하나', ',', '우린', '사랑', '을', '했', '##다', '.', '[SEP]']\n",
            "Predicted token: 사랑\n",
            "\n",
            "Filled sentence: 열여덟 , 우리는 서로의 이름을 처음 불렀다 . 그리고 스물 하나 , 우린 사랑 을 했다 .\n"
          ]
        }
      ],
      "source": [
        "# 예측된 토큰 확인\n",
        "predicted_index = torch.argmax(predictions[0, masked_index]).item() # masked_index에 들어갈 것으로 가장 확률이 높은 인덱스\n",
        "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "\n",
        "# 예측된 토큰으로 마스크 채우기\n",
        "tokenized_text[masked_index] = predicted_token\n",
        "# 토큰화된 텍스트를 다시 문자열로 변환\n",
        "filled_text = tokenizer.convert_tokens_to_string(tokenized_text[1:-1])\n",
        "\n",
        "print(\"Original:\", text)\n",
        "print(\"Masked:\", tokenized_text)\n",
        "print(\"Predicted token:\", predicted_token) ; print()\n",
        "\n",
        "print(\"Filled sentence:\", filled_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ncI4tBOWLh"
      },
      "source": [
        "\n",
        "### 1-6. MASK된 문장 복원\n",
        "- 예측된 토큰으로 [MASK]를 대체하여 완성된 문장 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQJBSmfZK2l2",
        "outputId": "d7df3692-0fc3-46b6-92e1-cbbe1cb9c054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# BERT 모델과 토크나이저 초기화\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
        "model = BertForMaskedLM.from_pretrained('klue/bert-base')\n",
        "\n",
        "def fill_mask(input_text):\n",
        "    # 텍스트를 토큰으로 변환\n",
        "    tokenized_text = tokenizer.tokenize(input_text)\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # 마스킹된 위치 찾기\n",
        "    masked_index = tokenized_text.index(\"[MASK]\") # 토큰화된 텍스트에서 마스킹된 위치를 찾아봅시다!\n",
        "\n",
        "    # 토큰화된 텍스트 -> 정수인덱스(ID) -> Pytorch 텐서\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "    # 모델에 토큰 텐서를 전달하고 예측 수행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens_tensor)\n",
        "        predictions = outputs[0]\n",
        "\n",
        "    # 예측된 토큰 확인\n",
        "    predicted_index = torch.argmax(predictions[0, masked_index]).item() # 위 코드 참고! masked_index에 들어갈 것으로 가장 확률이 높은 인덱스\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "\n",
        "    # 마스크를 채운 문장 반환\n",
        "    tokenized_text[masked_index] = predicted_token # 토큰화된 텍스트의 마스킹된 위치(인덱스 사용)를 예측된 토큰으로 채워봅시다!\n",
        "    return tokenizer.convert_tokens_to_string(tokenized_text[1:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeAYIzyYPVVt"
      },
      "source": [
        "예시 문장 만들어서 MLM을 사용해 보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q81b8zuYK3E9",
        "outputId": "ddcf44b5-75dd-46cf-fa24-81f78e3dced3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled sentence: 오늘은 날씨가 정말 좋아서 우리는 함께 산책 을 했다 .\n"
          ]
        }
      ],
      "source": [
        "# 예시 1: \"[CLS] 열여덟, 우리는 서로의 이름을 처음 불렀다. 그리고 스물 하나, 우린 [MASK]을 했다.[SEP]\"\n",
        "# 예시 2: \"[CLS] 윤해민은 INSGIHT 학회를 정말 사랑한다. 그는 INSIGHT 학회를 위해 [MASK]를 했다.[SEP]\"\n",
        "# 이 예시를 참고해서 [CLS](맨 앞), [MASK](채울 부분), [SEP](맨 뒤)를 추가해서 여러분만의 예시 문장 만들어주세요\n",
        "input_text = \"[CLS] 오늘은 날씨가 정말 좋아서 우리는 함께 [MASK]을 했다.[SEP]\"\n",
        "filled_text = fill_mask(input_text)\n",
        "print(\"Filled sentence:\", filled_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔍 2. GPT, RAG, Langchain"
      ],
      "metadata": {
        "id": "tmCHerNBVflo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-1 라이브러리 설치\n",
        "\n",
        "langchain 관련 라이브러리와, pdf 문서를 읽을수 있는 pypdf 라이브러리를 설치할게요!"
      ],
      "metadata": {
        "id": "BJXM4PpMfBB_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHh7iUqLyHQk",
        "outputId": "c4e649a0-e8ad-4420-c9cb-f3da9e1105a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.9/328.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ⬇️ Colab에서 한 번만 실행\n",
        "%pip install -qU \"langchain>=0.3\" langchain-community langchain-openai langgraph chromadb pypdf tiktoken\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-2. 키값 설정"
      ],
      "metadata": {
        "id": "eWTYIcdbe4VG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-3 pdf 문서 선택 (로드)\n",
        "\n",
        "\n",
        "여러분들이 활용하고 싶은 아무 pdf 문서를 선택해보세요!"
      ],
      "metadata": {
        "id": "hOjJzln6fLaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os, re, unicodedata\n",
        "\n",
        "os.makedirs(\"/content/pdfs\", exist_ok=True)\n",
        "print(\"📥 업로드할 PDF 파일을 선택하세요 (여러 개 가능).\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "name_map = {}\n",
        "for i, (orig_name, data) in enumerate(uploaded.items(), 1):\n",
        "    nf = unicodedata.normalize(\"NFC\", orig_name)\n",
        "    base, ext = os.path.splitext(nf)\n",
        "    # 한글/영문/숫자/밑줄/대시/점만 남기고 나머지는 _\n",
        "    safe_base = re.sub(r\"[^\\w\\u3131-\\u318E\\uAC00-\\uD7A3.\\-]+\", \"_\", base).strip(\"._'‘’“”\")\n",
        "    # 파일명 너무 길면 잘라냄 (최대 ~140자 정도로)\n",
        "    safe_base = safe_base[:120] if len(safe_base) > 120 else safe_base\n",
        "    new_name = f\"doc_{i}_{safe_base}{ext.lower()}\"\n",
        "    with open(os.path.join(\"/content/pdfs\", new_name), \"wb\") as f:\n",
        "        f.write(data)\n",
        "    name_map[new_name] = orig_name\n",
        "\n",
        "print(\"✅ 저장 완료 (Colab 파일명 → 원본명 매핑):\")\n",
        "for k, v in name_map.items():\n",
        "    print(f\"  {k}  <=  {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "FH8xlYI0zEiG",
        "outputId": "01404251-54ab-4c04-fc30-eeeff670d493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 업로드할 PDF 파일을 선택하세요 (여러 개 가능).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-97ec857d-2bac-42b4-a565-f09d8deeaa6d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-97ec857d-2bac-42b4-a565-f09d8deeaa6d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nre2025-13.pdf to nre2025-13.pdf\n",
            "✅ 저장 완료 (Colab 파일명 → 원본명 매핑):\n",
            "  doc_1_nre2025-13.pdf  <=  nre2025-13.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-4 문서 분할 후 벡터 DB에 저장\n",
        "로딩한 문서를 분할 할 때,\n",
        "- chunk_size는 `900`\n",
        "- chunk_overlap은 `150`\n",
        "- separators(구분자)는 `[\"\\n\\n\", \"\\n\", \" \", \"\"]`\n",
        "으로 설정하여 청킹해주세요!"
      ],
      "metadata": {
        "id": "Rt0o0nGvbS8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예전 버전들 싹 지우기\n",
        "!pip uninstall -y langchain langchain-core langchain-community langchain-openai chromadb tiktoken pypdf\n",
        "\n",
        "# 호환되는 최신 버전들 설치 (버전 핀 하지 말고 pip가 알아서 맞추게 둠)\n",
        "!pip install -qU \\\n",
        "  \"langchain>=0.3.0\" \\\n",
        "  langchain-community \\\n",
        "  langchain-openai \\\n",
        "  langchain-text-splitters \\\n",
        "  chromadb \\\n",
        "  tiktoken \\\n",
        "  pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0qdjMD28Qlz",
        "outputId": "ea594495-9409-4d8b-9bfc-5aaefb3b4acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 1.0.7\n",
            "Uninstalling langchain-1.0.7:\n",
            "  Successfully uninstalled langchain-1.0.7\n",
            "Found existing installation: langchain-core 1.0.5\n",
            "Uninstalling langchain-core-1.0.5:\n",
            "  Successfully uninstalled langchain-core-1.0.5\n",
            "Found existing installation: langchain-community 0.4.1\n",
            "Uninstalling langchain-community-0.4.1:\n",
            "  Successfully uninstalled langchain-community-0.4.1\n",
            "Found existing installation: langchain-openai 1.0.3\n",
            "Uninstalling langchain-openai-1.0.3:\n",
            "  Successfully uninstalled langchain-openai-1.0.3\n",
            "Found existing installation: chromadb 1.3.5\n",
            "Uninstalling chromadb-1.3.5:\n",
            "  Successfully uninstalled chromadb-1.3.5\n",
            "Found existing installation: tiktoken 0.12.0\n",
            "Uninstalling tiktoken-0.12.0:\n",
            "  Successfully uninstalled tiktoken-0.12.0\n",
            "Found existing installation: pypdf 6.3.0\n",
            "Uninstalling pypdf-6.3.0:\n",
            "  Successfully uninstalled pypdf-6.3.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import glob\n",
        "\n",
        "# 1) PDF → Documents\n",
        "pdf_paths = sorted(glob.glob(\"/content/pdfs/*.pdf\"))\n",
        "docs = []\n",
        "for p in pdf_paths:\n",
        "    try:\n",
        "        loader = PyPDFLoader(p)\n",
        "        docs.extend(loader.load())\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 로딩 실패: {p} -> {e}\")\n",
        "\n",
        "print(f\"총 문서 조각(페이지 기준): {len(docs)}\")\n",
        "\n",
        "# 2) 문서 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=900,                       # 청크 사이즈\n",
        "    chunk_overlap=150,                   # 청크 오버랩\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # 엔터/공백 기준으로 분할\n",
        ")\n",
        "chunks = text_splitter.split_documents(docs)\n",
        "print(f\"총 청크 수: {len(chunks)}\")\n",
        "\n",
        "# 3) 벡터스토어\n",
        "persist_dir = \"/content/chroma_pdf_db\"\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_dir,\n",
        ")\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
        "print(\"✅ 인덱싱 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfApbza30fU1",
        "outputId": "ac94e495-4021-4cd9-d3bb-3ed18f73107e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 문서 조각(페이지 기준): 73\n",
            "총 청크 수: 114\n",
            "✅ 인덱싱 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-5 RA<U>Generate</U> : 생성 부분 선언\n",
        "\n",
        "PROMPT 부분은 여러분들이 원하시는대로 입력해도 좋습니다!\n",
        "\n",
        "🤥 영어로 입력하면 모델이 더 잘 이해한대요"
      ],
      "metadata": {
        "id": "RF2U8Ddmhyu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "PROMPT = ChatPromptTemplate.from_template(\n",
        "\"\"\"다음 컨텍스트(업로드한 PDF에서 추출됨)만을 바탕으로 질문에 한국어로 답하라.\n",
        "불확실하면 모른다고 말하라. 핵심 근거를 요약하고, 각 근거 옆에 출처(파일/페이지)를 표시하라.\n",
        "\n",
        "[질문]\n",
        "{question}\n",
        "\n",
        "[컨텍스트]\n",
        "{context}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "rag_chain = (PROMPT | llm | StrOutputParser())\n"
      ],
      "metadata": {
        "id": "8qaycjB50fSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-6 RAG 파이프라인 langgraph로 구성\n",
        "\n",
        "벡터db에서 검색하는 것이 <U>Retrieve</U>AG이고,\n",
        "\n",
        "검색 결과를 생성 단계에 던져주는 것이 R<U>Augment</U>G입니다!"
      ],
      "metadata": {
        "id": "ZMP-y_6bjw5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List\n",
        "from langchain_core.documents import Document\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# format_docs의 역할은 문서를 포맷팅해서 모델에게 제공할 'context'를 정리하는 역할입니다!\n",
        "def format_docs(docs):\n",
        "    # 파일명/페이지를 메타데이터에 담아두는 PyPDFLoader 기본값 사용\n",
        "    lines = []\n",
        "    for i, d in enumerate(docs, 1):\n",
        "        src = d.metadata.get(\"source\", \"\")\n",
        "        page = d.metadata.get(\"page\", None)\n",
        "        tag = f\"{os.path.basename(src)}\"\n",
        "        if page is not None:\n",
        "            tag += f\" p.{page+1}\"\n",
        "        lines.append(f\"[{i}] {tag}\\n{d.page_content}\")\n",
        "    return \"\\n\\n\".join(lines)\n",
        "\n",
        "# 그래프 선언\n",
        "class QAState(TypedDict):\n",
        "    question: str\n",
        "    retrieved: List[Document]\n",
        "    answer: str\n",
        "\n",
        "def node_retrieve(state: QAState):\n",
        "    q = state[\"question\"]\n",
        "    topk = retriever.invoke(q)\n",
        "    return {\"retrieved\": topk}\n",
        "\n",
        "def node_generate(state: QAState):\n",
        "    q = state[\"question\"]\n",
        "    ctx = format_docs(state[\"retrieved\"])\n",
        "    ans = rag_chain.invoke({\"question\": q, \"context\": ctx})\n",
        "    return {\"answer\": ans}\n",
        "\n",
        "# --------- 그래프 구성 ---------\n",
        "# 노드끼리 연결하기\n",
        "workflow = StateGraph(QAState)\n",
        "workflow.add_node(\"retrieve\", node_retrieve) # 어떤 노드가 추가되어야 할까요?\n",
        "workflow.add_node(\"generate\", node_retrieve) # 어떤 노드가 추가되어야 할까요?\n",
        "\n",
        "workflow.set_entry_point(\"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"generate\") # 어떤 노드와 어떤 노드가 연결되어야 할까요?\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "app = workflow.compile()\n",
        "print(\"✅ LangGraph 컴파일 완료\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuCAAX4E0fOz",
        "outputId": "6d0d7883-2a2b-42e8-fcbc-e04c61faad46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LangGraph 컴파일 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-7 실제 구동해보기\n",
        "\n",
        "question에 여러분들이 입력하고 싶은 질문을 넣어보세요!\n",
        "\n",
        "RAG 과제는 이렇게 간단하게 끝내겠습니다😁"
      ],
      "metadata": {
        "id": "KNAKcKePchhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"이 논문의 주제가 뭘까.\"\n",
        "\n",
        "final = app.invoke({\n",
        "    \"question\": question,\n",
        "    \"retrieved\": [],\n",
        "    \"answer\": \"\"\n",
        "})\n",
        "\n",
        "print(\"▼ 답변\")\n",
        "print(final[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC-HXC7j0wHs",
        "outputId": "352a2408-afe9-4809-8923-0fe2d068fe01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▼ 답변\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"이 논문을 통해 알 수 있는 것들이 뭐야?.\"\n",
        "\n",
        "final = app.invoke({\n",
        "    \"question\": question,\n",
        "    \"retrieved\": [],\n",
        "    \"answer\": \"\"\n",
        "})\n",
        "\n",
        "print(\"▼ 답변\")\n",
        "print(final[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFIJftFPpXb9",
        "outputId": "80fc5431-48a1-43c5-bf07-18f1005497fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▼ 답변\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔍 3. sLM"
      ],
      "metadata": {
        "id": "bCgJ30gFVuQR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfsDR_omdNea"
      },
      "source": [
        "## 3-1. sLM(Gemma) 로드\n",
        "### sLM(small Language Model)의 대표 모델인 Gemma를 로드 해봅시다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXFZFUJHgTcU"
      },
      "source": [
        "### (1) 사전 준비 사항\n",
        "### 1. HuggingFace 로그인\n",
        "\n",
        "https://huggingface.co/\n",
        "\n",
        "이 링크로 들어가서 HuggingFace에 로그인합니다.(계정이 없다면 회원가입 해주세요!)\n",
        "\n",
        "### 2. 토큰 발급받기\n",
        "\n",
        "https://huggingface.co/settings/tokens\n",
        "\n",
        "- 이 링크로 들어가서 'Create new token'을 클릭\n",
        "- Token type: 'Read'로 해주세요.\n",
        "- Token name: 아무거나 상관 없습니다.\n",
        "- (⭐ 매우 중요!) 토큰 만드시고 **반드시 토큰 문자열 (hf_... 로 시작함)을 복사해주세요!**  \n",
        "한 번만 볼 수 있습니다!\n",
        "\n",
        "### 3. google colab에서 토큰 등록하기\n",
        "- 왼쪽에 열쇠 모양 버튼(보안 비밀)을 눌러주세요.\n",
        "- 이름: colab-gemma\n",
        "- 값: 복사해둔 토큰 문자열(hf_...로 시작함)\n",
        "- 노트북 액세스 : 스위치 키기(파란색)\n",
        "\n",
        "### 4. gemma-2b-it 모델 사용 약관 동의\n",
        "\n",
        "https://huggingface.co/google/gemma-2b-it\n",
        "\n",
        "- (⭐ 매우 중요!) 반드시 2번 단계에서 토큰을 발급받았던 바로 그 Hugging Face 계정으로 로그인된 상태에서 위 링크로 들어가야 합니다.\n",
        "- 링크로 들어가서 'Access Gemma on Hugging Face' 부분의 약관을 읽고 동의 버튼을 클릭해 주세요.\n",
        "- \"You have been granted access to this model\"이라는 메시지가 뜨면 성공입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwjo5_Uucxkw"
      },
      "source": [
        "### (2) 필요한 툴 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_nXPEsF7UWQ",
        "outputId": "59f6f7df-1ca7-4d8a-9289-354dd31ad6f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.48.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U bitsandbytes\n",
        "!pip install --upgrade -q transformers huggingface_hub peft \\\n",
        "  accelerate bitsandbytes datasets trl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00df732f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525332a7-d48d-4554-ca13-4988109e37f7"
      },
      "source": [
        "# HuggingFace에 로그인합니다.\n",
        "\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# 따음표 안에 본인의 보안 비밀 키의 이름을 적습니다.(여기선 colab-gemma)\n",
        "try:\n",
        "    login(token=userdata.get(\"colab-gemma\"))\n",
        "except Exception as e:\n",
        "    print(f\"Error logging in to Hugging Face: {e}\")\n",
        "    print(\"Please make sure you have added your Hugging Face token to Colab secrets with the name 'colab-gemma'\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error logging in to Hugging Face: Secret colab-gemma does not exist.\n",
            "Please make sure you have added your Hugging Face token to Colab secrets with the name 'colab-gemma'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_z4600bwvSq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "outputId": "f0ea238f-095e-49c3-c0e6-da5a7eccedc3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2b-it.\n401 Client Error. (Request ID: Root=1-691da42e-2a5cf057368f993668887d20;b605c994-0e5a-458d-a528-3ad6e4d81a33)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\nAccess to model google/gemma-2b-it is restricted. You must have access to it and be authenticated to access it. Please log in.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-2b-it/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1544\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGatedRepoError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-691da42e-2a5cf057368f993668887d20;b605c994-0e5a-458d-a528-3ad6e4d81a33)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\nAccess to model google/gemma-2b-it is restricted. You must have access to it and be authenticated to access it. Please log in.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1214959574.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 토크나이저를 로드합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 모델을 로드합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m                     config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m   1094\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_gated_repo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;34m\"You are trying to access a gated repo.\\nMake sure to have access to it at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;34mf\"https://huggingface.co/{path_or_repo_id}.\\n{str(e)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2b-it.\n401 Client Error. (Request ID: Root=1-691da42e-2a5cf057368f993668887d20;b605c994-0e5a-458d-a528-3ad6e4d81a33)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\nAccess to model google/gemma-2b-it is restricted. You must have access to it and be authenticated to access it. Please log in."
          ]
        }
      ],
      "source": [
        "# 모델을 로드합니다.\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# 계산 부하를 줄이고 추론 속도를 높이기 위해 '양자화'합니다.\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# sLM(gemma)를 Q&A, 요약 등에 활용하기 위해 '지시 튜닝(Instruction-Tuned) 버전의 모델을 사용합니다.\n",
        "# \"google/gemma-2b-it\" 모델을 사용합니다.\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "\n",
        "# 토크나이저를 로드합니다.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# 모델을 로드합니다.\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config, # 양자화(quantization)\n",
        "    device_map={\"\":\"cuda:0\"} # Changed from \"0\" to \"cuda:0\"\n",
        ")\n",
        "\n",
        "# GPU를 사용하도록 설정합니다.\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlmGvFMg4a2q"
      },
      "source": [
        "## 3-2. sLM 활용\n",
        "- sLM은 LLM을 경량화한 모델이기 때문에 언어 모델의 기능인 질의응답(추론), 요약, 분류(감정분석) 등이 가능합니다.\n",
        "- **속도는 비교적 빠르지만, 성능이 그닥 좋지 않다는 것을 확인하실 수 있습니다.**\n",
        "\n",
        "### Gemma 활용 예시 (Common Use Cases)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 질의응답(Reasoning)\n",
        "\n",
        "#### 원하는 질문을 한 번 넣어보세요!"
      ],
      "metadata": {
        "id": "7VylD-KiV2ow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGU1uuui4a2q",
        "outputId": "503eebe0-a162-4853-cc30-80a644bf9f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 예시 1: 질의응답 (Reasoning) ---\n",
            "**AI가 회계 분야에서 어떻게 활용될 수 있는지**\n",
            "\n",
            "**1. 데이터 분석 및 예측**\n",
            "* AI는 회계 데이터를 분석하고 예측하여 미래 결과를 추측할 수 있습니다.\n",
            "* 예를 들어, 회계 수익과 비용을 예측하고, 회계 성과를 개선하기 위한 전략을 수립할 수 있습니다.\n",
            "\n",
            "**2. 회계 자동화**\n",
            "* AI는 회계 업무를 자동화할 수 있는 도구를 개발할 수 있습니다.\n",
            "* 예를 들어, 데이터 입력, 계정 관리, 보고서 생성 등을 자동화할 수 있습니다.\n",
            "\n",
            "**3. 회계 의사 결정 지원**\n",
            "* AI는 회계 의사 결정에 도움을 줄 수 있는 정보와 분석을 제공할 수 있습니다.\n",
            "* 예를 들어, 회계 성과와 리스크를 평가하고, 투자 및 재무 계획을 수립할 수 있습니다.\n",
            "\n",
            "**4. 회계 솔루션 제공**\n",
            "* AI는 회계 솔루션을 제공하는 데 사용될 수 있습니다.\n",
            "* 예를 들어, 회계 시스템 구축, 데이터\n"
          ]
        }
      ],
      "source": [
        "print(\"--- 예시 1: 질의응답 (Reasoning) ---\")\n",
        "\n",
        "# content : '~~' 따음표 안에 질문을 써주시면 됩니다.\n",
        "# 하고 싶은 질문 아무거나 넣어보세요!\n",
        "\n",
        "# \"role\": \"user\" 입니다.\n",
        "\n",
        "chat = [\n",
        "    # Gemma 모델의 채팅 형식에 맞춰 'role'과 'content'를 지정합니다.\n",
        "    { \"role\": \"user\", \"content\": \"AI가 회계 분야에서 어떻게 활용될 수 있는지 알려줘\" }\n",
        "]\n",
        "\n",
        "# 1. 딕셔너리 리스트('chat')를 Gemma 모델이 이해할 수 있는 공식 프롬프트 문자열로 변환합니다.\n",
        "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "# 2. 변환된 프롬프트 문자열을 모델이 입력받을 수 있는 토큰 ID 텐서로 변환하고, GPU('device')로 보냅니다.\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# 3. 토큰화된 입력을 모델에 전달하여 텍스트 \"\"생성\"\"을 시작합니다 (최대 256개의 새 토큰 생성)\n",
        "# 생성을 위해 'generate' 함수를 사용합니다.\n",
        "outputs = model.generate(**inputs, max_new_tokens=256) # **inputs에서 **는 빈칸이 아닙니다.\n",
        "\n",
        "# 4. 'outputs'에는 '입력'과 '답변'이 모두 포함되어 있습니다.\n",
        "# 따라서 원본 입력 토큰의 길이(입력, 'inputs.input_ids.shape[1]')를 기준으로, 그 이후에 '새로 생성된' 토큰(답변)만 추출합니다.\n",
        "new_tokens = outputs[0][inputs.input_ids.shape[1]:]\n",
        "\n",
        "# 5. 추출된 토큰 ID 리스트를 다시 사람이 읽을 수 있는 문자열로 \"\"디코딩\"\"합니다.\n",
        "# 디코딩을 위해 'decode' 함수를 사용합니다.\n",
        "text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "# 6. 최종 생성된 답변 텍스트를 화면에 출력합니다.\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 요약 (Summarization)\n",
        "\n",
        "#### 원하는 글을 넣어서 요약해 보세요!"
      ],
      "metadata": {
        "id": "5jqUC9Arb6pf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPxJeg244a2q",
        "outputId": "392a0a37-58d6-4ff5-fa65-990b6a145000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 예시 2: 요약 (Summarization) ---\n",
            "1. 최근 석 달 동안 국내 증시 코스피가 1,000p 안팎으로 오를 만큼 강세인데 환율이 급등하는 현상이 나타나고 있습니다.\n",
            "\n",
            "\n",
            "2. 원, 달러 환율의 약세 이유는 환율 상승의 성격과 주가 상승을 이끄는 주체가 다르기 때문으로 해석할 수 있을 것 같고요.\n",
            "\n",
            "\n",
            "3. 한국은 미국 중심의 글로벌 요인보다는 국내 요인보다는 미국 국채 금리가 급등하고안전자산 선호 심리가 더해지면서 달러인덱스도 강세를 보이고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- 예시 2: 요약 (Summarization) ---\")\n",
        "\n",
        "# text_to_summarize = \"\"\"~~~\"\"\" 따음표 안에 요약하고 싶은 글을 넣어주시면 됩니다.\"\"\n",
        "# 요약하고 싶은 글 아무거나 넣어보세요!\n",
        "\n",
        "text_to_summarize = \"\"\"\n",
        "코스피 석 달 동안 1,000p 올랐는데 환율 급등한 이유는?\n",
        "\n",
        "[앵커]\n",
        "최근 석 달 동안 국내 증시 코스피가 1,000p 안팎으로 오를 만큼 강세인데환율이 급등하는 현상이 나타나고 있습니다.원·달러 환율의 약세 이유와 주식 시장 동향을 최재민 해설위원과 함께 짚어보겠습니다. 어서 오십시오. 통상적으로 주식 시장이 괜찮으면 환율은 내려가는 게 정설인데지금은 환율이 급등하고 있거든요. 어떤 이유 때문일까요?\n",
        "\n",
        "[기자]\n",
        "그렇습니다. 주식 시장과 환율은 비슷하게 움직이는 게 통상적인데요. 그런데 최근에는 역설적이고 특이한 현상이 나타난다고 볼 수 있겠습니다. 주요 원인은 환율 상승의 성격과 주가 상승을 이끄는 주체가 다르기 때문으로 해석할 수 있을 것 같고요. 환율이 오르는 건 국내 요인보다는 미국 중심의 글로벌 요인이 더 크게 작용하고 있다고 봐야 될 것 같습니다. 미 연준이 물가 안정을 위해서 현재의 기준금리 인하를 더 늦출 가능성이 크다는 전망이 최근 우세한 상황이고 이 때문에 미국 국채 금리가 급등하고안전자산 선호 심리가 더해지면서 달러인덱스도 강세를 보이고 있습니다.\n",
        "\n",
        "[앵커]\n",
        "달러인덱스 얘기해 주셨는데 금융시장에서 미국 달러화의 가치를 측정하는 게 달러인덱스잖아요. 최근에 얼마나 강세인 건가요?\n",
        "\n",
        "[기자]\n",
        "유로와 엔, 파운드 등 주요 6개국 통화 그러니까 영국 파운드, 캐나다 달러 포함해서 6개 나라 대비 미국 달러화의 평균적인 가치를 측정한 지수가 달러인덱스인데 1973년 3월 기준점 100으로 설정되어 있습니다. 이 수치보다 높으면 달러 가치가 강세, 낮으면 약세를 의미하는 거거든요. 최근 석 달 전에는 98대 정도에서 움직이다가 9월 말에는 96대까지 내려갔습니다. 내려갔다가 지난달부터 오르기 시작해 99∼100대를왔다갔다하고 있는 상황입니다. 그런데 올해 초에는 110까지 올랐었는데그때도 그래프를 보면 알겠습니다만 그때도 원달러 환율은 1,460원∼1,480원이었는데 지난주 금요일 원·달러 환율은 7개월 만에 1,450원을 넘어서서 종가 기준으로 1458원에 근접했습니다. 그러니까 그때 달러인덱스가 강세일 때하고 비슷한 정도로 갔다는 거고요. 달러인덱스가 10p나 낮은데도원달러 환율은 그때와 비슷한 수준이니까상대적으로 원화가 그때보다 더 힘을 못 쓰고 있다고 보시면 될 것 같습니다. 원화 가치는 일주일 동안 2%나 급락했고요. 중요 통화국 가운데 절하율이 가장 큽니다. 또 한가지 주목할 것은 엔화 약세가 계속되고 있다는 점인데 시장에서 우려가 나오는 수준입니다. 1달러에 150엔대 중반에서 움직이고 있고요. 3년 전에 1달러에 150엔을 넘어섰는데 좀처럼 약세를 탈출할 기미를 보이지 않고 있습니다. 우리와 경쟁 관계에 있는 일본 엔화의 가치가 떨어지면 우리 수출 기업의 가격 경쟁력이 상대적으로 낮아져 원화 약세 압력이 더 커진다는 걸 의미한다고 보시면 될 것 같습니다.\n",
        "\n",
        "[앵커]\n",
        "그런데 연말에는 원·달러 환율이 더 오를 수도 있다, 이렇게 전망하는 전문가들도 있는 것 같더라고요.\n",
        "\n",
        "[기자]\n",
        "여전히 높은 변동성을 예상하는 게 중론이고요. 상단을 1,500원도 열어둬야 한다는 전망도 나오고 있습니다. 가장 큰 게 역시 미국의 금리 인하 여부인데요. 미국은 기준금리가 하단이 3.75%, 상단이 4%고요. 우리 기준금리는 2.5% 수준이거든요. 미국은 지난달 0.25%p 금리 인하를 시행했습니다. 올해는 미 연준의 FOMC 회의가 이제 한 차례만 남았는데우리 시각으로 다음 달 11일에 열립니다. 올해의 통화정책 방향을 마무리하고내년 금리 경로에 대한 중요한 단서를 제공하기 때문에 시장의 이목이 집중돼 있는데 최근 유럽과 중국의 경기 둔화 가능성이 커지면서 투자자들이 리스크가 큰 원화와 같은 신흥국 자산을 회피하고 안전한 자산으로 옮겨가고 있는 추세고요. 이 때문에 외환시장에서 달러의 희소성을 높여 원달러 환율을 끌어올리는 효과를 나타내고 있습니다.\n",
        "\n",
        "[앵커]\n",
        "지금까지는 글로벌 요인들을 설명해 주셨는데 그렇다면 원화가 약세인 국내적 요인도 있을까요?\n",
        "\n",
        "[기자]\n",
        "아무래도 유가증권시장에서 찾을 수 있을 것 같고요. 코스피가 4,000선을 내줬어요. 3953선에서 마무리됐고 금요일에만 72포인트 하락해서 4000선이 무너졌는데 가장 큰 원인이 외국인들이 주식을 팔고 있기 때문입니다. 주간 기준 외국인의 유가증권시장 순매도액이 역대 최대 수준이고요. 지난주 외국인의 코스피 시장 순매도액은 7조 2,640억으로 집계됐는데,직전 역대 1위 기록은 지난 2021년 8월 둘째 주에 기록한 7조450억 원이었습니다. 특히 지난 4일에는 외국인들이 2조 2,300억 원 가까이 내다 팔면서 4년 3개월 만에 최대치를 기록했고요. 증권가에서는 당분간 외국인의 매도세가 지속할 것으로 전망하고 있습니다. 원달러 상승하는 이유도 외국인의 투자심리를 위축하는 요소로 작용하고 있고 그런데 한국은행은 경기 침체와 높은 가계 부채 부담 때문에 금리를 올리기 어려운 딜레마에 처해 있습니다. 이는 한국은행이 환율 방어보다는 국내 경제를 우선할 수 있다는 신호를 줘서원화 약세를 부추길 수 있다는 지적입니다.\n",
        "\n",
        "[앵커]\n",
        "그리고 또 미 연방정부 셧다운이 40일 가까이 되지 않았습니까? 이 부분도 우리 경제나 금융시장에 영향을 미칠까요?\n",
        "\n",
        "[기자]\n",
        "단기 셧다운은 크게 영향을 미치지 않는데 하지만 장기적으로 미국 경제 성장 둔화와 소비 위축을 통해서 우리 금융 시장과 실물 경제 전반에 부정적인 파장을 미치는 악재로 작용할 가능성이 굉장히 크고요. 이미 그 악영향은 우리 경제에도 영향을 미치고 있다고 보는 게 맞을 것 같습니다. 셧다운 장기화 시 정부 기관의 업무가 중단되면서, 중단되면 예를 들면 중요한 고용보고서서나 국내총생산 같은 핵심 경제지표의 발표가 지연되거든요. 가장 중요한 게 미국의 통화정책인데 미 연준은 데이터를 기반으로 금리 정책을 결정합니다. 그렇게 되면 주요 지표를 확인할 수 없게 되면 통화정책 결정에 차질이 생기게 되고요. 이는 곧 시장의 불확실성을 더욱 확대하는 결과를 가져오게 됩니다. 미국 소비자 심리가 위축되면 우리의 주력 수출품인 자동차와 전자제품 같은 미국 수출 수요를 둔화시킬 위험도 있습니다.\n",
        "\n",
        "[앵커]\n",
        "셧다운이 한 달 넘은 상황인데 언제쯤 해결될 것으로 전망을 하시나요?\n",
        "\n",
        "[기자]\n",
        "장담할 수 있는 상황이 아니고요. 2018∼2019년의 35일인 역대 최장 기록을 이미 넘어섰습니다. 참고로 미국의 회계연도는 10월에 시작해서 이듬해 9월에 마무리되는데 트럼프 대통령이 셧다운을 정치적 수단으로활용하려는 의지가 강해서 과거의 셧다운보다 해결이 더 오래 걸릴 수 있다는 경고가 지배적입니다. 셧다운은 한국 증시의 핵심적인 불안 요인 가운데 하나이기도 하고요. 투자자, 그러니까 특히 외국인 투자자의 셀 코리아를 더욱 부추길 가능성도 있습니다.\n",
        "\n",
        "[앵커]\n",
        "그리고 얼마 전에 한미 관세협상 타결 소식이 있었잖아요. 연간 200억 달러씩 투자하기로 한 것도 원달러 환율에 영향을 미친다고 봐야겠죠?\n",
        "\n",
        "[기자]\n",
        "아무래도 환율 상승 압력으로 작용할 가능성이 크다고 봐야 할 것 같고요. 외환시장의 수급 불균형을 심화하는 구조적 요인으로 작용할 가능성이 큽니다. 단기적으로 관세라는 불확실성을 해소할 수 있지만, 장기적으로는 지속적이고 구조적인 상승 압력으로 작용할 것 같고요. 이 때문에 당분간은 1,200원이나 1,300원대 초반 환율은 기대하기 어렵다는 분석이 지배적입니다. 전문가들은 대미 투자에 따른 수급 부담이 겹쳐서 1,400원대 환율은 '뉴 노멀'로 자리 잡을 가능성이 크다고 우려하고 있습니다.\n",
        "\n",
        "[앵커]\n",
        "끝으로 이번 주 국내 주식 시장,전문가들은 어떻게 전망하고 있는지 설명해 주시죠.\n",
        "\n",
        "[기자]\n",
        "전반적으로 이번 주는 글로벌 불확실성이 극도로 높은 상황에서 변동성이 매우 클 것으로 전망하고 있고요. 낙폭 과대 기술주와 정책 수혜가 예상되는 종목을 선별적으로 접근하는 전략을 권고하고 있습니다. 그러니까 만약 이번 주에 셧다운 관련 타결 소식이 나오면단기적으로 가장 강력한 증시 반등 동력이 될 것으로 판단하고 있습니다.\n",
        "\n",
        "[앵커]\n",
        "알겠습니다. 오늘 말씀 여기까지 듣겠습니다. 지금까지 최재민 해설위원과 함께했습니다. 고맙습니다.\n",
        "\"\"\"\n",
        "\n",
        "# content : '~~~'에 요청사항을 적으시면 됩니다. 여기서는 위 글을 세 문장으로 요약해 달라고 요청했습니다.\n",
        "# \"role\": \"user\" 입니다.\n",
        "\n",
        "chat = [\n",
        "    { \"role\": \"user\", \"content\": f\"Could you summarize the following text in three sentence?\\n\\nText:\\n{text_to_summarize}\" }\n",
        "]\n",
        "\n",
        "# 여기부터는 각 사례 모두 코드가 동일합니다.\n",
        "\n",
        "# 1. 딕셔너리 리스트('chat')를 Gemma 모델이 이해할 수 있는 공식 프롬프트 문자열로 변환합니다.\n",
        "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "# 2. 변환된 프롬프트 문자열을 모델이 입력받을 수 있는 토큰 ID 텐서로 변환하고, GPU('device')로 보냅니다.\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# 3. 토큰화된 입력을 모델에 전달하여 텍스트 \"\"생성\"\"을 시작합니다 (최대 256개의 새 토큰 생성).\n",
        "# 생성을 위해 'generate' 함수를 사용합니다.\n",
        "outputs = model.generate(**inputs, max_new_tokens=256) # **inputs에서 **는 빈칸이 아닙니다.\n",
        "\n",
        "# 4. 'outputs'에는 '입력'과 '답변'이 모두 포함되어 있습니다.\n",
        "# 따라서 원본 입력 토큰의 길이(입력, 'inputs.input_ids.shape[1]')를 기준으로, 그 이후에 '새로 생성된' 토큰(답변)만 추출합니다.\n",
        "new_tokens = outputs[0][inputs.input_ids.shape[1]:]\n",
        "\n",
        "# 5. 추출된 토큰 ID 리스트를 다시 사람이 읽을 수 있는 문자열로 \"\"디코딩\"\"합니다.\n",
        "# 디코딩을 위해 'decode' 함수를 사용합니다.\n",
        "text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "# 6. 최종 생성된 답변 텍스트를 화면에 출력합니다.\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (3) 분류 (Classification)\n",
        "\n",
        "원하는 문장을 넣고 감정 분석을 해보세요!"
      ],
      "metadata": {
        "id": "l_UiOd02cuK2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN5y1c0v4a2q",
        "outputId": "84b0f6ce-20df-456d-ff9e-f28a1392702c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 예시 3: 분류 (Classification) ---\n",
            "Neutral.\n",
            "\n",
            "The text is describing a movie review without expressing a positive or negative sentiment.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- 예시 3: 분류 (Classification) ---\")\n",
        "\n",
        "# content: '~~~' 따음표 안에 요청사항을 적으시면 됩니다.\n",
        "# 여기서는 긍정, 부정, 중립으로 감정분석을 요청했습니다.\n",
        "\n",
        "# \\n\\nText: 여기에 감정분석할 문장을 적어주시면 됩니다.\n",
        "# 원하는 문장을 넣고 감정 분석을 해보세요!\n",
        "\n",
        "# \"role\": \"user\" 입니다.\n",
        "\n",
        "chat = [\n",
        "    { \"role\": \"user\", \"content\": \"Classify the text into neutral, negative, or positive. Generate only the class, nothing else.\\n\\nText: 너무 재미가 없다(영화 리뷰)\" }\n",
        "]\n",
        "\n",
        "# 1. 딕셔너리 리스트('chat')를 Gemma 모델이 이해할 수 있는 공식 프롬프트 문자열로 변환합니다.\n",
        "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "# 2. 변환된 프롬프트 문자열을 모델이 입력받을 수 있는 토큰 ID 텐서로 변환하고, GPU('device')로 보냅니다.\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# 3. 토큰화된 입력을 모델에 전달하여 텍스트 \"\"생성\"\"을 시작합니다 (최대 256개의 새 토큰 생성).\n",
        "# 생성을 위해 'generate' 함수를 사용합니다.\n",
        "outputs = model.generate(**inputs, max_new_tokens=256) # **inputs에서 **는 빈칸이 아닙니다.\n",
        "\n",
        "# 4. 'outputs'에는 '입력'과 '답변'이 모두 포함되어 있습니다.\n",
        "# 따라서 원본 입력 토큰의 길이(입력, 'inputs.input_ids.shape[1]')를 기준으로, 그 이후에 '새로 생성된' 토큰(답변)만 추출합니다.\n",
        "new_tokens = outputs[0][inputs.input_ids.shape[1]:]\n",
        "\n",
        "# 5. 추출된 토큰 ID 리스트를 다시 사람이 읽을 수 있는 문자열로 \"\"디코딩\"\"합니다.\n",
        "# 디코딩을 위해 'decode' 함수를 사용합니다.\n",
        "text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "# 6. 최종 생성된 답변 텍스트를 화면에 출력합니다.\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### sLM 활용사례 결과 요약\n",
        "\n",
        "- sLM은 질의응답이나 요약은 어느 정도 수행하지만, 퀄리티가 아쉽습니다.\n",
        "- 감정 분석에서 '너무 재미가 없다'를 중립으로 판단하는 것으로 보아 분류 작업에서도 한계가 나타납니다.\n",
        "\n",
        "\n",
        "- 이렇게 범용적인 활용에서는 한계가 나타나지만, 미세조정(Fine-Tuning)을 통해 특정 작업에 특화하면 해당 작업에는 좋은 성능을 내면서도 여전히 경량화된 모델의 장점을 누릴 수 있는 것이 sLM의 특징입니다!"
      ],
      "metadata": {
        "id": "mCExY4TXqUcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🤩🤩 수고하셨습니다 🤩🤩\n",
        "⭐️⭐️ 2-2의 API KEY 셀을 지우고 과제 제출해주세요!! ⭐️⭐️"
      ],
      "metadata": {
        "id": "NwtpRrJivCh7"
      }
    }
  ]
}