{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21516a58",
   "metadata": {},
   "source": [
    "# 언어모델\n",
    "- 언어모델: 단어 시퀀스에 확률을 할당해 가장 자연스러운 시퀀스를 찾아내는 모델\n",
    "- 이전 단어를 받고 다음단어를 예측하는 방향으로 시퀀스를 찾아냄 그리고 그 예측방식이 두가지로 나뉨.\n",
    "- 바로 통계기반과 인공신경망 기반임.\n",
    "\n",
    "## SLM\n",
    "### SLM\n",
    "- 분포가설이라는 아이디어에 근거함. 분포가설은 비슷한 문맥에 함께 나타나는 단어들은 비슷한 의미를 가진다는 가설임. 이로써 문맥에서 비슷한 위치에 계속 오는 단어들은 같은 카테고리라고 여길 수 있게됨. \n",
    "- 조건부확률\n",
    "    - 앞에서부터 순차적으로 단어가 주어질때 다음 단어가 올 확률을 조건부로 구한다.\n",
    "    - 각 단계의 확률을 모두 곱하면 문장전체의 최종확률이 계산된다. \n",
    "- 카운트기반\n",
    "    - 이전 단어 시퀀스의 등장 빈도로 다음단어의 확률을 계산한다.\n",
    "    - 모든 학습데이터에서 특정 단어가 등장한 경우에, 타겟단어가 따라온 경우의 비율을 계산한다. \n",
    "    - 직관적인만큼 희소문제라는 한계가 존재함. 희소문제란 언어모델이 학습데이터의 양이 한정되어 언어를 정확히 모델링하지 못하는 문제임. 이 문제때문에 통계모델은 버려지고 인공신경망 기반 모델로 넘어가게됨.\n",
    "\n",
    "### N-gram\n",
    "- 정의:연속된 n개의 단어 묶음(시퀀스)로 잘라 토큰화 하는것\n",
    "- 확률 계산할때 모든 앞 단어를 보는 것이 아니라 n-1개의 단어만 참고함.\n",
    "- 희소문제를 어느정도 완화할 수 있지만, 여전히 희소문제가 남아있긴하고 문맥파악의 한계를 극복하지 못했다. \n",
    "### Perplexity\n",
    "- 정의: 언어모델이 특정 문장을 얼마나 '혼란스러워하는지'를 나타내는 수치. \n",
    "- 모든 언어모델들의 성능을 매번 비교하기 어려우니 통합적인 기준을 만들고자 했다. PPL은 낮을수록 좋다. 낮을수록 덜 혼란스러워한다는 뜻.\n",
    "- 평가하려는 문장의 확률에 역수를 취한후 문장의 단어수로 N제곱근을 한 값이다. 즉 모델이 문장의 확률을 높게 예측할수록 PPL 값이 낮아지는 구조다. \n",
    "- PPL 값에 영향을 주는 요인들\n",
    "    1. 문장의 희소성\n",
    "        - 문장이 희소하게 되면 모델이 훈련데이터에서 더 적게볼수밖에 없다. 즉 더 혼란스러워한다.\n",
    "    2. 문장의 길이\n",
    "        - 단어개수가 커지면 함께봐야할 단어들이 많아지므로 희소한 부분이 있어도 예측을 어떻게 잘 해볼 수 있다. 즉 PPL이 낮아진다.\n",
    "\n",
    "## 딥러닝 기반 언어모델\n",
    "### LLM\n",
    "- 정의 : 대규모 언어모델. 통계적모델이 아닌 인공신경망 모델이다!\n",
    "- 발전 단계\n",
    "    1. Small LM : 제한된 텍스트를 학습해 국소적인 문맥이해에 초점을 둔 작은 모델\n",
    "    2. Neural LM: 단어 임베딩, 문장완성, 기계 번역등의 NLP작업에 활용되는 언어모델. 통계적 모델보다 더 성능이 좋아짐\n",
    "    3. Pretrained LM: 대규모 데이터셋으로 미리 학습한 언어모델, 이후 파인튜닝을 통해 다양한 작업에 특화가능함.\n",
    "\n",
    "    4. LLM : PLM이 더 거대해진 거대 언어 모델 \n",
    "    5. AI: LLM이 뇌인 에이전트에 가까움.\n",
    "- 작동방식\n",
    "    - 대규모 학습: 인터넷의 방대한 데이터를 학습하고 단어사이의 관계, 문맥, 문법, 지식등에서 언어의 패턴을 스스로 터득함.\n",
    "    - 예측 및 생성: 학습이 완료된 LLM에게 사용자가 질문이나 지시를 내리면 학습한 패턴을 기반으로 다음에 올 가장 확률 높은 단어를 순서대로 예측하며 응답해줌\n",
    "- 사용사례: 텍스트 생성, 기계번역, 질의 응답, 문서요약, 감정분석\n",
    "### BERT\n",
    "- 정의: 양방향 어텐션을 활용한 인코더\n",
    "- 사전학습을 충분히 시키고 마지막 레이어로 파인튜닝을해 다운스트림 태스크를 완수하는 모델을 만드는 구조. \n",
    "- 양방향 어텐션이므로 시퀀스에서 임의의 단어들을 마스킹하고 예측하는식으로 학습함. 당연히 예측할땐 마스크기준 앞뒤 문맥을 모두 참고함.\n",
    "- 입력시퀀스는 1개일수도 2개일수도 있음. 따라서 임베딩과정에서 어떤 문장의 단어인지 세그먼트 임베딩하고, 전체 포지셔널인코딩도 함. \n",
    "- 마스크 비율은 인풋 텍스트의 15%정도의 단어를 랜덤으로 만들며 마스킹방식도 세가지임. 일반적인 마스크로 바꾸거나, 랜던단어로 대체하거나, 그대로 두기임. 왜 이런 방식을 하냐? 파인튜닝과정에서 마스크에만 의존하는 문제가 있어서 일반화시키기 위해서임.\n",
    "- NSP는 문장간 관계를 학습시키는 훈련임. \n",
    "### GPT\n",
    "- 정의: 단방향 어텐션을 활용한 디코더\n",
    "- 버트와의 차이점: 버트는 양방향 셀프어텐션이지만 지피티는 좌->우 방향 셀프어텐션임. 지피티의 이 논리는 트랜스포머 디코더에서 사용하던 걸 그대로 가져온것임. 다음 단어를 예측할 때 정답을 이미 알면 베끼기에 불과하다는 아이디어. \n",
    "- 버트는 사전학습한 모델에 마지막 파인튜닝을 거치지만 지피티는 파인튜닝없이 SHOT을 먹여서 바로 task를 수행하도록 만듦. \n",
    "### LLM의 한계\n",
    "- 할루시네이션\n",
    "- 업데이트 비용이 엄청 비싸당\n",
    "### RAG\n",
    "- 새로운 지식이 나올때마다 LLM을 학습시킬거냐? 완전비효율~ 그래서! LLM이 그냥 그 지식을 토대로 말하도록 하는건 어떨까\n",
    "- 정의: 관련 정보를 검색해 먼저 찾고, 이를 LLM에 같이 넣어 최종답변을 생성하는 하나의 파이프라인\n",
    "- 구조\n",
    "    1. 질의 인코더 : 사용자의 질문을 벡터로 인코딩\n",
    "    2. 지식 검색기: 인코딩된 질문을 바탕으로 외부 지식베이스에서 검색\n",
    "    3. 지식증강생성기: 검색된 지식을 활용해 답함. 기존 LLM과 유사하지만 검색된 지식을 추가 입력 받는다는 차이점이 있음.\n",
    "- 장점: 풍푸한 정보제공이 가능, 실시간 정보를 반영 가능, 환각 방지\n",
    "- CAG : 레그를 보완한 프레임워크. \n",
    "\n",
    "### LangChain\n",
    "- 모델 파이프라인을 쉽게 구성할 수 있도록 도와주는 프레임워크\n",
    "- LLM을 기반으로 앱 만들때 필요한 구성요소를 쉽게 연결 가능.\n",
    "- 특징\n",
    "    1. 추상화: LLM서비스를 만들때 필요한 각종 작업을 간결하게 표핸해주고 간소화해줌\n",
    "    2. 표준화: 비슷한 기능을 갖춘 요소들을 똑같은 형식의 컴포넌트로 표준화해줌\n",
    "    3. 체이닝: 자주 활용하는 주요 컴포넌트를 쉽게 연결해 로직을 만듦. \n",
    "- LangGraph\n",
    "    - 비선형적인 작업 형태로 사이클, 루프를 만들 수 있음\n",
    "    - 노드: 특정 작업을 수행하는 단위. 랭테인의 컴포넌트가 노드가 될수도 있음\n",
    "    - 엣지: 노드와 노드를 연결하는 선. 어떤 노드에서 다음 노드로 이동할지를 결정. 조건부 엣지도 가능함. \n",
    "- LangSmith\n",
    "    - LLM기반 애플리케이션을 위한 통합 개발 및 운영 플랫폼\n",
    "    - 핵심기능\n",
    "        1. 디버깅과 추적: 모든 실행과정을 단계별로 시각화 가능.\n",
    "        2. 테스트 및 평가: 개발중인 어플의 성능을 자동으로 평가\n",
    "        3. 모니터링: 실제 사용자들이 어떻게 사용하는지 모니터링 가능(API호출횟수, 지연시간, 토큰 사용량등)\n",
    "        4. 프롬프트 허브: 다양한 프롬프트 저장, 버전관리 등의 편의성\n",
    "- 외부 API 활용하기\n",
    "    - LLM내부 지식만을 이용해 해결할 수 없는 질문을 외부 API를 가져와 답변가능!\n",
    "    \n",
    "## sLM\n",
    "- 소규모 언어모델이란: 자연어 콘텐츠를 처리하는 모델이지만 LLM에 비해 규모와 범위가 매우 작음. \n",
    "- LLM은 엄청 큰 메모리, 학습시간, 데이터, 비용이 문제점이었음 따라서 이를 해결코자 소규모 언어모델의 필요성이 부각된것임. 주로 모바일이나 엣지 환경에서 사용되는것! \n",
    "- 모델압축\n",
    "    1. 가지치기 : 신경망에서 중요도가 낮거나 중복되는 매개변수는 과감히 쳐내자\n",
    "    2. 양자화: 고정밀 데이터를 저정밀 데이터로 변환하자. 이로써 계산 부하를 줄이고 속도를 높히자\n",
    "    3. 지식 증류: 사전학습된 교사모델의 학습내용을 학생모델로 이전시키자. 교사의 예측과 기본추론능력을 모방하도록 학습시키자!\n",
    "- 장점: 외부서버가 아니므로 프라이버시가 지켜짐, 학습과 추론에서 비용을 절감, 특정 작업에 최적화해 효율성 및 맞춤화 가능.\n",
    "- 한계\n",
    "    1. 편향 : 교사의 편향도 그대로 학습해버린다.\n",
    "    2. 제한된 일반화: 광범위한 지식이 없으므로 특정작업에는 적합하지만 다양한 작업에는 실수가 많음.\n",
    "    3. 할루시네이션: 당연히 할루시네이션발생 가능\n",
    "    4. 성능과 용량의 한계: LLM에 밀리는것이 당연.\n",
    "        - 하지만 극복해볼수 있다. 파인튜닝과 지식증류를 통해 학습단계에서 최대한 전문화 및 지식을 확보해놓자. 이후 추론단계에서 일반화나 할루시를 줄이기 위해 RAG의 도움을 받거나 결합추론을 해보자. 용량의 한곈른 모델압축으로 극복해보자\n",
    "- LLM과의 결합\n",
    "    - sLM이 먼저 해보고 어렵다? 선생님 호출~~!\n",
    "    - sLM이 풀고 점수를 매겨서 좀 불확실하다면 LLM에게 딱 그 불확실한 단계만 요청해서 도움을 받는구조. LLM을 안쓰니까 토큰 사용량을 획기적으로 줄일 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b9fe1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
