{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H3gXKi9Ppbhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시계열 분석 2차시\n",
        "\n",
        "---\n",
        "\n",
        "# 0. 1차시 간단 복습\n",
        "\n",
        "## 시계열이란?\n",
        "- 시간 순서대로 기록된 데이터  \n",
        "- 관측치 간 상관관계 존재\n",
        "- 순서가 중요한 시퀀스 데이터\n",
        "\n",
        "\n",
        "---\n",
        "----\n",
        "\n",
        "## 시계열 데이터의 특징\n",
        "\n",
        "### 1) 시간 의존성  \n",
        "값이 시간에 따라 변화함\n",
        "\n",
        "### 2) 추세 & 계절성\n",
        "- 추세: 장기 증가/감소  \n",
        "- 계절성: 일정 주기 반복 패턴\n",
        "\n",
        "### 3) 자기상관\n",
        "이전 값이 이후 값에 영향\n",
        "\n",
        "→ 회귀 분석의 오차항 독립성 위배 → 일반 회귀는 시계열에 부적합\n",
        "\n",
        "---\n",
        "\n",
        "## 시계열 구성 요인 (요소분해)\n",
        "\n",
        "- Trend  \n",
        "- Cycle  \n",
        "- Seasonality  \n",
        "- Irregular\n",
        "\n",
        "---\n",
        "\n",
        "## 시계열 분석 프로세스\n",
        "\n",
        "1. 데이터 전처리(결측치, 이상치, 분해)\n",
        "2. 정상성 검정(ADF, KPSS)\n",
        "3. 정상성 확보  \n",
        "   - 추세 → 차분(d)  \n",
        "   - 계절성 → 계절 차분(D)  \n",
        "   - 분산 변동 → 로그/Box-Cox 변환  \n",
        "4. 모델링\n",
        "   - 안정적: AR, MA, ARMA  \n",
        "   - 비정상: ARIMA, SARIMA  \n",
        "5. 예측 → 평가 (AIC, BIC)\n",
        "\n",
        "---\n",
        "\n",
        "# 1. 단변량 시계열 분석\n",
        "\n",
        "# 정상성 O — 안정적 시계열\n",
        "\n",
        "---\n",
        "\n",
        "# AR(p): Autoregressive Model\n",
        "\n",
        "###  개념\n",
        "과거 자신의 값을 이용해 현재 값을 예측하는 자기회귀 모델\n",
        "\n",
        "###  특징\n",
        "- 예측값을 모델에 활용하도록 설계됨  \n",
        "- 파라미터 추정: MLE\n",
        "- 일반 회귀보다 시계열 예측에 더 적합\n",
        "\n",
        "---\n",
        "\n",
        "# MA(q): Moving Average Model\n",
        "\n",
        "### 주의할 점\n",
        "평활화 Moving Average와 다름\n",
        "\n",
        "### 개념\n",
        "현재 값은 과거 오차(충격)들의 선형결합\n",
        "\n",
        "### 백색잡음\n",
        "\n",
        "- 평균 0  \n",
        "- 분산 일정  \n",
        "- 상관 없음  \n",
        "\n",
        "---\n",
        "\n",
        "# AR/MA 모델 전제 조건\n",
        "\n",
        "###  1) 정상성\n",
        "- AR 모델 필수  \n",
        "- AR(1):  \n",
        "\n",
        "- MA 모델은 잔차 기반이므로 항상 정상성 만족\n",
        "\n",
        "###  2) 가역성\n",
        "- MA 모델 필수  \n",
        "- 특성방정식 해의 절댓값 > 1  \n",
        "\n",
        "---\n",
        "\n",
        "# ARMA(p, q) 모델\n",
        "\n",
        "### 개념\n",
        "AR + MA 결합 모델\n",
        "\n",
        "###  조건\n",
        "- AR 정상성  \n",
        "- MA 가역성\n",
        "\n",
        "###  특수 형태\n",
        "- ARMA(p,0) = AR(p)  \n",
        "- ARMA(0,q) = MA(q)  \n",
        "- ARMA(0,0) = White Noise  \n",
        "\n",
        "---\n",
        "\n",
        "#  차수 결정: ACF & PACF\n",
        "\n",
        "\n",
        "AR(p) acf: 천천히 감소, pacf: p 이후 절단\n",
        "MA(q) acf: q 이후 절단, pacf:  천천히 감소\n",
        "ARMA(p,q) acf: 둘 다 감소, pacf: 둘 다 감소\n",
        "\n",
        "---\n",
        "\n",
        "# 1.2 정상성 X — 불안정 시계열\n",
        "\n",
        "---\n",
        "\n",
        "# 분석 절차\n",
        "1. 추세·계절성 존재  \n",
        "2. 차분(d), 계절 차분(D) 수행  \n",
        "3. 정상성 확보  \n",
        "4. ARMA 기반 모델 적용 → ARIMA/SARIMA  \n",
        "\n",
        "---\n",
        "\n",
        "# ARIMA(p, d, q)\n",
        "\n",
        "### 정의\n",
        "\n",
        "- \\(p\\): AR 차수  \n",
        "- \\(d\\): 추세 제거(차분) 횟수  \n",
        "- \\(q\\): MA 차수  \n",
        "\n",
        "### 특수 케이스\n",
        "1. ARIMA(0,1,0): 랜덤워크  \n",
        "\n",
        "2. ARIMA(0,1,0) + c: Drift 랜덤워크  \n",
        "\n",
        "---\n",
        "\n",
        "#  SARIMA\n",
        "\n",
        "### 계절성 포함 ARIMA\n",
        "\n",
        "- (p,d,q): 비계절  \n",
        "- (P,D,Q): 계절  \n",
        "- m: 계절 주기 (예: 12개월)\n",
        "\n",
        "### 예시\n",
        "\n",
        "- 비계절 차분 1회  \n",
        "- 계절 차분 1회  \n",
        "- AR(1), MA(1), 계절 AR(1), 계절 MA(1)\n",
        "\n",
        "---\n",
        "\n",
        "# 계절성 시계열의 ACF/PACF 특징\n",
        "\n",
        "- ACF가 m의 배수 lag에서 급등  \n",
        "- 계절 차분(D=1) 후 비계절 차분(d=1)을 수행  \n",
        "\n",
        "---\n",
        "\n",
        "# 하이퍼파라미터 선택 절차\n",
        "\n",
        "1. ADF → d, D 선택\n",
        "2. ACF·PACF → p, q 후보\n",
        "3. AIC/BIC → 최종 선택\n",
        "---\n",
        "\n",
        "# 2. 다변량 시계열 분석\n",
        "\n",
        "---\n",
        "\n",
        "# VAR\n",
        "\n",
        "###  개념\n",
        "자신의 과거 + 다른 변수의 과거를 함께 사용하여 미래 예측\n",
        "\n",
        "---\n",
        "\n",
        "## Granger 인과관계 검정\n",
        "\n",
        "X의 과거가 Y 예측에 통계적으로 의미 있는가?\n",
        "\n",
        "- p-value < 0.05 → VAR에 변수 포함\n",
        "\n",
        "---\n",
        "\n",
        "##  VAR 분석 도구\n",
        "\n",
        "### 1) IRF\n",
        "충격 발생 시 다른 변수의 시간적 반응 분석\n",
        "\n",
        "### 2) Variance Decomposition\n",
        "미래 예측 오차가 어떤 변수 충격 때문인지 기여도 분해\n",
        "\n",
        "---\n",
        "\n",
        "# 3. 딥러닝 기반 시계열 분석\n",
        "\n",
        "---\n",
        "\n",
        "# 딥러닝이 필요한 이유\n",
        "- 비선형 패턴 포착  \n",
        "- 긴 시퀀스 처리  \n",
        "- 병렬 연산 기반 예측 능력 향상  \n",
        "\n",
        "---\n",
        "\n",
        "# RNN 계열\n",
        "\n",
        "- RNN\n",
        "\n",
        "RNN은 가장 기본적인 순환 구조를 가진 모델로, 짧은~중간 길이(약 10~100 시점)의 시계열 패턴을 학습하는 데 적합하다. 하지만 장기 의존성을 학습하기 어려워, 긴 시퀀스에서는 성능이 급격히 떨어진다는 한계가 있다.\n",
        "\n",
        " - LSTM\n",
        "\n",
        "LSTM은 게이트구조를 도입해 오래된 정보를 보존하고 불필요한 정보를 걸러낼 수 있도록 설계된 모델이다. 덕분에 100~1000 시점처럼 비교적 긴 시계열에서도 안정적으로 장기 의존성을 학습할 수 있다. 다만 구조가 복잡하고 학습 속도가 느리다는 단점이 있다.\n",
        "\n",
        "- GRU\n",
        "\n",
        "GRU는 LSTM의 구조를 단순화한 모델로, 비슷한 성능을 유지하면서도 계산량이 적어 더 빠르게 학습된다. 특히 실시간 처리처럼 속도가 중요하거나, 데이터가 많지 않은 경우에 유리하다. 하지만 장기 의존성 학습 능력은 LSTM에 비해 약간 떨어지는 경향이 있다.\n",
        "\n",
        "---\n",
        "\n",
        "# ② Transformer 계열\n",
        "\n",
        "###  공통 장점\n",
        "- 병렬 처리  \n",
        "- 매우 긴 시계열(1000+) 처리  \n",
        "- 다변량에 강함  \n",
        "\n",
        "### 모델별 특징\n",
        "\n",
        " - Transformer\n",
        "\n",
        "Transformer는 기본적인 Attention 구조를 사용하는 시계열 모델로, 짧은 길이에서 중간 정도 길이의 시계열 데이터를 처리하는 데 적합하다. 구조가 비교적 단순해 구현과 확장이 용이하다.\n",
        "\n",
        "- Informer\n",
        "\n",
        "Informer는 ProbSparse Attention 기법을 활용하여 중요한 쿼리만 선택하는 방식으로 계산량을 크게 줄인 모델이다. 덕분에 매우 긴 시계열을 효율적으로 처리할 수 있어, 대규모 시퀀스 데이터에 특히 강하다.\n",
        "\n",
        "- Autoformer\n",
        "\n",
        "Autoformer는 시계열을 추세와 계절성으로 분해하는 구조를 기반으로 하며, 자기상관모듈을 통해 주기적 패턴을 안정적으로 학습한다. 따라서 계절성과 주기성이 뚜렷한 데이터에서 가장 효과적이다.\n",
        "\n",
        "- TFT\n",
        "\n",
        "TFT는 시계열 예측에서 해석 가능성을 강조한 모델로, Attention과 다양한 게이트 구조를 활용해 정적 변수·동적 변수·미래 정보 등 외생 변수를 효과적으로 통합한다. 외생 변수가 많거나 변수 간 상호작용이 중요한 예측 문제에 적합하다.\n",
        "\n",
        "---\n",
        "\n",
        "# Foundation Model\n",
        "\n",
        "### 개념\n",
        "대규모 시계열 데이터로 사전 학습된 범용 예측 모델  \n",
        "(예: TimeGPT, TimesFM, Moirai)\n",
        "\n",
        "### 장점\n",
        "- 사전 지식 기반 빠른 예측  \n",
        "- 여러 도메인에 적용 가능  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dE3AqulTrGrj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpq-WHZTrENB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}