{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 추천시스템\n",
        "\n",
        "## 내용 기반 필터링\n",
        "\n",
        "콘텐츠의 '유사도'를 기반으로 사용자에게 추천하는 방법으로 사용자가 이용하거나 선택한 아이템과 유사한 아이템을 추천하는 방식이다.\n",
        "\n",
        "## 협업 필터링\n",
        "\n",
        "서비스 내에 있는 다수의 사용자로부터 얻은 선호도 정보를 기반으로 사용자에게 추천하는 방식이다.\n",
        "\n",
        "## 하이브리드 필터링\n",
        "\n",
        "2가지 이상의 다양한 종류의 추천시스템 알고리즘을 조합하여 만들어진 알고리즘"
      ],
      "metadata": {
        "id": "4STPt8Emjs2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 협업필터링의 구현 방식\n",
        "\n",
        "### 1. 기억 기반\n",
        "실제 평점 데이터를 메모리에 저장하고, 유사도를 계산하는 방식을 작동한다.\n",
        "1) 사용자 기반 협업 필터링 방식\n",
        "- 나와 다른 모든 사용자 간의 유사도를 계산\n",
        "- 유사도가 높은 상위 k명의 이웃을 선정\n",
        "- 이웃들이 선호했지만 내가 보지 않은 아이템을 추천\n",
        "- 사용자가 많아질수록 계산량이 늘어나 사용자 취향이 매우 다양하여 유사도를 정확히 찾기 어려움\n",
        "\n",
        "2) 아이템 기반 협업 필터링 방식\n",
        "- 모든 아이템 쌍 간의 유사도를 계산\n",
        "- 내가 선호한 아이템과 유사한 아이템을 찾아서 추천\n",
        "\n",
        "-> 한계점\n",
        "1) 대부분의 사용자는 전체 아이템 중 극히 일부에만 평점을 매기기에 데이터의 희소성 문제가 발생\n",
        "2) 사용자와 아이템 수가 증가할수록 유사도를 계산해야 하는 쌍의 수가 늘어나는 확장성 문제가 발생\n",
        "3) 새로운 아이템은 상호작용이 없어 유사도를 계산할 수 없는 문제가 발생\n",
        "\n",
        "-> 모델 기반 협업 필터링의 등장"
      ],
      "metadata": {
        "id": "3u7bQxF0kAW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 기반 협업 필터링\n",
        "\n",
        "## 잠재요인과 행렬 분해\n",
        "잠재 요인: 사용자와 아이템 상호작용 행렬에 숨겨져 있는 사용자의 취향이나 아이템의 특성을 설명하는 숨겨진 차원이다.\n",
        "\n",
        "행렬 분해: User-item 평점 행렬이 사용자의 취향 벡터와 아이템의 특성 벡터의 내적으로 설명될 수 있다는 가설에서 출발하여 \"관측된 평점을 가장 잘 재현하는 가장 적절한 잠재 요인의 개수 k를 찾는 것\"\n",
        "\n",
        "행렬 분해의 수행 방식 4가지\n",
        "1) 수학적 분해 기법: 행렬대수학에 기반하여 행렬을 분해\n",
        "2) 최적화 알고리즘: 경사 하강법 기반의 알고리즘\n",
        "3) 제약 조건 기반 모델: 분해된 행렬에 비음수라는 제약 조건을 추가하여 잠재 요인의 해석력을 높임\n",
        "4) 확률적 모델: 평점 예측에 확률 분포를 사용"
      ],
      "metadata": {
        "id": "KWuC-2rIkol1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최근 추천시스템의 방향성\n",
        "\n",
        "## VAE 기반 협업 필터링\n",
        "사용자의 아이템 상호작용 벡터를 입력으로 받아, 잠재 공간에서 재구성하도록 VAE를 학습하는 방식\n",
        "\n",
        "장점\n",
        "1) 기존 행렬분해처럼 단일 포인트 벡터가 아니라 확률적 잠재 분포로 사용자 선호를 모델링 하여 불확실성을 반영\n",
        "2) 희소한 상호작용 데이터에서도 활용 가능\n",
        "\n",
        "-> VAE가 나오게 된 계기\n",
        "1) MF의 근본적인 한계\n",
        "- 선형성의 한계: 평점 예측이 단순 잠재 벡터의 내적으로만 이루어져서 비선형 활성화 함수를 가진 신경망을 활용하여 복잡한 패턴을 학습한다.\n",
        "- 불확실성 무시: 사용자 취향을 단 하나의 벡터값으로만 표현하여 확률 분포로 취향을 모델링하여 데이터의 불확실성을 반영하도록 한다.\n",
        "\n",
        "VAE인 이유? (AE가 아니라)\n",
        "-> AE의 접근 방식은 A의 취향을 '단일 값'으로 추정하기 때문에 데이터가 부족하면 이 단일 추정치가 불안정하고 틀리기 쉬워 노이즈에 취약하게 되기에 평균과 표준편차를 따르는 '분포'일 것으로 추정하여 불확실성을 모델링에 포함시켜 안정성을 높일 수 있다.\n",
        "\n",
        "VAE기반 CF의 작동 구조\n",
        "-> VAE 기반 CF에서는 사용자의 아이템 상호작용 벡터를 입력으로 받아 잠재 공간에서 재구성하도록 학습하는 방식이다.\n",
        "\n",
        "VAE의 우수성: 목적함수와 KL Divergence\n",
        "1) 재구성 오차 최소화: 디코더가 잠재 벡터 z를 사용하여 원래 입력 x를 최대한 비슷하게 복원하도록 한다.\n",
        "2) KL Divergence: 인코더가 출력하는 잠재 분포가 사전 분포와 유사하도록 강제하여 과적합을 방지하고 잠재 공간을 넓고 부드럽게 유지하도록 한다."
      ],
      "metadata": {
        "id": "PuQ5Ow0MlbJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN 기반 사용자 선호 예측\n",
        "\n",
        "1. GNN의 필요성\n",
        "\n",
        "그러나, VAE와 같은 딥러닝 잠재 요인 모델 역시 '관계'나 '순서'라는 풍부한 정보를 활용하지 못하는 문제가 발생한다.\n",
        "\n",
        "2. GNN: 그래프 신경망\n",
        "\n",
        "GNN은 사용자와 아이템의 상호작용을 '서로 연결된 거대한 관계망'을 형성한다는 점에서 모티브를 얻고, 사용자-아이템 상호작용은 그래프라는 것에서 출발한다.\n",
        "\n",
        "- 그래프란?\n",
        "\n",
        "노드와 그 노드를 잇는 선을 모아 구성한 자료구조로 노드는 '현실 세계의 개체'를 의미하며, 노드를 잇는 선인 엣지는 '개체 간 관계나 상호작용'을 나타낸다.\n",
        "\n",
        "- 그래프를 사용하는 이유?\n",
        "1) 관계, 상호작용과 같이 추상적 개념을 다루기에 적합하다.\n",
        "2) Non-Euclidean space도 표현하고 학습할 수 있다.\n",
        "\n",
        "3. GNN의 구조\n",
        "1) 그래프 구조 생성: 노드와 엣지를 정의하고 각각의 피처를 담아 표현하는\n",
        "2) 메시지 패싱: 각 노드가 이웃 노드로부터 정보를 받아서 전달한다.\n",
        "- 메시지 생성: 이웃 노드에 전달할 메시지 생성\n",
        "- 집계: 받은 여러 이웃의 메시지를 하나로 합침\n",
        "- 갱신: 자신의 노드 상태를 업데이트\n",
        "3) 최종 출력"
      ],
      "metadata": {
        "id": "qVQPGiszm_Ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGCN\n",
        "LightGCN은 GCN의 한 종류이며, GNN의 한 종류이기도 하다. 그 중에서도 추천 시스템에 특화된 GNN으로 '복잡성을 제거하고 최적화'한 버전이다.\n",
        "\n",
        "특징\n",
        "1) 특징 변환 제거: 레이어마다 복잡했던 학습 파라미터 삭제\n",
        "2) 비선형 활성화 함수 제거: ReLU와 같은 활성화 함수를 사용하지 않고 이웃 정보를 합침\n",
        "\n",
        "-> 매우 가볍고 효율이 좋은 모델"
      ],
      "metadata": {
        "id": "KVcz-zWrn-bv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN의 장단점\n",
        "\n",
        "장점\n",
        "1) 고차원 협업 시그널 포착: 단순히 '나'의 잠재 요인을 넘어, 나와 취향이 비슷한 사용자들과 내가 본 아이템과 연결된 다른 아이템들의 정보를 직접 반복해서 반영할 수 있다.\n",
        "2) 정형화되지 않은 데이터 학습 가능: '관계'를 학습하기 때문에 각 노드가 정형화된 데이터로 정의되지 않아도 관계망 속에서 정보를 효과적으로 전파할 수 있다.\n",
        "3) Cold Start 문제 완화에 효과적: 신규 사용자나 아이템에 대한 데이터가 부족해 추천을 생성하기 어려웠던 기존 방식과 달리, 노드의 고유 특징과 주변 이웃과의 관계를 활용해 즉시 임베딩을 생성할 수 있다.\n",
        "\n",
        "단점\n",
        "1) 과평탄화 문제: 연결된 그래프 내에 모든 노드 간의 임베딩이 비슷해지는 문제가 발생한다.\n",
        "2) 과압축 문제: GNN의 층이 깊어질수록 집계하는 이웃의 범위가 기하급수적으로 커지는데, 이를 고정된 크기의 벡터 하나에 모두 압축하려고 하면 정보가 손실될 수 있다.\n",
        "3) 높은 계산 복잡도\n",
        "4) 해석의 어려움"
      ],
      "metadata": {
        "id": "a2QaYN1XoYH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer 기반 추천 시스템\n",
        "\n",
        "### 기존 추천 시스템의 순차적 한계\n",
        "1. CF의 순차적 한계\n",
        "- 순서 무시\n",
        "- 문맥 부족\n",
        "- 예측의 한계\n",
        "\n",
        "2. GNN의 순차적 한계\n",
        "- 지역적 정보 전파의 한계\n",
        "- 장기 의존성 문제\n",
        "\n",
        "### Transformer: 사용자 행동을 '순서'로 접근\n",
        "의도의 파악이라는 목적을 갖고, 행동 순서(문맥)을 파악하는데 강한 특징이 있다.\n",
        "ex) 문맥에 따라 달라지는 동일 아이템의 의미 파악\n",
        "ex) 시간 순서를 뛰어넘는 '핵심 의도'의 포착\n",
        "\n",
        "### Transformer의 핵심: Self-Attention\n",
        "시퀀스 내 모든 아이템 간의 관계를 거리에 상관없이 동시 계산한다.\n",
        "\n",
        "동작원리: Query, Key, Value\n",
        "\n",
        "연산 과정: \"관련성\"을 계산하여 \"가중치\"를 만드는 것\n",
        "1) attention score 계산: Query가 모든 Key와 얼마나 유사한지 유사도를 통해 '관련성 점수'를 계산한다.\n",
        "2) 가중합이 '관련성 점수'를 거쳐 '가중치'로 변환한다.\n",
        "3) 이 가중치를 각 아이템의 value에 곱하여 모두 더한다.\n",
        "4) 결과: 아이템간 관련성에 따라 정보 반영률이 차등 적용된다.\n",
        "\n",
        "### Transformer 기반 주요 추천 시스템 모델\n",
        "1) SASRec\n",
        "2) BERT4Rec"
      ],
      "metadata": {
        "id": "81aEofm5pru4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 진짜 최신 트렌드: LLM\n",
        "추천을 '랭킹' 문제가 아닌 '언어'문제로 푸는 것\n",
        "-> 추천을 점수 계산이 아닌 '문장'으로 출력하여 단순한 랭킹을 보여주는 것이 아니라, 사용자의 상황에 맞게 이유를 덧붙인 서술형 추천까지 가능하다.\n",
        "\n",
        "P5 / TALLRec\n",
        "1) P5: 모든 추천 과제를 LLM이 풀 수 있도록 '하나의 거대한 텍스트 프롬프트'문제로 통일시킨 모델\n",
        "2) TALLRec: P5처럼 처음부터 다 학습시키기보다 이미 잘 만들어진 범용 LLM을 '추천' 작업에 맞게 효율적으로 튜닝하는 프레임워크"
      ],
      "metadata": {
        "id": "xnPIzRAXrI9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 책임감 있는 AI\n",
        "1) 인기 편향: 추천 시스템이 소수의 인기 아이템을 과도하게 노출하고 다수의 비인기 아이템이 받아야 할 관심을 받지 못하게 할 경우, 인기 있는 것만 더 인기가 높아질 가능성, 비인기 아이템은 거의 추천되지 않을 수 있다.\n",
        "2) 설명가능성: GNN과 Transformer 같은 딥러닝 모델은 모델은 강력하지만 '블랙박스' 문제가 있다.\n",
        "\n",
        "즉, 최고의 모델은 가장 정확한 모델이 아니라, 편향과 공정성을 고려하여 그 추천 근거를 설명할 수 있는 '책임감 있는' 모델이다."
      ],
      "metadata": {
        "id": "ntbKZUDsrljz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpr7KoAMjrTc"
      },
      "outputs": [],
      "source": []
    }
  ]
}