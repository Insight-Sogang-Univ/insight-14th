{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2c59bf",
   "metadata": {},
   "source": [
    "# 시계열2\n",
    "## 단변량 시계열 분석<br>\n",
    "#### <span style='background-color: #fff5b1'> 1. 안정적 시계열 분석 </span>\n",
    "\n",
    "**(1) 자기 회귀 모델 (AR)**<br>\n",
    "\n",
    "자기 회귀 = 과거 자신의 값을 독립변수로 삼아 현재 값을 예측하는 회귀      \n",
    "=> 시계열 데이터의 자기상관성 활용    \n",
    "\n",
    "- AR(p) = p차 자기 회귀 모형: 과거 p개 시점의 데이터의 선형 조합을 이용해 예측하는 모델    \n",
    "- 예측값을 사용하는 구조가 모델 설계에 포함     \n",
    "- 최우도 추정 기반으로 파라미터 추정     \n",
    "\n",
    "\n",
    "**(2) 이동 평균 모델 (MA)**<br>\n",
    "\n",
    "= 과거 시점의 잔차를 독립변수로 삼아 현재 값을 예측하는 모델 -> 과거 예측 오차를 현재 시점에 반영     \n",
    "- MA(q) = q차 이동 평균 모형: 과거 q개 예측 오차의 선형 결합으로 예측하는 모델     \n",
    "\n",
    "\n",
    "**(3) AR, MA 모델의 전제 조건**<br>\n",
    "\n",
    "- 데이터 특성과 모델 구조 안정성 고려해야 함     \n",
    "\n",
    "- **정상성**       \n",
    "\n",
    "- 특성 방정식의 모든 해의 절댓값이 1보다 커야 함     \n",
    "- 잔차들은 이미 정상성을 만족하기 때문에, 잔차 조합으로 구성된 MA 모형도 항상 정상성 만족      \n",
    "- ADF, KPSS로 파악하는 데이터 정상성과 다름       \n",
    "\n",
    "- **가역성**       \n",
    "\n",
    "- MA 모형을 AR 형태로 다시 표현할 수 있는지 여부      \n",
    "=> 오차항을 과거 관측값으로 표현할 수 있어야 안정적     \n",
    "- MA 모형의 특정 방정식의 모든 해의 절댓값이 1보다 커야 함     \n",
    "- AR 모형은 처음부터 AR 형태이므로 가역성 확인할 필요 없음     \n",
    "\n",
    "\n",
    "**(4) ARMA 모형**<br>\n",
    "\n",
    "- AR(p) + MA(q) = 과거 p개의 관측값 + 과거 q개의 오차를 활용해 예측     \n",
    "- AR(p) 정상성, MA(q) 가역성 모두 만족해야 함     \n",
    "- ARMA(p, 0) = AR(p)      \n",
    "- ARMA(0, q) = MA(q)       \n",
    "- ARMA(0,0) = 백색 잡음 모델과 동일      \n",
    "\n",
    "**차수 결정 방법: 자기 상관 함수**<br>\n",
    "\n",
    "- ACF, PACF로 적절한 차수 (p,q) 결정     \n",
    "    - ACF = 자기 상관 계수: ARMA(p, q)모형에서 사용할 q개의 오차 결정 방법 => 두 시점 사이 상관 관계 파악      \n",
    "    - PACF = 부분 자기 상관 계수: ARMA(p, q) 모형에서 사용할 p개의 시점 결정 방법 => 두 시점 사이의 직접적 영향만 파악     \n",
    "\n",
    ". | ACF 그래프 | PACF 그래프      \n",
    "----- | ----- | -----        \n",
    "AR(p) 사용 | 천천히 감소 / 진동 감소 [현재 값이 여러 시차의 과거 값과 약하게 연결] | p+1 부터 0 근접 [p까지만 과거가 현재에 영향]         \n",
    "MA(q) 사용 | q+1 부터 0 근접 [q까지만 과거 오차항의 영향] | 천천히 감소 / 진동 감소 [오차항이 만드는 간접 상관 존재]       \n",
    "ARMA(p,q) 사용 | q+1 부터 0 근접 | p+1 부터 0 근접     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91554c5",
   "metadata": {},
   "source": [
    "#### <span style='background-color: #fff5b1'> 2. 불안정 시계열</span>\n",
    "\n",
    "= 안정적 시계열 모델에 정상성 확보 과정 (차분, 계절성 차분) 추가        \n",
    "\n",
    "**ARIMA**<br>\n",
    "\n",
    "- ARIMA(p, d, q) => 차분, 변환을 통해 AR, MA, ARMA로 정상화     \n",
    "- p = AR 모형 차수 / d = 차분 / q = MA 모형 차수      \n",
    "\n",
    "**ARIMA 모형의 특수 케이스**       \n",
    "\n",
    ". | .       \n",
    "----- | -----         \n",
    "백색 잡음 | ARIMA(0,0)         \n",
    "자기 회귀 | ARIMA(p,0,0)           \n",
    "이동 평균 | ARIMA(0,0,q)        \n",
    "랜덤 워크 (이전 값에 무작위 충격만 더해져 예측 불가 & 방향성 X) | 상수 없는 ARIMA(0,1,0)        \n",
    "표류 랜덤 워크 (랜덤 워크 모델에 상수항 추가 & 방향성 O) | 상수 있는 ARIMA(0,1,0)      \n",
    "\n",
    "**SARIMA (= Seasonal ARIMA)**<br>\n",
    "\n",
    "= 시계열 데이터의 계절성을 처리 가능한 모델          \n",
    "= ARIMA(p,d,q) + 계절성 차분 -> $SARIMA(p,d,q)(P,D,Q)_m$     \n",
    "\n",
    "- p : AR 차수 / q : MA 차수      \n",
    "- P : 계절성 AR 차수 / Q : 계절성 MA 차수     \n",
    "=> ACF, PACF로 범위 추정한 뒤 그리드 서치 후 최종 선택 (AIC, BIC)       \n",
    "\n",
    "- d : 차분 정도 / D : 계절성 차분 정도         \n",
    "=> ADF로 정상성 확보 여부 판단 후 결정 (대부분 0,1 중 결정)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b93f1",
   "metadata": {},
   "source": [
    "## 다변량 시계열 분석<br>\n",
    "#### <span style='background-color: #fff5b1'> 1. VAR(Vector Autoregression) </span>\n",
    "\n",
    "= 자신의 과거 값과 다른 변수들의 과거 값을 함께 사용해 미래 예측하는 모델       \n",
    "\n",
    "- 여러 경제 지표가 서로 영향을 주고 받는 경우    \n",
    "- 금융 시장에서 여러 자산 가격이 상호작용하는 경우     \n",
    "- 변수 간 상호 의존성이 중요한 경우          \n",
    "\n",
    "**VAR 활용한 분석 방법**<br>\n",
    "\n",
    "(1) 충격 반응 함수           \n",
    "= 특정 시점에서 충격이 발생할 때, 다른 시계열에 시간에 따라 어떤 영향을 주는지 분석            \n",
    "ex. 소득에 충격이 발생했을 때, 소비 변수는 며칠 뒤 얼마나 어떤 방향으로 충격이 나타나는지        \n",
    "\n",
    "(2) 예측오차 분산 분해       \n",
    "= 어떤 시계열이 상대적으로 어떤 영향을 끼치는지의 중요도 산출            \n",
    "= 변수가 미래의 움직임을 예측하는 데 기여하는 정도 평가         \n",
    "ex. 얼마만큼의 소득 충격과 얼마만큼의 저축 충격으로 소비의 미래 값 예측에 오차가 생기는지        \n",
    "\n",
    "**장단점**<br>\n",
    "(+)        \n",
    "- 변수 간 양방향 분석         \n",
    "- 도메인 지식 없이 여러 변수 함께 예측 가능        \n",
    "- 과거 값만 사용하기 때문에 동시성 문제 없음      \n",
    "\n",
    "(-)       \n",
    "- 변수가 많으면 파라미터 폭발       \n",
    "- 장기적 관계 정보 손실 가능         \n",
    "- 상관관계와 인과관계가 다름              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39dadd6",
   "metadata": {},
   "source": [
    "## 딥러닝을 활용한 시계열 분석<br>\n",
    "#### <span style='background-color: #fff5b1'> 0. 등장 배경 </span>\n",
    "\n",
    "1. 데이터가 많으면 처리 속도가 느림         \n",
    "2. 크기가 고정된 데이터만 가능          \n",
    "3. 비선형 패턴 포착 어려움      \n",
    "\n",
    "=> 딥러닝을 통해 전통 통계 모델의 한계 극복         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a40fb",
   "metadata": {},
   "source": [
    "#### <span style='background-color: #fff5b1'> 1. RNN 계열 </span>\n",
    "\n",
    "**(1) RNN**<br>\n",
    "\n",
    "- 이전 시점의 정보를 현재로 전달하는 순환 구조의 기본 신경망         \n",
    "\n",
    "(+) 짧은~중간 길이의 시계열에 적합, 순차적 의존성이 강한 주가 및 센서 데이터에 적합 / 자기 상관이 큰 데이터에 적합       \n",
    "(-) 시계열이 매우 길면 장기 의존성 문제, 병렬 처리가 필요한 대규모 데이터에 부적합         \n",
    "\n",
    "**(2) LSTM**<br>\n",
    "\n",
    "- 게이트 메커니즘으로 장기 기억을 유지하도록 개선한 RNN      \n",
    "\n",
    "(+) 장기 의존성이 중요한 경우 적합, 중요한 과거 이벤트가 먼 미래에 영향을 주는 경우 적합            \n",
    "\n",
    "**(3) GRU**<br>\n",
    "\n",
    "- LSTM 단순화해 더 빠르게, 비슷한 성능으로 학습하는 모델       \n",
    "\n",
    "(+) 장기 의존성이 필요하지만 학습 속도가 중요한 경우 적합, 데이터가 상대적으로 적을 때, 실시간 처리가 필요할 때 적합    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2079c7",
   "metadata": {},
   "source": [
    "#### <span style='background-color: #fff5b1'> 2. Transformer 계열 </span>\n",
    "\n",
    "**Transformer**<br>\n",
    "\n",
    "- 어텐션 메커니즘으로 모든 시점을 동시에 참조해 병렬 처리하는 모델     \n",
    "\n",
    "(+) 시계열이 매우 길 때, 전역 패턴이 중요할 때, 대규모 데이터, 다변량 시계열에 적합        \n",
    "(-) 짧은 시계열, 계산 자원이 제한적일 경우 부적합 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bda53d",
   "metadata": {},
   "source": [
    "#### <span style='background-color: #fff5b1'> 3. Foundation Model </span>\n",
    "\n",
    "- 거대한 데이터로 사전 학습해 다양한 문제를 해결하는 범용 모델             \n",
    "\n",
    "**(1) LLM 기반 모델**<br>\n",
    "\n",
    "= 대규모 언어 모델의 패턴 인식 능력을 시계열에 활용하는 접근법      \n",
    "- Without Adaptation : LLM 이 이미 시계열 지식이 있다고 가정      \n",
    "- Adapt LLM : LLM을 시계열 데이터로 파인 튜닝           \n",
    "- Adapt to LLM : 시계열을 텍스트로 변환 후 LLM 활용        \n",
    "\n",
    "**(2) 자체 거대 모델**<br>\n",
    "\n",
    "= 대규모 시계열 데이터로 사전 학습해 다양한 예측 문제에 범용적으로 적용 가능한 모델           \n",
    "ex. TimeGPT, TimesFM, Moirai      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3111abf",
   "metadata": {},
   "source": [
    "#### <span style='background-color: #fff5b1'> 4. 딥러닝 모델 선택 가이드 </span>\n",
    "\n",
    "상황 | 추천 모델 | 이유         \n",
    "------- | ------- | -------      \n",
    "짧은 시계열 | 통계 모델, RNN | 데이터가 적어 과적합 방지에 단순한 모델이 유리          \n",
    "중간 길이 | LSTM, GRU | 장기 의존성 학습 가능, 적절한 복잡도             \n",
    "매우 긺 | Informer, Autoformer | 긴 시퀀스의 전역 패턴 효율적으로 학습        \n",
    "장기 의존성 중요 | LSTM, Transformer | GRU보다 먼 과거 정보 유지에 강함           \n",
    "주기 패턴 뚜렷 | Autoformer | 추세/계절성 분해로 주기 포착에 강함         \n",
    "외생 변수 많음 | TFT | 정적/동적 변수 융합 및 해석 가능       \n",
    "대규모 데이터 | Transformer 계열 | 병렬 연산으로 효율적으로 학습          \n",
    "범용 예측 필요 | foundation | 사전 학습된 지식 빠르게 적용        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
