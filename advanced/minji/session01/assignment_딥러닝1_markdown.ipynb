{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f793bd7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bfaf714",
   "metadata": {},
   "source": [
    "# 1. 인공신경망의 시작: 퍼셉트론\n",
    "\n",
    "## 1-1. 인공신경망이란? (Artificial Neural Network)\n",
    "\n",
    "### 인공신경망과 퍼셉트론\n",
    "\n",
    "- 인공신경망(ANN)은 뇌의 신경세포 뉴런의 연결 구조를 모방한 머신러닝 모델\n",
    "- 입력값에 각 가중치(weight)를 곱해 합산(가중합)한 뒤, 활성화 함수로 판단하여 출력을 만들어냄\n",
    "\n",
    "### 생물학적 뉴런과 인공신경망 비교\n",
    "\n",
    "| 생물학적 신경망 | 인공신경망 |\n",
    "| :--- | :--- |\n",
    "| 가지돌기 | 입력값(inputs) |\n",
    "| 시냅스 | 가중치(weights) |\n",
    "| 세포체의 신호 합산 | 가중 합(weighted sum) |\n",
    "| 역치(Threshold) | 활성화 함수(activation function) |\n",
    "| 축삭돌기 | 출력(Output) |\n",
    "\n",
    "### 퍼셉트론\n",
    "\n",
    "초창기 인공신경망 구조\n",
    "\n",
    "**계산 과정:**\n",
    "입력 → 가중합 → 활성화 함수 → 출력\n",
    "\n",
    "* 입력값과 가중치 곱의 합이 임계값($\\theta$)을 넘으면 1, 아니면 0을 출력\n",
    "* 활성화 함수로 계단 함수(Step), 이후에는 ReLU, Sigmoid 등도 발전\n",
    "\n",
    "**퍼셉트론 수식**\n",
    "$$\n",
    "y = \\text{Step} \\left( \\sum_{i=1}^{n} x_i w_i + b \\right)\n",
    "$$\n",
    "\n",
    "* **가중치(weight):** 각 입력의 중요도, 값이 클수록 더 영향\n",
    "* **활성화 함수(activation function):** 결과 신호를 출력 결정. 예: Step, Sigmoid, Tanh, ReLU, leaky ReLU\n",
    "* **편향(bias):** 임계값과 동일하게 신호의 기준점 역할\n",
    "\n",
    "\n",
    "\n",
    "## 1-2. 단층 퍼셉트론과 한계 (Single-Layer Perceptron)\n",
    "\n",
    "### 단층 퍼셉트론\n",
    "\n",
    "입력층, 출력층 두 층만으로 구성\n",
    "\n",
    "```python\n",
    "\n",
    "논리 게이트 구현\n",
    "\n",
    "def AND_gate(x1, x2):\n",
    "    w1, w2, b = 0.5, 0.5, -0.7\n",
    "    return 1 if x1*w1 + x2*w2 + b > 0 else 0\n",
    "def NAND_gate(x1, x2):\n",
    "    w1, w2, b = -0.5, -0.5, 0.7\n",
    "    return 1 if x1*w1 + x2*w2 + b > 0 else 0\n",
    "def OR_gate(x1, x2):\n",
    "    w1, w2, b = 0.6, 0.6, -0.5\n",
    "    return 1 if x1*w1 + x2*w2 + b > 0 else 0\n",
    "한계: XOR 게이트와 같은 비선형 분리는 실행 불가. 퍼셉트론은 입력값과 가중치의 선형결합만으로 분류함.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0728b",
   "metadata": {},
   "source": [
    "\n",
    "## 1-3. 다층 퍼셉트론 (MLP, Multi-Layer Perceptron)\n",
    "\n",
    "### 다층 퍼셉트론\n",
    "\n",
    "\n",
    "- 심층 신경망(DNN): 은닉층 2개 이상\n",
    "\n",
    "- 딥러닝: DNN 학습\n",
    "\n",
    "- 관계: 퍼셉트론 ⊂ MLP ⊂ 딥러닝 ⊂ 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2738a",
   "metadata": {},
   "source": [
    "# 2. 딥러닝 모델의 학습 방법\n",
    "\n",
    "## 2-1. 순전파와 역전파\n",
    "\n",
    "* **순전파:** 입력값으로 예측값 생성\n",
    "* **오차 계산:** 예측과 실제 비교\n",
    "* **역전파:** 오차 역으로 전달 (Chain Rule)\n",
    "* **가중치 업데이트**\n",
    "* **반복(Epoch)**\n",
    "\n",
    "**Chain Rule(연쇄법칙)**\n",
    "여러 은닉층의 미분값 곱 → 앞쪽 영향이 점점 사라짐(기울기 소실 문제)\n",
    "\n",
    "\n",
    "\n",
    "## 2-2. 손실 함수 (Loss Function)\n",
    "\n",
    "**평균 제곱 오차(MSE):** 회귀문제\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum (y - \\hat{y})^2\n",
    "$$\n",
    "\n",
    "**이진 크로스 엔트로피(Binary Cross-Entropy, BCE):** 이진분류\n",
    "$$\n",
    "\\text{BCE} = - (y \\log \\hat{y} + (1-y) \\log(1-\\hat{y}))\n",
    "$$\n",
    "\n",
    "**크로스 엔트로피(Cross Entropy, CE):** 다중분류\n",
    "$$\n",
    "\\text{CE} = - \\sum y \\log \\hat{y}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## 2-3. 활성화 함수 (Activation Function)\n",
    "\n",
    "* **계단 함수(Step):** 0/1 출력, 단층 퍼셉트론\n",
    "* **Sigmoid:** $f(x) = \\frac{1}{1 + e^{-x}}$, 0~1\n",
    "* **ReLU:** $f(x) = \\max(0, x)$, 음수 차단, 은닉층에서 자주 사용\n",
    "* **Tanh:** -1~1 값 출력\n",
    "* **Softmax:** 각 클래스별 확률 분포 계산\n",
    "\n",
    "\n",
    "## 2-4. 경사 하강법(Gradient Descent)과 옵티마이저(Optimizer)\n",
    "경사 하강법: 손실함수의 값이 최소가 되도록 가중치/편향을 효율적으로 조정함\n",
    "\n",
    "종류\n",
    "\n",
    "* **배치 경사하강법(Batch)**: 전체 데이터 사용\n",
    "\n",
    "* **확률적(SGD)**: 데이터 1개씩 업데이트\n",
    "\n",
    "* **미니배치(Mini-Batch)**: 일부 데이터 사용\n",
    "\n",
    "\n",
    "대표적 옵티마이저\n",
    "\n",
    "* **Momentum**: 이전 기울기 방향의 관성 효과 반영\n",
    "\n",
    "* **RMSProp**: 각 방향별 학습률 자동 조절\n",
    "\n",
    "* **Adam: RMSProp+Momentum**, 가장 많이 쓰이는 방식\n",
    "\n",
    "\n",
    "## 2-5. 데이터 증강 & 전이학습\n",
    "* **데이터 증강(Data Augmentation)**\n",
    "원본 데이터의 다양한 변형을 학습에 사용(모델 일반화, 과적합 완화, 프라이버시 강화)\n",
    "\n",
    "* **전이학습(Transfer Learning)**\n",
    "사전훈련(Pre-trained) 모델의 특징을 활용해 새로운 문제에 빠르게 적용(Fine-tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe16297",
   "metadata": {},
   "source": [
    "# 3. 합성곱신경망(CNN, Convolutional Neural Network) 구조\n",
    "\n",
    "### 이미지 입력 데이터 기본\n",
    "\n",
    "* **흑백:** H x W 2차원 배열\n",
    "* **컬러(RGB):** H x W x 3\n",
    "\n",
    "### CNN 계층 핵심\n",
    "\n",
    "1.  **입력층**\n",
    "2.  **Convolution Layer:** 필터(kernel)로 특징 추출\n",
    "3.  **Pooling Layer:** 공간 크기 압축, 노이즈 제거\n",
    "4.  **Flatten:** 다차원 feature map을 1D로 변환\n",
    "5.  **Fully Connected Layer:** 분류 등 최종 출력\n",
    "\n",
    "\n",
    "\n",
    "## 3-1. MLP vs CNN 비교\n",
    "\n",
    "| 항목 | MLP | CNN |\n",
    "| :--- | :--- | :--- |\n",
    "| **구조** | 완전연결(1D 벡터화) | Conv+Pool 반복, 공간 정보 유지 |\n",
    "| **파라미터 수** | 매우 많음 | 부분연결, 효율적 |\n",
    "| **위치 변화 대응** | 민감 | Pooling으로 완화 |\n",
    "| **공간정보** | flatten 단계에서 손실 | convolution/Pooling단계에서 보존 |\n",
    "\n",
    "\n",
    "\n",
    "## 3-2. Convolution & Pooling\n",
    "\n",
    "* **Convolution:** 필터(커널)가 이미지를 슬라이딩하며 특정 패턴 추출\n",
    "* **Padding:** 경계 정보 손실을 막기 위한 주변에 0 채우기\n",
    "* **Stride:** 필터 이동 간격(크면 특징 추출량 감소, 속도 증가)\n",
    "* **Pooling:**\n",
    "    * **Max pooling:** 구역 최댓값\n",
    "    * **Average pooling:** 구역 평균값\n",
    "    * 주로 Max pooling 사용(차원 축소, 계산효율↑, 노이즈↓, 과적합↓)\n",
    "\n",
    "\n",
    "\n",
    "## 3-3. CNN 대표 아키텍처\n",
    "\n",
    "* **AlexNet (2012):** GPU 기반, ReLU, Dropout 적용, 대규모 이미지 분류\n",
    "* **VGGNet (2014):** 3x3 필터 반복, 층을 깊게 쌓아 전이학습에 적합\n",
    "* **ResNet (2015):** Residual/Skip connection으로 기울기 소실 문제 극복, 깊은 모델 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6158cc3",
   "metadata": {},
   "source": [
    "# 4. 이미지 딥러NING 주요 응용\n",
    "\n",
    "## 4-1. 이미지 분류 (Image Classification)\n",
    "\n",
    "픽셀 데이터 기반 분류, CNN, AlexNet, VGG, ResNet, ViT 등 활용\n",
    "\n",
    "\n",
    "| 모델명 | 특징 요약 | 주의사항 |\n",
    "| --- | --- | --- |\n",
    "| **AlexNet** | 비교적 단순한 구조, 초기 CNN 모델들 | 작은 데이터셋이나 학습 개념 설명용으로 적절 |\n",
    "| **VGG** | 더 깊은 구조, 복잡한 블록 구조 적용 | 계산량 증대, 메모리 요구 높음 |\n",
    "| **ResNet** | Residual 연결 (skip connections) → 매우 깊은 네트워크 가능 | 과적합 주의, batch size / regularization 조절 필요 |\n",
    "| **Vision Transformer (ViT)** | Transformer 구조 응용 → 패치 기반 입력 처리 | 이미지와 순차 처리 모델의 결합, 대규모 데이터 필요 |\n",
    "\n",
    "## 4-2. 객체 탐지 (Object Detection)\n",
    "\n",
    "이미지 내 여러 객체의 클래스 및 위치(bounding box) 추출\n",
    "대표 모델: YOLO, Faster R-CNN, SSD\n",
    "\n",
    "\n",
    "\n",
    "## 4-3. 이미지 캡셔닝 (Image Captioning)\n",
    "\n",
    "CNN 특징 추출 + RNN/Attention 네트워크로 자연어 설명 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd86cad",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
