{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d140305f",
   "metadata": {},
   "source": [
    "다음 내용이 필수적으로 들어가야 합니다.\n",
    "\n",
    "- 머신러닝의 종류\n",
    "- 선형회귀 (단순, 다중선형회귀)\n",
    "- 경사하강법\n",
    "- 다중공선성\n",
    "- 규제선형모델\n",
    "- 모델평가방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e9a33",
   "metadata": {},
   "source": [
    "# 머신러닝과 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db1579",
   "metadata": {},
   "source": [
    "## 1. 머신러닝과 모델링\n",
    "\n",
    "머신러닝 : 인공지능의 한 분야로, 모델을 이용해서 새로운 데이터를 예측 및 결정을 내리도록 하는 기술\n",
    "\n",
    "-> **데이터를 통해 학습**하고, 새로운 입력을 받았을 때 이를 **학습한 내용을 기반으로 예측** 하는 것이 목표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f9b8a",
   "metadata": {},
   "source": [
    "### 머신러닝의 종류\n",
    "\n",
    "1. 지도 학습 : 정답이 있는 데이터를 기반으로 진행하는 학습.\n",
    "    * 정답들을 기반으로 예측값을 학습 데이터에 존재하는 정답을 기준으로 진행\n",
    "    * 예시 : 회귀, 분류\n",
    "\n",
    "2. 비지도 학습 : 정답이 없는 데이터를 기반으로 진행하는 학습\n",
    "    * 기계가 알아서 데이터를 분류하도록 함\n",
    "    * 예시 : 군집화\n",
    "    * 요즘와서 사장됨 -> 정답을 찾는 것이 사실상 불가능하기 때문 (너무 많은 시간 소모), 예외에 너무 취약함 (기린 닮은 고양이에 좋아죽음)\n",
    "\n",
    "3. 강화학습\n",
    "    * 즉각적인 피드백이 아닌 시간을 가지는 피드백 (결과에 대한 점수 제공 등) 을 이용한 학습\n",
    "    * 예시 : 알파고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dccaf93",
   "metadata": {},
   "source": [
    "### 지도 학습: 회귀와 분류\n",
    "\n",
    "**지도 학습**\n",
    "* 인풋 값에 대응하는 정답을 함께 학습 데이터로 제공 (입력 정보가 이럴 때 정답이 이거였어~)\n",
    "* 진행 순서\n",
    "    1. 먼저 입력 값과 이를 통해 출력해야 할 값을 나누고 (원자번호 -> 에너지)\n",
    "    2. 70% 정도를 훈련 셋으로 해서 모델에 학습시킴\n",
    "    3. 30% 정도의 실험 셋의 입력 값을 준 뒤에 출력 값을 예측시키고 실제와 비교\n",
    "    4. 더 잘 맞게 supervise\n",
    "    *  훈련 vs 실험? : 훈련은 학습, 실험은 예측 성능 확인임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2cb913",
   "metadata": {},
   "source": [
    "**회귀와 분류**\n",
    "* 회귀 : 데이터에 가장 맞는 함수를 찾는다 (함수가 최대한 데이터의 경향성을 맞추는 것이 목표)\n",
    "* 분류 : 여러 가지의 데이터를 축들의 값들을 통해 종류를 판별할 수 있도록 한다\n",
    "\n",
    "--> 즉, 회귀는 데이터 값이 있을 선을 긋는 거고, 분류는 데이터들을 땅나누기를 해주는 선을 긋는 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f794dc",
   "metadata": {},
   "source": [
    "# 2. 회귀(Regression)와 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b74c31c",
   "metadata": {},
   "source": [
    "## 1. 회귀란? \n",
    "\n",
    "* 데이터에서 독립 변수에 의한 종속 변수의 형태를 보고 패턴을 찾아 추후에 예측에 사용하자\n",
    "* 연속적인 숫자를 다룰 때 사용 (사실 이래야 함수를 만들 수가 있으니)\n",
    "\n",
    "## 2. 회귀의 종류\n",
    "\n",
    "* 선형회귀, 비선형회귀, 릿지회귀, 라쏘회귀, 다항회귀 등 다양한 방법이 존재\n",
    "* 오늘은 선형회귀!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f200f9",
   "metadata": {},
   "source": [
    "## 3. 선형 회귀\n",
    "\n",
    "* 말그대로 종속 변수(y값)들을 독립변수 (x값)에 대해 선형적인 관계가 있을 거라고 보고 선형적인 그래프를 찾는 거\n",
    "* 근데 여기서 기울기만 파라미터이고, b값 (절편)은 파라미터가 아닙니다\n",
    "* 기본 가정 : 선형성 (선형적이겠지), 독립성 (관측이 서로 영향 X), 등분산성 (독립이 같은 종속이 바뀌면 안됨), 정규성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1fdc89",
   "metadata": {},
   "source": [
    "### 선형 회귀의 종류\n",
    "* 단순 : 차원이 하나 \n",
    "* 다중 : 차원이 하나보다 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d3873",
   "metadata": {},
   "source": [
    "### 단순선형회귀분석\n",
    "\n",
    "* 종속변수가 하나의 독립변수에만 영향읆 받음 -> 일차함수를 구하면 되는 과정임!\n",
    "--> 내용은 쉬운데, 그럼 이제 어떤 일차함수가 가장 아름다운 형태인건데?\n",
    "\n",
    "--> **잔차를 줄이자! (cf. 오차는 잘못된 값, 잔차는 실제의 값!)**\n",
    "\n",
    "**최소제곱법**\n",
    "\n",
    "* 잔차(함수값과 대응되는 실제 값의 차이겟죠)의 제곱들의 합이 최소가 되는 선 찾기\n",
    "\n",
    "--> 왜 제곱? 1. 양/음수 2. 차이 크면 더 가중치 업 3. 미분 가능한 형태(이후 필요함!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e7ca42",
   "metadata": {},
   "source": [
    "최소제곱법을 쓰기 어려운 경우, 경사하강법을 사용  \n",
    "\n",
    "* 최소제곱법을 쓰기 어려운 경우\n",
    "    * 함수가 닫힌 상태\n",
    "    * 미분 계수를 구하기 어려운 경우\n",
    "    * a를 구하는 것보다 경사하강이 쉬워보일 때\n",
    "    * 데이터 양이 너무 많을 때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a1351c",
   "metadata": {},
   "source": [
    "**경사하강법**\n",
    "\n",
    "일단 단순선형회귀분석이 목표인데, 최소제곱법의 결론 + 계산 과정의 간소화!\n",
    "\n",
    "0. 무엇으로 이루어져 있는가?\n",
    "\n",
    "- 목적함수 : 최적화하려는 대상을 수학적으로 표현하는 함수. 해결해야 하는 문제 자체를 공식으로 나타낸 것임\n",
    "        이 목적 함수의 값이 최대화 혹은 최소화하는 파라미터를 찾는 것이 목표!\n",
    "\n",
    "- 손실함수 : 한 개의 데이터에서 오차가 얼마나 큰지 확인하는 함수\n",
    "\n",
    "- 비용함수 : 평균적인 손실을 측정하는 함수. 상황에 따라 사용할 함수가 달라질 것임. (단순히 평균값 쓰는 게 아님)\n",
    "        -> 대부분 비용학습을 최소화 하는 것이 목표인데 이럴 때에는 비용함수가 목적함수가 될 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86d0df",
   "metadata": {},
   "source": [
    "### 1. 손실함수\n",
    "\n",
    "* 잔차들을 제곱한 뒤에 이를 합하는 형태. 근데 우리는 현재 함수를 모르니까? W 와 b를 모른다. 따라서, W 와 b가 변수인 함수가 완성될 것이다.\n",
    "* 그 중에서 E가 최소인 지점을 찾는 것이 최종 목표이다!\n",
    "\n",
    "**원리**\n",
    "* 점에서의 기울기를 이용해서 점이 이동할 방향을 정하고, 지속적인 이동을 하다 기울기가 0이 되는 구간에서 멈춘다\n",
    "\n",
    "### 2. 학습률\n",
    "* 이동하는 방향을 정했으니, 이동하는 정도를 정해야 한다 -> 학습률\n",
    "* 학습률이 너무 작으면? 수렴 지점 찾는 데에 시간이 너무 오래 걸림\n",
    "* 너무 크다면? 못찾는다. 수렴 포인트를 넘어설 것이기 때문\n",
    "* 따라서, 적당한 크기의 학습률을 찾는 것이 \n",
    "\n",
    "### 3. local minima 문제\n",
    "* 비용 함수가 하나의 골짜기만 가지면 생기지 않을 문제이지만, 여러개의 골짜기를 가져버린다면?    \n",
    "* 목적지에 도달하기 전에 다른 골짜기에 갖혀버릴 가능성이 존재한다.\n",
    "\n",
    "### 4. 해결법 - 모멘텀\n",
    "* 기울기에 관성을 부여해서 이동하려는 방향을 정해주는 방법\n",
    "* 관성을 부여한다? : 이전 기울기를 생각하는 것! 이전의 기울기와 이후의 기울기를 비교해서 어디까지 지점을 잡을지 결정하는 방법임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a2028c",
   "metadata": {},
   "source": [
    "## 다중선형회귀분석\n",
    "\n",
    "--> 하나의 독립변수가 아닌 두개 이상의 독립변수에 의해서 종속변수의 값이 결정이 될 때 사용하는 분석 방법.\n",
    "\n",
    "--> 독립변수가 2개일 때는 3차원 공간의 평면 함수로 표현할 수 있고, 최소제곱법을 통해 함수를 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94607ca4",
   "metadata": {},
   "source": [
    "### 1. 다중공선성\n",
    "\n",
    "* 두 독립변수를 사용할건데, 두 독립변수 사이에 연관이 있어버리는지 확인해야한다\n",
    "* 만약 게임을 좋아하는 사람 여부를 비교할건데 성별 여부와 군필 여부 이런 식으로 해버리면...? 두 독립변수가 너무 연결되어있음 (남성이면 군필 가능성이 높다)\n",
    "\n",
    "* 어떻게 확인하는가?\n",
    "    1. 상관계수로 확인하기 (히트맵, corr 함수, pairplot 등)\n",
    "    2. VIF 지수 -> R^2 를 사용해서 계산하는 방법\n",
    "    \n",
    "**그렇다면 어떻게 해결?**\n",
    "1. 변수 제거\n",
    "* 상관관계가 클 변수를 제거하면 상관이 있을 변수가 없겟죠?\n",
    "\n",
    "2. 변수 변환\n",
    "* 두 변수 사이에서 관계에 따라 새로운 변수로 변환하는 방법.\n",
    "\n",
    "3. 규제 선형 모델 활용\n",
    "* 릿지, 라쏘 등의 방법을 이용해서 모델의 복잡도 차체를 줄인다.\n",
    "\n",
    "4. PCA (주성분 분석)\n",
    "* **차원을 축소** 하는 것이 핵심이다!\n",
    "* 여러가지 독립변수들이 있으면, 독립변수의 개수가 결국 차원이다.\n",
    "* 독립변수와 데이터 사이의 관계를 본 다음에, 크게 상관이 없는 변수들은 없앤다\n",
    "* 변수들 자체들의 카테고리를 분류한 다음 더 큰 차원들을 찾아내는 것이 핵심이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d184f9",
   "metadata": {},
   "source": [
    "# 규제선형모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7da64",
   "metadata": {},
   "source": [
    "**규제선형모델**\n",
    "\n",
    "오버피팅이 일어나지 않도록 규제를 가하는 모델이다\n",
    "\n",
    "오버피팅 -> training set을 과도하게 맞추려고 하다 보면 모델의 파라미터도 매우 많아지고, test set과 맞지 않을 가능성이 매우 높아짐\n",
    "\n",
    "선형 모델에서는 최소제곱법 등을 통해 잔차를 줄이는 방법으로 진행되는데, 회귀 계수를 매우 크게 만듬. 이에 따라 특정 독립 변수에 과하게 의존하게 됨\n",
    "\n",
    "--> 회귀 계수 값도 커지지 않으면서 잔차 오류를 최소화 해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44acef",
   "metadata": {},
   "source": [
    "* 규제선형모델의 종류\n",
    "    * L2 : 회귀계수의 제곱에 대해 페널티 부과\n",
    "    * L1 : 회귀계수의 절댓값에 대한 페널티\n",
    "    * 둘 합쳐서 엘라스틱넷 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4613e7f",
   "metadata": {},
   "source": [
    "### 릿지 회귀 (L2)\n",
    "\n",
    "* 제곱에 대한 페널티 --> 큰 회귀계수에서 강한 패널티 부과\n",
    "* 모든 계수의 크기가 작아지긴 하지만 완전히 사라지진 않는다. (작은 애들에겐 작게 들어가니까)\n",
    "\n",
    "--> 모든 변수를 유지할 수 있음, 과적합 방지도 가능\n",
    "\n",
    "### 라쏘 회귀 (L1)\n",
    "* 절댓값에 대한 패널티 --> 모든 회귀계에 같은 패널티 부과\n",
    "* 이에 따라 작은 값들은 아예 삭제될 수 있다\n",
    "\n",
    "--> 비중이 낮은 변수들을 삭제하고 중요한 변수들만 남긴다!\n",
    "\n",
    "### 엘라스틱넷 (L1 + L2)\n",
    "* 일단 L1 방식으로 아예 필요없는 변수 제거\n",
    "* 이후 L2 방식으로 남은 변수들 중 상관관계가 높은 변수와 낮은 변수들 차이 확실하게!\n",
    "\n",
    "\n",
    "따라서 **변수 선택의 필요 유무** 와 **예측 변수의 수** 에 따라 규제선형모델을 선택하면 될 것이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc0357",
   "metadata": {},
   "source": [
    "# 모델 평가 방법\n",
    "\n",
    "생각에 따라 만든 모델이 과연 좋은 성능을 내고 있는가? 평가가가 필요하다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37047f9",
   "metadata": {},
   "source": [
    "## 성능 평가 지표\n",
    "\n",
    "### 1. MSE\n",
    "\n",
    "* 실제 값이랑 예측 값 차이의 제곱에 대한 값들의 평균을 구함\n",
    "* 역시 제곱을 사용하니까, 차이가 큰 값에 큰 무게가 쏠린다. --> 이상치에 로버스트하지않음\n",
    "\n",
    "### 2. MAE\n",
    "* 실제 값이랑 예측 값 차이의 절댓값에 대한 값들의 평균을 구함\n",
    "* 크기에만 의존하고, 이에 따른 무게가 더 더해지지는 않는다. --> 이상치에 로버스타하다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4449368",
   "metadata": {},
   "source": [
    "## 변수 유의성 평가\n",
    "\n",
    "### 1. t 검정\n",
    "* 독립변수의 회귀계수가 유믜미한지 검정한다. 이에 귀무가설과 대립가설을 세운다\n",
    "    * 귀무 : 회귀계수 == 0 --> 종속변수는 독립변수의 영향을 받지 않은다\n",
    "    * 대립 : 회귀계수 != 0 --> 종속병수는 독립변수의 영향을 받는다\n",
    "\n",
    "* 과정\n",
    "    1. t값 계산\n",
    "    2. P value 계산\n",
    "    3. 해석 진행\n",
    "        * 회귀계수가 0이면 귀무가설이 맞음\n",
    "        * pvalue가 작으면 귀무가설 반박이 커짐, 즉 대립가설이 더 신빙성 잇음, 즉 종속변수는 독립변수의 영향을 받음\n",
    "        * t값이 크면 귀무가설을 기각할 가능성이 높다.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
