{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec64f7f",
   "metadata": {},
   "source": [
    "# 0️⃣ 데이터 분석 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf927109",
   "metadata": {},
   "source": [
    "## 데이터 수집\n",
    "\n",
    "다양한 형식의 **데이터를 수집**합니다. (정형 / 비정형 / 반정형 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6ac01",
   "metadata": {},
   "source": [
    "## 데이터 탐색(EDA)\n",
    "\n",
    "**다양한 각도에서 (도표, 그래프, 통계) 수집한 데이터의 특징을 파악**합니다.\n",
    "\n",
    "ex) 요리로 비유하자면, 본격적인 취사에 들어가기 전에 앞 단계에서 모은 재료(데이터)들의 맛, 식감, 영양 등 특성을 파악하는 단계라고 할 수 있습니다.\n",
    "\n",
    "데이터의 특성, 패턴, 관계를 파악하고 시각화 하면서 데이터를 이해하고 전처리, 모델링 등의 후속 분석에 대한 방향성을 제시하는 중요한 단계입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf33006",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "**데이터를 분석(모델링)에 적합한 형태로 손질하는 과정**을 데이터 전처리라고 합니다.\n",
    "\n",
    "이상치(너무 튀는 값) 제거, 결측치(값 없음) 처리, 노이즈 제거 등의 작업이 수행됩니다.\n",
    "\n",
    "데이터의 왜곡을 피하고 데이터의 신뢰도를 높이는 과정이며, 반복적으로 수행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca69238",
   "metadata": {},
   "source": [
    "## 데이터 모델링\n",
    "\n",
    "데이터로부터 **유용한 정보를 추출하기 위해 모델을 구축**하는 단계입니다.\n",
    "\n",
    "예측, 분류, 군집화 등의 목적에 따라 모델을 선택하고 학습시키는 과정을 의미합니다.\n",
    "\n",
    "ex) 완성된 요리를 만드는 과정!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a643f",
   "metadata": {},
   "source": [
    "오늘의 핵심은 EDA에서 전처리까지!\n",
    "- EDA: 데이터를 여러 가지 방식으로 파악하는 과정\n",
    "- 전처리: 데이터를 적절한 방식으로 손질하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad6632",
   "metadata": {},
   "source": [
    "1️⃣ EDA의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174d04d",
   "metadata": {},
   "source": [
    "데이터 분석(모델링)을 위해 데이터를 여러 가지 방식으로 파악하는 모든 과정을 EDA라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e30716",
   "metadata": {},
   "source": [
    "<aside>\n",
    "👀 EDA\n",
    "\n",
    "- 시각화 같은 도구를 통해서 패턴을 발견하거나\n",
    "- 데이터의 특이성을 확인하거나\n",
    "- 통계와 그래프(혹은 시각적 표현)으로 가설을 검정하는 과정 등을 통해\n",
    "\n",
    " **주어진 데이터에 대해 알아보는 것**을 EDA라고 한다.\n",
    "\n",
    "</aside>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86914b64",
   "metadata": {},
   "source": [
    "EDA는 Exploratory Data Analysis의 약자로, **탐색적 데이터 분석 과정**을 일컫는 말입니다.\n",
    "\n",
    "데이터를 분석하고 결과를 내는 과정에 있어서 지속적으로 해당 데이터에 대한 **‘탐색과 이해’**를 기본으로 가져야 한다는 것을 의미합니다.\n",
    "\n",
    "EDA 과정에서 데이터를 잘못 해석하고, 문제를 올바르게 정의하지 못한다면 향후 분석 과정에서 큰 난항을 겪게 되므로, EDA는 매우 중요한 단계입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06436b",
   "metadata": {},
   "source": [
    "(1) EDA 대상 (일변량/다변량)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683aa09",
   "metadata": {},
   "source": [
    "하나의 변수를 살펴볼 것인가, 여러 변수 간의 관계를 살펴볼 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0ee48",
   "metadata": {},
   "source": [
    "### **Univariate(일변량)**\n",
    "\n",
    "EDA를 통해 한 번에 파악하려는 **변수가 한 개**.\n",
    "\n",
    "**데이터를 설명**하고 그 안에 **존재하는 패턴을 찾는 것**이 주요 목적."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1b97c",
   "metadata": {},
   "source": [
    "### **Multi-variate(다변량)**\n",
    "\n",
    "EDA를 통해 한 번에 파악하려는 **변수가 여러 개**.\n",
    "\n",
    "**여러 변수들 간의 관계**를 보는 것이 주요 목적.\n",
    "\n",
    "변수를 동시에 확인하기 전에 개별 데이터를 먼저 파악하는 것이 오류에 대처하기 용이하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501cf7b",
   "metadata": {},
   "source": [
    "## (2) EDA 종류 (시각화/비시각화)\n",
    "\n",
    "<aside>\n",
    "💡 **시각적으로 파악할 것인가, 수치적으로 파악할 것인가?**\n",
    "\n",
    "</aside>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b109ccb7",
   "metadata": {},
   "source": [
    "Graphic(시각화)\n",
    "\n",
    "차트 혹은 그림 등을 이용하여 데이터를 확인하는 방법. 아래에서 더 자세히 다룰 예정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b9afc5",
   "metadata": {},
   "source": [
    "Non-Graphic(비시각화)\n",
    "\n",
    "그래픽적인 요소를 사용하지 않고 주로 Summary Statistics를 통해 데이터를 확인하는 방법.\n",
    "\n",
    "→ 데이터를 그래프로 표현하게 되면 한눈에 데이터를 파악할 수 있으므로 graphic한 EDA를 통해 대략적인 형태를 파악할 수 있다. 반면에 정확한 값이 필요하다면 non-graphic한 EDA를 통해 파악할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3dcf2",
   "metadata": {},
   "source": [
    "(3) EDA 유형\n",
    "\n",
    "EDA 대상과 종류에 따라 EDA 유형이 구분됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163447a",
   "metadata": {},
   "source": [
    "- **Uni-Non Graphic(일변량 비시각화) :** 주어진 데이터의 Distribution을 확인하는 것이 주목적.\n",
    "- **Uni-Graphic(일변량 시각화)** : 주어진 데이터를 전체적으로 살펴보는 것이 주목적.\n",
    "- **Multi-Non Graphic(다변량 비시각화)** : 주어진 둘 이상의 변수 간 관계를 확인하는 것이 주목적.\n",
    "- **Multi-Graphic(다변량 시각화)** : 주어진 둘 이상의 변수 간 관계를 전체적으로 살펴보는 것이 주목적."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8144e56",
   "metadata": {},
   "source": [
    "## 2️⃣ 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5e0c7",
   "metadata": {},
   "source": [
    "## 데이터 읽기/쓰기\n",
    "\n",
    "데이터를 분석하려면 **데이터**가 필요하겠죠? \n",
    "\n",
    "작업 공간에 **데이터를 불러오는 것**이 **읽기** 새로운 **데이터를 만드는 것**이 **쓰기**에 해당합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c6089",
   "metadata": {},
   "source": [
    "### **(1) 절대경로와 상대경로**\n",
    "\n",
    "데이터를 읽어오는 형태를 다음과 같은데요, 여기서 파일경로를 나타내는 방법에는 절대 경로와 상대 경로 두 가지가 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a475e",
   "metadata": {},
   "source": [
    "- **절대 경로**\n",
    "\n",
    "**처음(root 파일)부터 시작하여 목적지까지 전체적인 경로(URL),** 해당 파일까지의 모든 경로.\n",
    "\n",
    "ex) C:\\Users\\사용자 이름\\OneDrive\\Desktop\n",
    "\n",
    "- **상대 경로**\n",
    "\n",
    "**현재 작업하고 있는 디렉터리를 기준**으로 상하위 디렉터리와 같이 상대적으로 표현되는 경로.\n",
    "\n",
    "- **./ : 현재 디렉터리**\n",
    "- ../ : 상위 디렉터리\n",
    "- / : 최상위(루트) 디렉터리\n",
    "- 현재 작업 디렉터리가 [`/content/drive/MyDrive/MyPythonFiles/TextFiles](https://colab.research.google.com/drive/14Jsf2hqp0cnovUrAw201GoSp5dohN0hQ#)/A` 인 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3d19c",
   "metadata": {},
   "source": [
    "### **(2) 데이터 입출력**\n",
    "\n",
    "데이터 파일의 형식에 따라 **데이터를 읽고(Reader) 쓰는 (Writer) 함수가 다르다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78104b50",
   "metadata": {},
   "source": [
    "| File Format | Reader | Writer |\n",
    "| --- | --- | --- |\n",
    "| CSV | `read_csv` | `to_csv` |\n",
    "| JSON | `read_json` | `to_json` |\n",
    "| HTML | `read_html` | `to_html` |\n",
    "| MS EXCEL | `read_excel` | `to_excel` |\n",
    "| SQL | `read_sql` | `to_sql` |\n",
    "\n",
    "→ 이중에서 CSV와 EXCEL 파일을 많이 다루게 됩니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c813fa",
   "metadata": {},
   "source": [
    "### (3) **CSV와 EXCEL**\n",
    "\n",
    "- **CSV 파일**: comma separated value의 약자로 데이터를 **쉼표(,)로 구분**하고 있는 텍스트 파일.\n",
    "\n",
    "데이터의 **크기가 작고 압축이 용이**하기 때문에 **가장 널리 사용되는 데이터 형식**입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4c8d3",
   "metadata": {},
   "source": [
    "- **EXCEL 파일**: 행과 열이 데이터프레임의 행, 열로 일대일 대응.\n",
    "    - 여러 개의 시트로 구성된 데이터를 읽을 때 불러올 특정 시트를 설정할 수 있음.\n",
    "        \n",
    "        ex) sheet_name='Sheet 2'\n",
    "        \n",
    "    - 여러 sheet를 불러올 때는 list로 받으면 됨.\n",
    "        \n",
    "        ex) sheet_name=['Sheet 1', 'Sheet 2']\n",
    "\n",
    "\n",
    "→ 두 형식 모두 pandas를 통해 DataFrame 형식으로 읽어올 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d467ae1",
   "metadata": {},
   "source": [
    "## 데이터셋 파악하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269248b",
   "metadata": {},
   "source": [
    "### (1) 데이터 프레임 보기\n",
    "\n",
    "`head(n)`: 데이터 프레임 상위 n개 데이터 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1f8c6",
   "metadata": {},
   "source": [
    "### (2) 데이터 변수 확인\n",
    "\n",
    "📌 변수 = 데이터 프레임의 column = feature\n",
    "\n",
    "<aside>\n",
    "❓ **변수 정의 확인**\n",
    "\n",
    "어떤 정보를 가지는 변수인지 확인\n",
    "\n",
    "**변수 유형 확인** \n",
    "\n",
    "질적·범주형(Categorical Data)과 양적·수치형(Numerical Data)으로 구분\n",
    "\n",
    "**변수 데이터 형식(자료형) 확인**\n",
    "\n",
    "날짜, 수치, 텍스트, 이미지 등의 구분\n",
    "\n",
    "</aside>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e589f56a",
   "metadata": {},
   "source": [
    "**타이타닉 데이터셋 변수 정의 확인**\n",
    "survived: 생존 여부\n",
    "\n",
    "pclass:Passenger Class, 승객 등급\n",
    "\n",
    "name: 승객 이름\n",
    "\n",
    "sex: 승객 성별\n",
    "\n",
    "age: 승객 나이\n",
    "\n",
    "sibsp: 동승한 형제 또는 배우자 수\n",
    "\n",
    "parch: 동승한 부모 또는 자녀 수\n",
    "\n",
    "ticket: 티켓 번호\n",
    "\n",
    "fare: 승객 지불 요금\n",
    "\n",
    "cabin: 선실 이름\n",
    "\n",
    "embarked: 승선항(C=쉘 부르크, Q=퀸즈타운, S=사우스 햄튼)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd5c1a",
   "metadata": {},
   "source": [
    "**타이타닉 데이터셋 변수 유형 확인**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc1ab0",
   "metadata": {},
   "source": [
    "| **범주형(Categorical)** : 몇 개의 범주로 나누어진 데이터 | **수치형(Numerical) :** 숫자로 표현되는 데이터 |\n",
    "| --- | --- |\n",
    "| **명목형(Nominal)** : 성별, 성공여부, 혈액형 등 순서와 상관없이 이름만 의미를 부여할 수 있는 경우 | **이산형(Discrete)** : 이산적인 값으로, 정수 단위로 떨어져 셀 수 있는 데이터  |\n",
    "| **순서형(Ordinal)** : 범주형 데이터 중 어떤 기준에 따라 순서에 의미를 부여할 수 있는 경우 | **연속형(Continuous)** : 연속적인 값을 갖는 데이터로 신장, 체중 등  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8daef",
   "metadata": {},
   "source": [
    "타이타닉 데이터셋 변수 데이터 형식(자료형) 확인 - df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115bd29d",
   "metadata": {},
   "source": [
    "### (3) 데이터 분포 확인\n",
    "\n",
    "단변수 분석은 원시 데이터(raw data)의 평균값, 최빈값, 중간값 등 변수들의 분포를 산포도, 박스 플롯, 히스토그램 등의 그래프를 통해 단변수, 즉 하나의 데이터 분포를 확인해 분석할 수 있는 방법입니다. 원시 데이터 분포의 확인을 통해 **전처리 아이디어**를 얻을 수 있습니다. 시각화 파트에서 더 자세히 알아봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a3d1e",
   "metadata": {},
   "source": [
    "## 3️⃣ 전처리\n",
    "\n",
    "**데이터 전처리**: 데이터를 **분석에 적합한 형태**로 만드는 과정\n",
    "\n",
    "머신러닝 등 데이터 분석의 정확도는 데이터의 품질에 의해 좌우됩니다. 따라서 데이터 품질을 높이기 위해 이상값, 결측값, 노이즈를 수정하고, 분석 목적에 맞게 변형하는 과정이 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace6ba54",
   "metadata": {},
   "source": [
    "## 결측값 처리\n",
    "\n",
    "**결측값** = 데이터 수집 과정에서 측정되지 않거나 누락된 데이터\n",
    "\n",
    "변수의 결측값이 있는 상태로 데이터 분석 모델을 만들면 변수 간의 관계가 왜곡될 수 있어 모델의 정확성이 떨어지게 되고, 이는 데이터의 시각적 표현에도 문제를 일으킬 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e5955e",
   "metadata": {},
   "source": [
    "### (1) 결측값 확인\n",
    "\n",
    "데이터프레임 상에서 `NaN`, `?`, `0` 등의 값으로 나타나 있는 결측값을 확인합니다.\n",
    "\n",
    "이때 0의 경우에는 **진짜 0의 값으로 측정**된 건지, **결측되어 0으로 표기된 것**뿐인지 잘 살펴봐야겠죠\n",
    "\n",
    "🐼 결측값 관련 다양한 pandas function ~~\n",
    "\n",
    "- `info()` :  데이터 프레임의 요약 정보를 출력 → 각 열에 속하는 유효한 값(NaN 값이 아닌 non-null)의 개수를 보여줌\n",
    "- `value_counts(dropna=False)` : 각 열의 결측값을 포함한 전체 데이터 확인 가능\n",
    "- `isnull()` : 누락 데이터면 True, 유효한 데이터면 False 반환\n",
    "    \n",
    "    **→** `df.isnull().sum()` 의 형식으로 자주 사용!\n",
    "    \n",
    "- `notnull()` : 유효 데이터면 True, 누락 데이터면 False 반환\n",
    "- `replace()` : 결측값이 NaN이 아니라 ‘0’ 이나 ‘?’ 등으로 입력되기도 하는데, 이때 replace를 활용하여 NaN으로 변환할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de74866",
   "metadata": {},
   "source": [
    "### (2) 결측값 처리\n",
    "\n",
    "1. **삭제**\n",
    "    \n",
    "    : 데이터가 있는 행 또는 열을 삭제\n",
    "\n",
    "    dropna(): DataFrame내의 결측값이 포함된 레이블을 제거하는 매서드\n",
    "\n",
    "    - <삭제 기준> `axis = 0` & `axis = 1`\n",
    "    - `axis = 0` : **결측값이 있는 행 삭제 -** 분석 대상의 관측값(레코드)을 제거 << default 값\n",
    "    - `axis = 1` : **결측값이 있는 열 삭제 -** 분석 대상이 갖는 특성(변수)를 삭제\n",
    "    \n",
    "- <삭제 조건> `how = ‘any’` & `how = ‘all’`\n",
    "    - `how = ‘any’` : 하나라도 결측값 있으면 삭제 << default 값\n",
    "    - `how = ‘all’` : 모든 값이 결측값일때만 삭제\n",
    "    \n",
    "- <특정 column(열) 기준으로 삭제> `subset = [’column명’]`\n",
    "    - `axis = 0` (행 삭제) 일때만 적용가능\n",
    "        \n",
    "        ```python\n",
    "        df.dropna(subset=['A', 'B'])\n",
    "        ```\n",
    "        \n",
    "- <원본 데이터 변경 여부> `inplace = False` & `inplace = True`\n",
    "    - `inplace = False` : 반영한 내용을 새로운 DataFrame으로 반환 << default 값\n",
    "    - `inplace = True` : 원본 DataFrame 자체를 변경하여 반영\n",
    "\n",
    "    **🗑️ 삭제 시 주의할 점** \n",
    "\n",
    "삭제는 결측값이 **무작위**로 발생한 경우에 사용합니다. 결측값이 무작위로 발생한 것이 아닌데 관측치를 삭제한 데이터를 사용할 경우, 왜곡된 모델이 생성될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15a461",
   "metadata": {},
   "source": [
    "2. **대체**\n",
    "    \n",
    "    : 결측값을 다른 값으로 대체\n",
    "\n",
    "    → 평균값**,** 최빈값 등의 대푯값을 활용\n",
    "\n",
    "- **일괄 대체**: 모든 변수들 일괄적으로 같은 값으로 대체\n",
    "    \n",
    "    ex) 모든 변수들의 평균값(대푯값)을 구해 일괄적으로 대체\n",
    "    \n",
    "- **유사 유형 대체**: 범주형 변수들을 활용해 **유사한 범주에 따라 다른 값**으로 대체\n",
    "    \n",
    "    ex) 범주형 변수들을 활용해 유사한 유형의 평균값(대푯값)으로 대체\n",
    "\n",
    "    fillna() : 결측값 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03960edb",
   "metadata": {},
   "source": [
    "## 이상치 처리\n",
    "\n",
    "**이상치** = 관측된 **데이터의 범위에서 많이 벗어난 값**을 말한다.\n",
    "\n",
    "이상치를 처리해주지 않으면 데이터 분석에 큰 영향을 끼치게 되기 때문에 알맞은 처리를 진행해주어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468f548",
   "metadata": {},
   "source": [
    "### (1) 이상치 확인\n",
    "\n",
    "1. 통계를 통해 확인: 🐼`describe()`\n",
    "2. 시각화를 통해 확인: BoxPlot\n",
    "3. **Z-score**을 통해 확인\n",
    "    - 데이터를 **평균(0)과 표준편차(1)로 정규화**하여, **평균으로부터 얼마나 떨어져**있는지 나타냄\n",
    "    - 평균에 가까울수록 0에 가깝고 멀어질수록 Z-score가 커짐\n",
    "    - Z-score가 특정 기준값(일반적으로 2~3)을 넘어가는 데이터를 이상치로 간주\n",
    "4. **Tukey Fences**을 통해 확인:  사분위 범위(IQR, Interquartile Range)를 기반으로, 두 가지 경우에 이상치라고 판단\n",
    "    - Q1 - (1.5 * IQR) 미만\n",
    "    - Q3 + (1.5 * IQR) 초과\n",
    "    \n",
    "    → 보통은 IQR의 1.5배를 기준으로 잡고, 데이터의 특성에 따라 3.0배 등 조절할 수 있음 \n",
    "    \n",
    "    Tukey Fences(튜키 펜스)는 이상치를 식별하는 통계적인 방법 중 하나로, 데이터의 사분위 범위(IQR, Interquartile Range)를 기반으로 합니다. IQR은 데이터의 중간 50% 범위를 측정하며, 이는 데이터의 상위 25%와 하위 25%를 제외한 중간 범위를 의미합니다.\n",
    "    \n",
    "    → 이상치 판단 기준이 될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a5d9e",
   "metadata": {},
   "source": [
    "## (2) 이상치 제거 및 처리\n",
    "1. **전체 삭제**\n",
    "    - 이상값이 **Human error**에 의해서 발생한 경우에는 해당 관측치를 **삭제**하면 됩니다.\n",
    "    - 단순 오타나, 주관식 설문 등의 비현실적인 응답, 데이터 처리 과정에서의 오류 등의 경우에 사용합니다.\n",
    "2. **다른 값으로 대체**\n",
    "    - 절대적인 관측치의 **숫자가 작은 경우**, 단순 삭제를 통해 이상치를 제거하면 관측치의 절대량이 작아져 신뢰성 문제가 발생합니다.\n",
    "    - 이런 경우 이상값이 Human error에 의해 발생했더라도 관측치를 삭제하는 대신 다른 값(평균 등)으로 **대체**하거나, 결측값과 유사하게 다른 변수들을 사용해서 예측 모델을 만들고, 이상값을 **예측**한 후 해당 값으로 대체하는 방법도 사용할 수 있습니다.\n",
    "3. **변수화**\n",
    "    - 이상값이 **자연 발생**한 경우, 단순 삭제나 대체의 방법을 통해 수립된 모델은 설명/예측하고자 하는 현상을 잘 설명하지 못할 수도 있습니다.\n",
    "        - 예를 들어, 아래 그래프에서 다른 관측치들만 보면 **경력과 연봉이 비례**하는 현상이 존재하는 것 처럼 보이지만, 5년차의 연봉 **$35,000인 이상치**가 포함됨으로써 모델의 설명력이 크게 낮아 집니다.\n",
    "    -  자연발생적인 이상값의 경우, 바로 삭제하지 말고 좀 더 찬찬히 이상값에 대해 **파악**하는 것이 중요합니다.\n",
    "        - 예를 들어, 위 이상값의 경우 **의사 등 전문직종**에 종사하는 사람이라고 가정해 봅시다.\n",
    "        - 이럴 경우 **전문직종 종사 여부를 Yes – No로 변수화** 하면 **이상값을 삭제하지 않고 모델에 포함**시킬 수 있습니다.\n",
    "4. **리샘플링**\n",
    "- 자연발생한 이상값을 처리하는 또 다른 방법으로는 해당 **이상값을 분리**해서 모델을 만드는 방법이 있습니다.\n",
    "    - 아래와 같이 15년 이상의 경력을 가진 이상값이 존재한다고 가정해 봅시다. 이 관측치는 경력도 길지만 연봉이 비례해서 늘어나지 않은 사람입니다.\n",
    "    - <위 사례와의 차이>\n",
    "        - 위 사례는 독립 변수(x), 즉 경력 측면에서는 Outlier가 아니고, 종속 변수(y)인 연봉만 예측치를 벗어남\n",
    "        - 본 케이스는 독립 변수(x), 종속 변수(y) 모두에서 Outlier라는 점입니다.\n",
    "            - 15년 경력이라는 독립변수(x) 자체가 희귀한 데이터 → 독립변수(x)에서 outlier\n",
    "            - 종속 변수(y)의 예측치가 벗어남 → 종속변수(y)에서 outlier\n",
    "    - 이 경우, 이상값을 대상에서 제외시키는 것은 현상에 대한 정확한 설명이 되지 않을 수 있습니다. 보다 좋은 방법은 이상값을 포함한 모델과 제외한 모델을 모두 만들고 각각의    모델에 대한 설명을 다는 것입니다.\n",
    "\n",
    "→ 즉, 자연발생한 이상값에 별다른 특이점이 발견되지 않는다면, 단순 제외 보다는 케이스를 분리하여 분석하는 것을 추천합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6517ecf",
   "metadata": {},
   "source": [
    "## 피처 엔지니어링 (변수 가공)\n",
    "\n",
    "해결하고자 하는 문제를 컴퓨터가 잘 이해할 수 있도록 **피처(변수)들의 형태를 변형하거나 적절하게 처리**하는 과정\n",
    "\n",
    "도메인 지식과 기존의 변수를 사용해서 **기존의 데이터에 정보를 추가하는 일련의 과정**을 변수 가공(피처 엔지니어링)이라고 합니다. \n",
    "\n",
    "이는 데이터 전처리의 마지막 단계로 새로운 데이터 또는 변수의 추가 없이 기존의 데이터를 보다 유용하게 만드는 방법이며, \n",
    "\n",
    "도메인 지식 여부에 따라 변수 가공의 결과와 그 유의성이 많이 달라지기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7fdc3",
   "metadata": {},
   "source": [
    "피처 엔지니어링 방식\n",
    "1) 레이블인코딩, 원핫인코딩: 문자열 값들을 숫자형으로 변경하는 작업\n",
    "2) 구간화(Binning): 연속적인 값을 일정한 구간(Bin)으로 구분 \n",
    "3) 파생변수 생성: 기존의 피처를 변환해 새로운 피처 생성\n",
    "4) 스케일링: 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045609d8",
   "metadata": {},
   "source": [
    "### **1) 레이블인코딩(Label Encoding) vs 원핫인코딩(One-hot Encoding)**\n",
    "\n",
    "기계는 숫자만을 이해하고 텍스트를 이해하지는 못합니다. 따라서 우리는 **텍스트로 주어지는 값**들을 **기계가 이해할 수 있도록 숫자**로 바꾸는 작업을 수행해야 합니다.\n",
    "\n",
    "- Label Encoding\n",
    "    - 범주형 변수를 0부터 N-1까지의 숫자로 변환\n",
    "- One-Hot Encoding\n",
    "    - 범주형 변수를 이진 벡터(0과 1)로 변환합니다\n",
    "    - (표현하고 싶은 단어의 인덱스는 1, 다른 인덱스는 0)\n",
    "    \n",
    "    🐼 `pd.get_dummies(데이터프레임, columns=[컬럼 리스트])` : 명목변수를 0과 1로 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970cc3e5",
   "metadata": {},
   "source": [
    "### **(2) 구간화 (Binning)**\n",
    "\n",
    "연속 데이터를 그대로 사용하기 보다는 **일정한 구간으로 나눠서 분석**하는 것이 효율적인 경우가 있습니다. 이산적인 값으로 나타내어 구간별 차이를 드러내는 것이지요. 이는 원칙이나 규칙이 있는 것이 아니기 때문에 분석 목적과 방법 등 필요한 영역에 따라 분석가의 도메인 지식을 최대한 활용해 수행하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8ff94",
   "metadata": {},
   "source": [
    "### **(3) 파생변수 생성**\n",
    "\n",
    "**기존의 피처를 다른 피처로 변환(재정의)하여 변수를 추가**합니다. 기존 데이터를 다른 관점에서 분석해 새로운 특성과 정보를 얻기 위한 과정입니다. 정해진 원칙이 있는 방법이 아니어서 **분석가의 도메인 지식과 데이터 특성에 대한 이해도**에 따라 다양한 파생변수가 생성될 수 있습니다.\n",
    "\n",
    "논리적 타당성과 기준을 가지고 생성해야 하며, 생성하는 방법으로는 단위 변환, 표현형식 변환, 요약 통계량 변환, 정보 추출, 변수 결합, 조건문 이용 등의 방법들이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ea947",
   "metadata": {},
   "source": [
    "### **(4) 스케일링**\n",
    "\n",
    " 서로 다른 **변수의 값 범위를 일정한 수준으로 맞추는 작업**입니다. 숫자의 상대적인 크기 차이로 인한 결과의 왜곡을 방지하기 위해, 각 열(변수)에 속하는 데이터 값을 동일한 크기 기준으로 나눈 비율로 나타내는 **정규화(normalization) 작업**을 수행합니다. 모든 스케일러는 이상치에 민감하기 때문에 이상치 제거가 선행되어야 합니다.\n",
    "\n",
    "1.  StandardScaler (표준화)\n",
    "\n",
    "    각 feature의 평균을 0, 분산을 1로 변경하여, 모든 피처들이 같은 스케일을 갖게 됩니다.\n",
    "    → 정규분포를 따른다고 가정하는 기술에 적합!\n",
    "2. MinMaxScaler \n",
    "    모든 feature가 0과 1사이에 위치하게 만듭니다. 데이터가 2차원 셋일 경우, 모든 데이터는 x축의 0과 1 사이에, y축의 0과 1사이에 위치하게 됩니다.\n",
    "    → 데이터가 서로 다른 비율의 속성으로 구성되어 있을 때, 같은 비율로 속성을 맞춤.\n",
    "    → 연산 속도를 높이고 알고리즘 최적화하는 데에 효과적!\n",
    "\n",
    "`StandardScaler()` `MinMaxScaler()`\n",
    "\n",
    "sklearn 라이브러리는 StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler 등 다양한 종류의 스케일러를 제공합니다.\n",
    "\n",
    "`sklearn` 라이브러리에서 원하는 스케일러 `import`\n",
    "\n",
    "원하는 스케일러를 `scaler` 변수에 저장\n",
    "\n",
    "해당 `scaler` 변수로 기존 컬럼을 `fit_transform` 해주면 됨 !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e474fb1c",
   "metadata": {},
   "source": [
    "## 4️⃣ 데이터 시각화\n",
    "\n",
    "데이터 시각화(Data Visualization)는 데이터에 대한 이해를 돕기 위해 그림, 도형 등 그래픽 요소들을 이용해 데이터를 묘사하고 표현하는 과정입니다.\n",
    "\n",
    "시각화를 통해 숫자와 텍스트로 표현되는 정보를 그래프, 차트, 그림, 도표 등의 시각적 요소로 변환하고, 이를 통해 데이터 패턴, 관계, 추세 등을 쉽게 파악할 수 있습니다.\n",
    "\n",
    "**How?**: 시각적 분석기법을 활용할 때 일반적으로 **Matplotlib**과 **Seaborn**을 사용합니다. \n",
    "\n",
    "- Matplotlib는 Python 프로그래밍 언어 및 수학적 확장 NumPy 라이브러리를 활용한 플로팅(그래프를 그리기 위한) 라이브러리\n",
    "\n",
    "- Seaborn은 matplotlib을 기반으로 만들어져 통계 데이터 시각화에 최적화된 인기 라이브러리\n",
    "\n",
    "시각화를 하기 전 데이터가 **범주형인지 수치형**인지 파악하고, **결측값 및 이상치가** 있는지 확인해야 합니다. 데이터의 특성을 파악하고 난 뒤에는 어떤 그래프를 그려서 데이터를 바라볼지 고민해야 합니다.\n",
    "\n",
    "막대 그래프, 선 그래프, 파이 그래프, 산점도 그래프 등등 많은 종류의 그래프들이 존재합니다. 데이터를 어떤 식으로 바라보고 싶은 지에 따라 사용하는 그래프가 모두 다릅니다.\n",
    "\n",
    "처음부터 존재하는 모든 그래프에 대해 공부하고 활용방법을 터득할 수는 없어요!\n",
    "→ 주요 그래프들의 특징에 대해서 알아두고, 추가적으로 공부가 필요한 그래프는 그때그때 찾아서 익히는 방식을 추천합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3bedf",
   "metadata": {},
   "source": [
    "**파라미터**\n",
    "\n",
    "컴퓨터 프로그래밍에서 **매개변수(parameter 파라미터)란** 프로그래밍된 함수의 **입력값**을 의미합니다.\n",
    "\n",
    " seaborn의 막대 그래프 함수 countplot을 예시로 설명하겠습니다.\n",
    "위 코드의 **`data**=data,**x**='Survived'` ****에서,\n",
    "\n",
    "- **`data`** 와 `x`는 각각 countplot의 **매개변수(parameter 파라미터)**\n",
    "- `data`와 `‘Survived’`는 실제 전달되는 **인자(argument)**\n",
    "\n",
    "→ 그래프를 그릴 때 **`data`로서** `data`**(데이터프레임이 저장된 변수)**를 활용하고 `x`축에 표현할 칼럼을 `‘Survived’`로 지정한다는 의미입니다.\n",
    "\n",
    "이처럼 함수를 내가 원하는 조건에 맞춰서 이용하기 위해 파라미터 = 인자 형식으로 전달합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea051ef",
   "metadata": {},
   "source": [
    "추가적으로 오늘 실습에서 **중요하게 사용될 파라미터인** `hue`에 대해 알아봅시다. \n",
    "\n",
    "`hue` **파라미터**에는 성별(Sex)과 같은 **범주형 변수**를 넣어, **내가 원하는 변수를 기준**으로 **데이터를 구분하여 그래프에 표시**해줄 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059c9e0",
   "metadata": {},
   "source": [
    "**다양한 그래프 톺아보기**\n",
    "\n",
    "### (1) boxplot(상자 수염 그림)\n",
    "\n",
    "**boxplot**은 아래와 같이 **사분위수**와 **이상치**를 보여주는 그래프입니다. ****\n",
    "\n",
    "### (2) countplot, histplot\n",
    "\n",
    "**countplot**은 **범주형 변수의 빈도수**를 확인하는 그래프입니다.\n",
    "\n",
    "**histplot**은 도수분포표를 그래프로 나타낸 것으로, **수치형 변수**의 **구간별 빈도수**를 보여줍니다. \n",
    "\n",
    "### (3) displot, kdeplot (커널밀도추정 그래프)\n",
    "\n",
    "**displot**과 **kdeplot**은 히스토그램을 연속적으로 곡선으로 연결한 그래프입니다.\n",
    "\n",
    "### (4) barplot, pointplot\n",
    "\n",
    "**barplot**은 **범주형 데이터 값 x**에 따른 **수치형 데이터 값 y의 평균 값**을 제공합니다. **pointplot**은 막대 그래프와 모양만 다르고 동일한 정보를 제공합니다.\n",
    "\n",
    "### (5) scatterplot(산점도 그래프), regplot(회귀선이 추가된 산점도래프)\n",
    "\n",
    "**scatterplot**은 **두 연속형 변수 간의 관계**를 시각화하기 위해 사용되는 그래프 유형입니다. 각각의 데이터 포인트는 두 변수의 값을 나타내며, x축과 y축에 데이터 포인트를 분산하여 그립니다.\n",
    "\n",
    "**→ 변수 간의 패턴**, **상관관계**, **분포** 등을 쉽게 파악할 수 있다!\n",
    "\n",
    "**regplot**은 두개의 연속 변수 사이의 산점도를 그리고 회귀선을 함께 나타내는 그래프입니다.\n",
    "\n",
    "### (6) catplot\n",
    "\n",
    "**catplot**은 **category**plot의 준말로, **수치형 데이터와 범주형 데이터의 관계**를 볼 때 주로 사용합니다.\n",
    "\n",
    "### (7) pieplot\n",
    "\n",
    "**pieplot**은 데이터의 부분과 전체 간의 비율을 표현하는 그래프입니다. 주로 비율을 강조하기 위해 사용되며, 모든 데이터가 합쳐서 전체를 이루는 경우에 효과적으로 활용할 수 있습니다.\n",
    "\n",
    "### (8) heatmap\n",
    "\n",
    "**heatmap**은 변수간 **상관계수**를 직관적으로 볼 수 있는 그래프입니다. `corr()`메서드로 변수간의 상관계수를 구하고 이를 히트맵에 표현할 수 있습니다.\n",
    "\n",
    "상관계수란 **두 수치형 변수 사이의 상관 관계의 정도를 수치적으로 나타낸 계수**입니다. 즉 두 변수간 **서로 영향을 주는 정도**를 나타내는 값입니다. **-1과 1 사이**의 값을 가지며 -1과 1에 가까울수록 큰 상관계수를 가진다고 판단합니다. \n",
    "\n",
    "- **음의 상관계수**: 하나가 커지면 다른 하나가 작아짐 (반비례)\n",
    "- **양의 상관계수**: 하나가 커지면 다른 하나도 커짐 (비례)\n",
    "\n",
    "### (9) violinplot\n",
    "\n",
    "**바이올린 플롯**은 박스 플롯과 커널밀도추정 함수 그래프를 합쳐 놓은 그래프라고 할 수 있습니다.\n",
    "\n",
    "위의 박스 플롯을 바이올린 플롯으로 시각화하면 나이의 분포를 더 정확하게 파악할 수 있습니다.\n",
    "\n",
    "## (10) 여러 그래프 한번에 찍기, pairplot\n",
    "\n",
    "**각 그래프를 ax[i]에 할당하여 원하는 위치에 출력 가능**\n",
    "\n",
    "pairplot은 여러 변수간의 산점도를 한번에 보여주는 그래프입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd7f574",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
