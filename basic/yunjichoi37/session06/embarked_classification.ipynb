{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd9c318",
   "metadata": {},
   "source": [
    "# 기초 데이터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc12a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\3377644071.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Mr' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'Initial'] = initial_search\n",
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\3377644071.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Initial'].replace([\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./titanic.csv\")\n",
    "\n",
    "df['Initial'] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    initial_search = row['Name'].split(',')[1].split('.')[0].strip() # Name 컬럼에서 .(dot)을 기준으로 알파벳 문자열 추출\n",
    "    df.at[index, 'Initial'] = initial_search\n",
    "    \n",
    "df['Initial'].replace([\n",
    "    'Mlle', 'Mme', 'Ms', 'Dr', 'Major', 'Lady', 'Countess', 'Jonkheer', 'Col',\n",
    "    'Rev', 'Capt', 'Sir', 'Don','the Countess' \n",
    "], [\n",
    "    'Miss', 'Miss', 'Miss', 'Mr', 'Mr', 'Mrs', 'Mrs', 'Other', 'Other',\n",
    "    'Other', 'Mr', 'Mr', 'Mr', 'Other'\n",
    "],\n",
    "    inplace=True)\n",
    "\n",
    "df.loc[(df['Age'].isnull()) & (df.Initial == 'Mr'), 'Age'] = 33\n",
    "df.loc[(df['Age'].isnull()) & (df.Initial == 'Mrs'), 'Age'] = 36\n",
    "df.loc[(df['Age'].isnull()) & (df.Initial == 'Master'), 'Age'] = 5\n",
    "df.loc[(df['Age'].isnull()) & (df.Initial == 'Miss'), 'Age'] = 22\n",
    "df.loc[(df['Age'].isnull()) & (df.Initial == 'Other'), 'Age'] = 46\n",
    "\n",
    "df.dropna(subset='Embarked', inplace=True)\n",
    "df.drop(['Cabin', 'Name', 'PassengerId', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "df_org = df.copy()\n",
    "df['Relatives'] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['Age'] = (df['Age'] // 10).astype(int)\n",
    "df['Fare'] = pd.qcut(df['Fare'], q=9, labels=range(9))\n",
    "df['Embarked'] = df['Embarked'].map({'S': 1, 'C': 2, 'Q': 3})\n",
    "initial_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other':4}\n",
    "df['Initial'] = df['Initial'].map(initial_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b7c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_survival(model, scaler, survived, pclass, sex, age, sibsp, parch, fare, initial):\n",
    "    input_data = pd.DataFrame({\n",
    "        'Survived': [survived],\n",
    "        'Pclass': [pclass],\n",
    "        'Sex': [0 if sex == 'male' else 1],\n",
    "        'Age': [age // 10],\n",
    "        'SibSp': [sibsp],\n",
    "        'Parch': [parch],\n",
    "        'Fare': [fare],\n",
    "        'Initial': [0 if initial == 'Mr' else (1 if initial == 'Miss' else (2 if initial == 'Mrs' else (3 if initial == 'Master' else 4)))],\n",
    "        'Relatives': [sibsp + parch],\n",
    "    })\n",
    "    \n",
    "    fare_bins = pd.qcut(df_org['Fare'], 9, retbins=True)[1]\n",
    "    input_data['Fare'] = pd.cut(input_data['Fare'], bins=fare_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    # 코드 수정\n",
    "    input_data_for_scaling = input_data.drop(['SibSp', 'Parch'], axis=1)\n",
    "    input_data_scaled = scaler.transform(input_data_for_scaling)\n",
    "    # input_data_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    prediction = model.predict(input_data_scaled)\n",
    "    prediction_proba = model.predict_proba(input_data_scaled)\n",
    "\n",
    "    result = \"S\" if prediction == 1 else (\"C\" if prediction == 2 else \"Q\")\n",
    "    probability = prediction_proba[0][int(prediction)]\n",
    "    \n",
    "    return result, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f87e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Embarked', axis=1)\n",
    "y = df['Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43cf072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ad0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a219e",
   "metadata": {},
   "source": [
    "# 풀이 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f96a0",
   "metadata": {},
   "source": [
    "우선, 데이터의 결측값과 다중공선성을 확인해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83584e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived     0\n",
       "Pclass       0\n",
       "Sex          0\n",
       "Age          0\n",
       "SibSp        0\n",
       "Parch        0\n",
       "Fare         0\n",
       "Embarked     0\n",
       "Initial      0\n",
       "Relatives    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74cefb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inf</td>\n",
       "      <td>SibSp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inf</td>\n",
       "      <td>Relatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>inf</td>\n",
       "      <td>Parch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.93</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.48</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.28</td>\n",
       "      <td>Pclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.75</td>\n",
       "      <td>Sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.68</td>\n",
       "      <td>Survived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.65</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF   features\n",
       "4   inf      SibSp\n",
       "8   inf  Relatives\n",
       "5   inf      Parch\n",
       "6  4.93       Fare\n",
       "3  4.48        Age\n",
       "1  3.28     Pclass\n",
       "2  2.75        Sex\n",
       "0  2.68   Survived\n",
       "7  2.65    Initial"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "df_vif = pd.DataFrame()\n",
    "df_vif[\"VIF\"] = np.round([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], 2)\n",
    "\n",
    "df_vif[\"features\"] = X.columns\n",
    "df_vif.sort_values(by='VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ad75f",
   "metadata": {},
   "source": [
    "결측치가 없음을 확인하였고, SibSp와 Parch를 사용하여 Relatives 변수를 만들었으므로 SibSp와 Parch 변수를 제거해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5056b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['SibSp', 'Parch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac005fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.92</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.48</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.27</td>\n",
       "      <td>Pclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.73</td>\n",
       "      <td>Sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.68</td>\n",
       "      <td>Survived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.65</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.33</td>\n",
       "      <td>Relatives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF   features\n",
       "4  4.92       Fare\n",
       "3  4.48        Age\n",
       "1  3.27     Pclass\n",
       "2  2.73        Sex\n",
       "0  2.68   Survived\n",
       "5  2.65    Initial\n",
       "6  2.33  Relatives"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Embarked', axis=1)\n",
    "df_vif = pd.DataFrame()\n",
    "df_vif[\"VIF\"] = np.round([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], 2)\n",
    "\n",
    "df_vif[\"features\"] = X.columns\n",
    "df_vif.sort_values(by='VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ab355",
   "metadata": {},
   "source": [
    "모든 독립변수의 VIF가 5를 넘지 않음을 확인하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "072c5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 쪼개기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2596b6f",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6216486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 모델의 정확도: 0.7303370786516854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      1.00      0.84       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.24      0.33      0.28       178\n",
      "weighted avg       0.53      0.73      0.62       178\n",
      "\n",
      "\n",
      "[예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.2334355912695269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\2413866240.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(\"로지스틱 회귀 모델의 정확도:\", lr_accuracy)\n",
    "\n",
    "lr_report = classification_report(y_test, lr_pred)\n",
    "print(lr_report)\n",
    "\n",
    "model = lr_model\n",
    "result, probability = predict_survival(model, scaler, survived=1, pclass=2, sex='female', age=32, sibsp=1, parch=2, fare=60, initial='Mrs')\n",
    "print(\"\\n[예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8431a78",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da9c7196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "최적 하이퍼파라미터: {'C': 0.01, 'solver': 'liblinear'}\n",
      "최고 교차검증 정확도: 0.7229\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      1.00      0.84       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.24      0.33      0.28       178\n",
      "weighted avg       0.53      0.73      0.62       178\n",
      "\n",
      "\n",
      "[예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.2352350714193948\n",
      "\n",
      "튜닝된 Logistic Regression 모델의 정확도: 0.7303370786516854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\2413866240.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "lr_pred = best_lr_model.predict(X_test_scaled)\n",
    "\n",
    "lr_report = classification_report(y_test, lr_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(lr_report)\n",
    "\n",
    "result, probability = predict_survival(best_lr_model, scaler, survived=1, pclass=2, sex='female', age=32, sibsp=1, parch=2, fare=60, initial='Mrs')\n",
    "print(\"\\n[예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(\"\\n튜닝된 Logistic Regression 모델의 정확도:\", lr_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2f783",
   "metadata": {},
   "source": [
    "## 의사결정나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee3f49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 모델의 정확도: 0.702247191011236 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.88      0.82       130\n",
      "           2       0.35      0.19      0.25        36\n",
      "           3       0.43      0.25      0.32        12\n",
      "\n",
      "    accuracy                           0.70       178\n",
      "   macro avg       0.51      0.44      0.46       178\n",
      "weighted avg       0.66      0.70      0.67       178\n",
      "\n",
      "\n",
      "[예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\2413866240.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "tree_pred = tree_model.predict(X_test_scaled)\n",
    "\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"Decision Tree 모델의 정확도:\", tree_accuracy, \"\\n\")\n",
    "\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(tree_report)\n",
    "\n",
    "model = tree_model\n",
    "result, probability = predict_survival(model, scaler, survived=1, pclass=2, sex='female', age=32, sibsp=1, parch=2, fare=60, initial='Mrs')\n",
    "print(\"\\n[예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b42b7e",
   "metadata": {},
   "source": [
    "## 의사결정나무 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0fa5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "최적 하이퍼파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "최고 교차검증 정확도: 0.7271\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.93      0.86       130\n",
      "           2       0.63      0.33      0.44        36\n",
      "           3       0.57      0.33      0.42        12\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.67      0.53      0.57       178\n",
      "weighted avg       0.75      0.77      0.74       178\n",
      "\n",
      "\n",
      "[예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.20469798657718122\n",
      "\n",
      "튜닝된 Decision Tree 모델의 정확도: 0.7696629213483146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\2413866240.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_tree_model = grid_search.best_estimator_\n",
    "tree_pred = best_tree_model.predict(X_test_scaled)\n",
    "\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(tree_report)\n",
    "\n",
    "model = best_tree_model\n",
    "result, probability = predict_survival(model, scaler, survived=1, pclass=2, sex='female', age=32, sibsp=1, parch=2, fare=60, initial='Mrs')\n",
    "\n",
    "print(\"\\n[예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)\n",
    "\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"\\n튜닝된 Decision Tree 모델의 정확도:\", tree_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f5d1a",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b2ad59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 모델의 정확도: 0.7359550561797753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.99      0.85       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.67      0.17      0.27        12\n",
      "\n",
      "    accuracy                           0.74       178\n",
      "   macro avg       0.47      0.39      0.37       178\n",
      "weighted avg       0.58      0.74      0.64       178\n",
      "\n",
      "\n",
      "[예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.17476624504555993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\2413866240.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(random_state=42, probability=True)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(\"SVM 모델의 정확도:\", svm_accuracy)\n",
    "\n",
    "svm_report = classification_report(y_test, svm_pred)\n",
    "print(svm_report)\n",
    "\n",
    "model = svm_model\n",
    "result, probability = predict_survival(model, scaler, survived=1, pclass=2, sex='female', age=32, sibsp=1, parch=2, fare=60, initial='Mrs')\n",
    "print(\"\\n[예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e0c0c1",
   "metadata": {},
   "source": [
    "정확도 떨어짐. 생존확률은 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9ff86",
   "metadata": {},
   "source": [
    "## Grid Search SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "330e71f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "최적 하이퍼파라미터: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True}\n",
      "최고 교차검증 정확도: 0.7257\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.98      0.84       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.43      0.25      0.32        12\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.39      0.41      0.39       178\n",
      "weighted avg       0.57      0.73      0.64       178\n",
      "\n",
      "\n",
      "[예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.16571127595132099\n",
      "\n",
      "튜닝된 SVM 모델의 정확도: 0.7303370786516854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\yunji\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\2413866240.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'probability': [True]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {grid_search.best_score_:.4f}\")\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "svm_pred = best_svm_model.predict(X_test_scaled)\n",
    "svm_report = classification_report(y_test, svm_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(svm_report)\n",
    "model = best_svm_model\n",
    "result, probability = predict_survival(model, scaler, survived=1, pclass=2, sex='female', age=32, sibsp=1, parch=2, fare=60, initial='Mrs')\n",
    "print(\"\\n[예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(\"\\n튜닝된 SVM 모델의 정확도:\", svm_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c065a18f",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd33d35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN 모델의 정확도 :  0.6966292134831461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.86      0.81       130\n",
      "           2       0.35      0.25      0.29        36\n",
      "           3       0.60      0.25      0.35        12\n",
      "\n",
      "    accuracy                           0.70       178\n",
      "   macro avg       0.57      0.45      0.48       178\n",
      "weighted avg       0.67      0.70      0.67       178\n",
      "\n",
      "\n",
      "[예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\2413866240.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "knn_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(\"kNN 모델의 정확도 : \", knn_accuracy)\n",
    "\n",
    "knn_report = classification_report(y_test, knn_pred)\n",
    "print(knn_report)\n",
    "\n",
    "model = knn_model\n",
    "result, probability = predict_survival(model, scaler, survived=1, pclass=2, sex='female', age=32, sibsp=1, parch=2, fare=60, initial='Mrs')\n",
    "print(\"\\n[예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925dc1ff",
   "metadata": {},
   "source": [
    "## Grid Search kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a37d1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "최적 하이퍼파라미터: {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "최고 교차검증 정확도: 0.7244\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.93      0.83       130\n",
      "           2       0.42      0.14      0.21        36\n",
      "           3       0.50      0.25      0.33        12\n",
      "\n",
      "    accuracy                           0.72       178\n",
      "   macro avg       0.56      0.44      0.46       178\n",
      "weighted avg       0.67      0.72      0.67       178\n",
      "\n",
      "\n",
      "[예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.1111111111111111\n",
      "\n",
      "튜닝된 kNN 모델의 정확도: 0.7247191011235955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunji\\AppData\\Local\\Temp\\ipykernel_19252\\2413866240.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {grid_search.best_score_:.4f}\")\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "knn_pred = best_knn_model.predict(X_test_scaled)\n",
    "knn_report = classification_report(y_test, knn_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(knn_report)\n",
    "model = best_knn_model\n",
    "result, probability = predict_survival(model, scaler, survived=1, pclass=2, sex='female', age=32, sibsp=1, parch=2, fare=60, initial='Mrs')\n",
    "print(\"\\n[예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(\"\\n튜닝된 kNN 모델의 정확도:\", knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e6d0d",
   "metadata": {},
   "source": [
    "전처리 안 한 거\n",
    "--- 최종 모델별 정확도 비교 ---\n",
    "                     Accuracy\n",
    "Decision Tree        0.769663\n",
    "kNN                  0.747191\n",
    "SVM                  0.730337\n",
    "Logistic Regression  0.730337"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba3de2",
   "metadata": {},
   "source": [
    "# 최종\n",
    "## 튜닝된 정확도\n",
    "Logistic Regression     0.7303370786516854<br/>\n",
    "Decision Tree:          0.7696629213483146<br/>\n",
    "SVM:                    0.7303370786516854<br/>\n",
    "kNN:                    0.7247191011235955<br/>\n",
    "\n",
    "\n",
    "### (참고: Sirsp, parch 변수를 제거하지 않았을 때의 정확도)\n",
    "Logistic Regression:  0.730337<br/>\n",
    "Decision Tree:        0.769663<br/>\n",
    "SVM:                  0.730337<br/>\n",
    "kNN:                  0.747191<br/>\n",
    "\n",
    "## 결론\n",
    "하이퍼파라미터: {'max_depth': 3, 'min_samples_split': 2}로 튜닝한 의사결정나무의 정확도가 약 0.7697로 가장 높게 나왔다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
