{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51a61dd",
   "metadata": {},
   "source": [
    "# 분류 이론\n",
    "저번 세션에서 배운 분류 이론을 복습해봅시다.\n",
    "\n",
    "노션에 있는 분류 이론 파트를 참고해도 좋아요! \n",
    "\n",
    "내용을 다시 읽어보면서 정리한다는 느낌으로 문제를 풀어주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b92f6a",
   "metadata": {},
   "source": [
    "##\n",
    "***머신러닝이 무엇인지 설명하세요.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d72df",
   "metadata": {},
   "source": [
    "답: 모델이라는 소프트웨어를 학습하여 새로운 데이터를 예측하거나 결정할 수 있도록 하는 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7acbdf",
   "metadata": {},
   "source": [
    "##\n",
    "***머신러닝에는 지도학습과 비지도학습이 있습니다. 지도학습과 비지도학습의 차이를 설명해주세요.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d53342",
   "metadata": {},
   "source": [
    "답: 지도 학습은 문제와 정답을 모두 알려 주고 학습시키는 방법이고, 비지도 학습은 정답을 알려 주지 않고 학습시키는 방법이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73ef87",
   "metadata": {},
   "source": [
    "##\n",
    "***대표적인 지도학습 모델로는 회귀와 분류가 있습니다. 회귀와 분류의 차이를 설명해주세요.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9ee24",
   "metadata": {},
   "source": [
    "답: 회귀는 연속형 변수를 예측할 때 사용하고 분류는 범주형 범주를 예측할 때 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de61db",
   "metadata": {},
   "source": [
    "##\n",
    "***이진분류와 다중분류의 차이를 설명해주세요.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1740665",
   "metadata": {},
   "source": [
    "답: 이진 분류는 예측하고자 하는 변수가 참 또는 거짓의 값만을 가질 때 사용하고, 다중 분류는 변수가 가질 수 있는 값이 3개 이상일 때 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec4ade",
   "metadata": {},
   "source": [
    "##\n",
    "***세션에서 공부한 네 종류의 분류 모델을 간략히 설명해주세요.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec7b0e",
   "metadata": {},
   "source": [
    "답 :\n",
    "(1) 로지스틱 회귀\n",
    "독립 변수의 선형 회귀에 로지스틱 (시그노이드) 함수를 적용하여 출력값을 0과 1 사이로 변환해 줌\n",
    "\n",
    "(2) 의사결정나무\n",
    "조건에 따라 데이터가 순수한 label의 집합으로 구성될 때까지 분류를 반복\n",
    "\n",
    "(3) SVM\n",
    "클래스를 분류할 수 있는 최적의(마진이 높은) 경계선을 찾아내는 알고리즘\n",
    "\n",
    "(4) KNN\n",
    "거리가 가까운 k개의 이웃 데이터 레이블을 참조하여 분류하는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a1b55",
   "metadata": {},
   "source": [
    "# 분류 실습: 탑승한 항구를 예측하는 다중 분류 모델 만들기\n",
    "저번 세션 시간에, 타이타닉 데이터셋을 이용해 **생존 여부(Survived)** 를 예측하는 분류 모델을 만들었었습니다.\n",
    "\n",
    "그 모델은 **Survived/Not Survived** 를 예측하는 **이진 분류 모델** 이었습니다.\n",
    "\n",
    "이번 과제에서는, **탑승한 항구(Embarked)** 를 예측하는 **다중 분류 모델** 을 만들어 볼 것입니다.\n",
    "\n",
    "(탑승한 항구 컬럼의 값은 S, C, Q로 나뉘기 때문에, '이진 분류'가 아닌 '다중 분류'를 사용합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd3b34",
   "metadata": {},
   "source": [
    "📌 어떤 사람에 대한 정보가 주어졌을 때, **그 사람이 어떤 항구에서 탑승했는지 예측하는 모델**만들어봅시다.\n",
    "- 주어지는 정보: 생존 여부, 좌석 등급, 성별, 나이 등의 정보 (모델의 독립 변수)\n",
    "- 예측하고자 하는 정보: 탑승한 항구 (모델의 종속 변수)\n",
    "\n",
    "[ 변수 설명 ]\n",
    "\n",
    "- PassengerId : 각 승객의 고유 번호\n",
    "\n",
    "- Survived : 생존 여부(종속 변수)\n",
    "\n",
    "        0 = 사망\n",
    "        1 = 생존\n",
    " \n",
    "- Pclass : 객실 등급 - 승객의 사회적, 경제적 지위\n",
    "\n",
    "        1st = Upper\n",
    "        2nd = Middle\n",
    "        3rd = Lower\n",
    "\n",
    "- Name : 이름\n",
    "\n",
    "- Sex : 성별\n",
    "\n",
    "- Age : 나이\n",
    "\n",
    "- SibSp : 동반한 Sibling(형제자매)와 Spouse(배우자)의 수\n",
    "\n",
    "- Parch : 동반한 Parent(부모) Child(자식)의 수\n",
    "\n",
    "- Ticket : 티켓의 고유넘버\n",
    "\n",
    "- Fare : 티켓의 요금\n",
    "\n",
    "- Cabin : 객실 번호\n",
    "\n",
    "- Embarked : 승선한 항"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37822baa",
   "metadata": {},
   "source": [
    "## 데이터 읽기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8d5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn을 sns, pandas를 pd, numpy를 np로 import해주세요\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 타이타닉 데이터셋을 불러와서 df에 저장해주세요\n",
    "df = pd.read_csv(\"./titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbcf9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/pn9k9hgx12l2ck39s3x225r00000gn/T/ipykernel_6121/2791606022.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Mr' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'Initial'] = initial_search\n"
     ]
    }
   ],
   "source": [
    "# initial 컬럼을 만들고 일시적으로 값을 0으로 초기화\n",
    "df['Initial'] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    initial_search = row['Name'].split(',')[1].split('.')[0].strip() # Name 컬럼에서 .(dot)을 기준으로 알파벳 문자열 추출\n",
    "    df.at[index, 'Initial'] = initial_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49c49ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/pn9k9hgx12l2ck39s3x225r00000gn/T/ipykernel_6121/2395359540.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Initial'].replace([\n"
     ]
    }
   ],
   "source": [
    "# 유추 가능한 값들로 대체하고, 흔하지 않은 Initial들은 Other로 대체하겠습니다.\n",
    "df['Initial'].replace([\n",
    "    'Mlle', 'Mme', 'Ms', 'Dr', 'Major', 'Lady', 'Countess', 'Jonkheer', 'Col',\n",
    "    'Rev', 'Capt', 'Sir', 'Don','the Countess' \n",
    "], [\n",
    "    'Miss', 'Miss', 'Miss', 'Mr', 'Mr', 'Mrs', 'Mrs', 'Other', 'Other',\n",
    "    'Other', 'Mr', 'Mr', 'Mr', 'Other'\n",
    "],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a0b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값을 Initial별 평균값으로 대체\n",
    "df.loc[(df.Age.isnull()) & (df.Initial == 'Mr'), 'Age'] = 33\n",
    "df.loc[(df.Age.isnull()) & (df.Initial == 'Mrs'), 'Age'] = 36\n",
    "df.loc[(df.Age.isnull()) & (df.Initial == 'Master'), 'Age'] = 5\n",
    "df.loc[(df.Age.isnull()) & (df.Initial == 'Miss'), 'Age'] = 22\n",
    "df.loc[(df.Age.isnull()) & (df.Initial == 'Other'), 'Age'] = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "190b3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked 열의 결측값을 제거해주세요\n",
    "df.dropna(subset=['Embarked'], inplace=True)\n",
    "\n",
    "# 'Cabin', 'Name', 'PassengerId', 'Ticket' 열은 분석에서 제외하겠습니다.\n",
    "df.drop(['Cabin', 'Name', 'PassengerId', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab65413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나중에 사용하기 위해 원본 데이터프레임을 저장해둡니다.\n",
    "df_org = df.copy()\n",
    "\n",
    "# SibSp 행과 Parch 행을 이용해 Relatives 열을 만듭니다.\n",
    "df['Relatives'] = df[\"SibSp\"] + df[\"Parch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6079c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex 열 인코딩\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "# Age 열을 10년 단위로 나누어 인코딩\n",
    "df['Age'] = (df['Age'] // 10).astype(int)\n",
    "# Fare 열을 9분위로 구간화하고 인코딩\n",
    "df['Fare'] = pd.qcut(df['Fare'], q=9, labels=range(9))\n",
    "# Embarked 열 인코딩\n",
    "df['Embarked'] = df['Embarked'].map({'S': 1, 'C': 2, 'Q': 3})\n",
    "# Initial 열 인코딩\n",
    "initial_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other':4}\n",
    "df['Initial'] = df['Initial'].map(initial_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adf59a",
   "metadata": {},
   "source": [
    "## 다중 분류 모델 target과 feature 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3aa332",
   "metadata": {},
   "source": [
    "앞서 말했지만, 우리의 목표는 어떤 사람의 정보가 주어졌을 때 그 사람이 탑승한 항구를 예측하는 것입니다. 모델의 target과 feature가 무엇인지 정의해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1d5eb",
   "metadata": {},
   "source": [
    "- feature(예측을 위해 주어지는 정보 = 독립 변수): ***(답) 한 사람에 대한 정보 = Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Initial, Relatives***\n",
    "- target(예측하고자 하는 값 = 종속 변수): ***(답) Embarked***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4b46e0",
   "metadata": {},
   "source": [
    "이 target과 feature에 따라 생존 여부를 예측하는 함수 predict_survival를 정의합니다.\n",
    "\n",
    "이 함수에 model과 독립 변수들을 넣어주면, 승선한 항 예측 값과 확률을 반환합니다.\n",
    "\n",
    "- 함수의 input: model, scaler, 독립 변수(pclass, sex, age, sibsp, parch, fare, survived, initial)\n",
    "- 함수의 output: 승선한 항구, 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a81fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_survival 함수 정의\n",
    "def predict_survival(model, scaler, survived, pclass, sex, age, sibsp, parch, fare, initial):\n",
    "    # 입력된 데이터를 데이터프레임으로 변환합니다.\n",
    "    # 위에서 피처엔지니어링한 방식대로(모델의 input으로 적절하게) input 값을 변환해줍니다. \n",
    "    input_data = pd.DataFrame({\n",
    "        'Survived': [survived],\n",
    "        'Pclass': [pclass],\n",
    "        'Sex': [0 if sex == 'male' else 1],  # 성별을 인코딩합니다.\n",
    "        'Age': [age // 10],  # 나이를 10년 단위로 나눕니다.\n",
    "        'SibSp': [sibsp],\n",
    "        'Parch': [parch],\n",
    "        'Fare': [fare],  # 요금을 일단 그대로 둡니다.\n",
    "        'Initial': [0 if initial == 'Mr' else (1 if initial == 'Miss' else (2 if initial == 'Mrs' else (3 if initial == 'Master' else 4)))],  # 호칭을 인코딩합니다.\n",
    "        'Relatives': [sibsp + parch],\n",
    "    })\n",
    "    \n",
    "    # 'Fare' 값을 qcut으로 생성된 bins를 사용해 범주화합니다.\n",
    "    fare_bins = pd.qcut(df_org['Fare'], 9, retbins=True)[1]  # pd.qcut을 사용해 요금 구간을 얻습니다.\n",
    "    input_data['Fare'] = pd.cut(input_data['Fare'], bins=fare_bins, labels=False, include_lowest=True)\n",
    "\n",
    "\n",
    "    # 입력 데이터를 스케일링합니다.\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # 예측을 수행합니다.\n",
    "    prediction = model.predict(input_data_scaled)\n",
    "    prediction_proba = model.predict_proba(input_data_scaled)\n",
    "\n",
    "    # 예측 결과를 반환합니다.\n",
    "    result = \"S\" if prediction == 1 else (\"C\" if prediction == 2 else \"Q\")\n",
    "    probability = prediction_proba[0][int(prediction)]  # 예측된 클래스의 확률을 반환합니다.\n",
    "    \n",
    "    return result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81076609",
   "metadata": {},
   "source": [
    "## target과 feature 분리\n",
    "데이터 셋을 target과 feature를 분리합니다.\n",
    "예측하고자 하는 값인 target과 예측하기 위해 주어진 값인 feature를 각각 변수에 담습니다.\n",
    "\n",
    "- target = 종속 변수 (변수명=y): 'Embarked'\n",
    "- feature = 독립 변수 (변수명=X): 'Pclass', 'Sex', 'Age', 'Sibsp', 'Parch', 'Fare', `Survived', 'Initial'\n",
    "\n",
    "[ 참고 ]\n",
    "\n",
    "drop() 함수는 drop한 후의 데이터프레임을 반환합니다.\n",
    "drop('drop하고자 하는 열', axis=1)\n",
    "\n",
    "위에서 주어진 참고 코드를 바탕으로 아래 주석에 맞게 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd393bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 X에 feature(= 'Embarked' 열을 drop한 데이터프레임)를 담아주세요.\n",
    "X=df.drop(['Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e958b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Initial</th>\n",
       "      <th>Relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch Fare  Initial  Relatives\n",
       "0           0       3    0    2      1      0    0        0          1\n",
       "1           1       1    1    3      1      0    7        2          1\n",
       "2           1       3    1    2      0      0    2        1          0\n",
       "3           1       1    1    3      1      0    7        2          1\n",
       "4           0       3    0    3      0      0    2        0          0\n",
       "..        ...     ...  ...  ...    ...    ...  ...      ...        ...\n",
       "886         0       2    0    2      0      0    3        4          0\n",
       "887         1       1    1    1      0      0    6        1          0\n",
       "888         0       3    1    2      1      2    5        1          3\n",
       "889         1       1    0    2      0      0    6        0          0\n",
       "890         0       3    0    3      0      0    1        0          0\n",
       "\n",
       "[889 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f73cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 y에 target(= 'Embarked' 열)을 담아주세요.\n",
    "y = df.Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3ee19ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      2\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "886    1\n",
       "887    1\n",
       "888    1\n",
       "889    2\n",
       "890    3\n",
       "Name: Embarked, Length: 889, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1860e",
   "metadata": {},
   "source": [
    "## 데이터 셋을 훈련 세트와 테스트 세트로 나누기\n",
    "- 훈련 세트 -> 모델을 학습시키는 데 사용됩니다.\n",
    "- 테스트 세트 -> 완성된 모델을 평가하는 데 사용됩니다.\n",
    "\n",
    "독립변수(X)와 종속변수(y)를 모두 훈련 세트와 테스트 세트로 나누어봅시다.\n",
    "\n",
    "[ 변수명 ]\n",
    "\n",
    "- 독립변수 훈련 세트: X_train\n",
    "- 독립변수 테스트 세트: X_test\n",
    "- 종속변수 훈련 세트: y_train\n",
    "- 종속변수 테스트 세트: y_test\n",
    "\n",
    "[ 참고 ]\n",
    "\n",
    "tran_test_split 함수는 변수를 훈련 세트와 테스트 세트로 나누어 반환합니다.\n",
    "~~~\n",
    "train_test_split(독립변수, 종속변수, test_size=테스트 세트 크기, random_state=시드값)\n",
    "~~~\n",
    "-> 독립변수 훈련 세트, 독립변수 테스트 세트, 종속변수 훈련 세트, 종속변수 테스트 세트 반환\n",
    "\n",
    "- test_size: 테스트 세트의 크기를 결정합니다. 예를 들어, 훈련 세트와 테스트 세트를 각각 70%와 30%로 하고 싶으면, test_size=0.3으로 하면 됩니다.\n",
    "- random_state: 임의의 숫자로 설정된 시드로, 어떤 숫자를 사용해도 상관없습니다.\n",
    "\n",
    "위에서 주어진 참고 코드를 바탕으로 아래 주석에 맞게 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "024dfaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.model_selectio의 train_test_split 함수를 import 해주세요.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tran_test_split 함수를 이용하여 독립변수(X)와 종속변수(y)를 각각 훈련 세트와 테스트 세트로 나누어주세요. 각 훈련 세트와 테스트 세트의 변수 명은 아래와 같습니다.\n",
    "# 독립변수 훈련 세트: X_train, 독립변수 테스트 세트: X_test, 종속변수 훈련 세트: y_train, 종속변수 테스트 세트: y_test\n",
    "# 단, random_state는 42로 합니다.\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edcb2f",
   "metadata": {},
   "source": [
    "# feature에 scaler 적용\n",
    "MinMaxScaler를 이용해서 모든 feature(독립변수, X)를 스케일링 해줍니다. \n",
    "\n",
    "[ 변수명 ]\n",
    "- 스케일링된 독립변수 훈련 세트: X_train_scaled\n",
    "- 스케일링된 독립변수 테스트 세트: X_test_scaled\n",
    "\n",
    "[ 참고 ]\n",
    "\n",
    "1. MinMaxScaler 함수는 MinMaxScaler를 반환합니다.\n",
    "~~~\n",
    "MinMaxScaler()\n",
    "~~~\n",
    "2. fit_transform 함수는 훈련 데이터의 스케일링을 수행하고, 스케일링된 데이터를 반환합니다.\n",
    "~~~\n",
    "스케일러.fit_transform(훈련 데이터)\n",
    "~~~\n",
    "3. transform 함수는 테스트 데이터의 스케일링을 수행하고, 스케일링된 데이터를 반환합니다.\n",
    "~~~\n",
    "스케일러.transform(테스트 데이터)\n",
    "~~~\n",
    "\n",
    "cf) 훈련 데이터에 대해서는 fit과 transform을, 테스트 데이터에 대해서는 transform만을 수행합니다.\n",
    "\n",
    "위에서 주어진 참고 코드를 바탕으로 아래 주석에 맞게 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8137a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.preprocessing에서 MinMaxScaler를 import 해옵니다.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler라는 변수를 MinMaxScaler 함수로 선언합니다.\n",
    "scaler= MinMaxScaler()\n",
    "\n",
    "# X_train_scaled라는 변수에 스케일링된 독립변수 훈련 세트를 저장합니다.\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "\n",
    "# X_test_scaled라는 변수에 스케일링된 독립변수 테스트 세트를 저장합니다.\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5c414",
   "metadata": {},
   "source": [
    "## 모델 생성 및 평가\n",
    "위에서 만든 함수에 input으로 들어갈 model을 만듭니다. 총 4개의 다중 분류 모델을 만들어볼 것입니다.\n",
    "1. 로지스틱 회귀\n",
    "2. 의사 결정 나무\n",
    "3. 서포트벡터머신(SVM)\n",
    "4. kNN\n",
    "\n",
    "또한, 생성한 모델들을 다음과 같은 방식으로 평가합니다.\n",
    "1. accuracy\n",
    "2. 분류 보고서\n",
    "\n",
    "cf) 혼동 행렬은 이진분류에 대해 만들어지므로, 이번 실습에서 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f4e36",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀\n",
    "로지스틱 회귀 이진 분류 모델을 생성합니다.\n",
    "sklearn 라이브러리는 로지스틱 회귀 모델(LogisticRegression)을 제공합니다.\n",
    "\n",
    "[ 참고 ]\n",
    "로지스틱 회귀 모델 생성 함수\n",
    "~~~\n",
    "LogisticRegression()\n",
    "\n",
    "- penalty: 어떤 방식의 규제를 적용할지 선택합니다.\n",
    "\n",
    "- C: 규제의 강도를 조절하는 파라미터입니다.\n",
    "\n",
    "- solver: 모델의 최적 가중치를 찾기 위해 사용하는 최적화 알고리즘을 선택합니다.\n",
    "~~~\n",
    "위에서 주어진 참고 코드를 바탕으로 아래 주석에 맞게 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a365483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.linear_model에서 LogisticRegression 함수를 import 해오세요.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# lr_model을 변수명으로 해서 로지스틱회귀 모델 객체를 생성하세요.\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdfa6f2",
   "metadata": {},
   "source": [
    "이제 모델을 학습하고, 평가해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b57eab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀 모델의 정확도: 0.7303370786516854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      1.00      0.84       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.24      0.33      0.28       178\n",
      "weighted avg       0.53      0.73      0.62       178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 모델 학습\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측 결과 생성\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(\"로지스틱 회귀 모델의 정확도:\", lr_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "lr_report = classification_report(y_test, lr_pred)\n",
    "print(lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2b3a8",
   "metadata": {},
   "source": [
    "이제, 생성한 모델을 사용해보겠습니다.\n",
    "\n",
    "2번에서 행성했던 predict_survival 함수를 사용하여 예측값과 확률을 구합니다.\n",
    "\n",
    "아래는 어떤 사람에 대한 정보입니다. 생성한 lr 모델을 이용해서 이 사람이 생존할지 생존하지 못할지, 또 그 예측이 맞을 확률은 어느 정도인지 구하세요.\n",
    "\n",
    "[ 정보 ]\n",
    "- pclass: 2\n",
    "- sex: 'female'\n",
    "- age: 32 \n",
    "- sibsp: 1\n",
    "- parch: 2 \n",
    "- fare: 60\n",
    "- survived: 1\n",
    "- initial: 'Mrs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b82e4f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/pn9k9hgx12l2ck39s3x225r00000gn/T/ipykernel_6121/1060574916.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]  # 예측된 클래스의 확률을 반환합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('S', np.float64(0.23511793872537384))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lr_model\n",
    "\n",
    "result, probability = predict_survival(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2f735",
   "metadata": {},
   "source": [
    "### 의사 결정 나무\n",
    "이번에는 의사 결정 나무 모델을 만들어보겠습니다. 다른 과정은 모두 똑같고, 로지스틱 회귀 모델 대신 의사 결정 나무 모델을 사용합니다.\n",
    "\n",
    "sklearn 라이브러리는 의사 결정 나무 모델(DecisionTreeClassifier)을 제공합니다.\n",
    "\n",
    "[ 참고 ]\n",
    "의사 결정 나무 모델 생성 함수\n",
    "~~~\n",
    "DecisionTreeClassifier(random_state=시드값)\n",
    "\n",
    "- random_state: 임의의 숫자로 설정된 시드로, 어떤 숫자를 사용해도 상관없습니다.\n",
    "\n",
    "- max_depth: 트리의 최대 깊이를 제한합니다. 이 값을 작게 설정할수록 모델이 단순해집니다.\n",
    "\n",
    "- min_samples_split: 노드를 분할하기 위해 필요한 최소한의 데이터(샘플) 개수를 지정합니다. 이 값을 높게 설정하면 트리의 성장을 억제하여 과적합을 방지하는 효과가 있습니다.\n",
    "\n",
    "- min_samples_leaf: 분할 후, 리프 노드가 가져야 하는 최소한의 데이터(샘플) 개수를 지정합니다. min_samples_split과 비슷하지만, 분할 이후의 조건을 검사합니다. 예를 들어, 어떤 노드를 분할했을 때 자식 노드 중 하나의 데이터 개수가 이 값보다 작아진다면 해당 분할은 수행되지 않습니다. 이 역시 모델을 부드럽게(smoothing) 하고 과적합을 막는 역할을 합니다.\n",
    "\n",
    "- ccp_alpha:(Cost-Complexity Pruning) 비용 복잡도 가지치기(Pruning)에 사용되는 파라미터입니다. 값이 클수록 더 많은 가지가 잘려나가 트리가 단순해집니다.\n",
    "\n",
    "- criterion: 노드를 분할할 때 어떤 기준으로 불순도(Impurity)를 측정할지 결정합니다. 불순도는 한 노드에 여러 클래스의 데이터가 얼마나 섞여 있는지를 나타내는 지표입니다. 'gini' 아니면 'entropy'를 선택할 수 있습니다.\n",
    "\n",
    "- max_features: 최적의 분할을 찾기 위해 고려할 피처(변수)의 최대 개수를 지정합니다. 매 분할마다 모든 피처를 고려하는 대신, 무작위로 선택된 일부 피처 중에서만 최적의 분할 기준을 찾습니다. 이는 트리가 특정 피처에 과도하게 의존하는 것을 막아주며, 특히 피처가 매우 많을 때 과적합 방지 및 훈련 속도 향상에 도움이 됩니다.\n",
    "~~~\n",
    "\n",
    "위에서 주어진 참고 코드를 바탕으로 아래 주석에 맞게 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72cf8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.tree에서 DecisionTreeClassifier를 import 해오세요.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# tree_model이라는 변수에 의사 결정 나무 모델을 생성해주세요. 단, random_state는 42로 합니다.\n",
    "tree_model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce444b31",
   "metadata": {},
   "source": [
    "이제 모델을 학습, 평가하고 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f16e6ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 모델의 정확도: 0.7134831460674157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.89      0.82       130\n",
      "           2       0.40      0.22      0.29        36\n",
      "           3       0.50      0.25      0.33        12\n",
      "\n",
      "    accuracy                           0.71       178\n",
      "   macro avg       0.55      0.45      0.48       178\n",
      "weighted avg       0.67      0.71      0.68       178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/pn9k9hgx12l2ck39s3x225r00000gn/T/ipykernel_6121/1060574916.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]  # 예측된 클래스의 확률을 반환합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C', np.float64(0.0))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측 결과 생성\n",
    "tree_pred = tree_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"Decision Tree 모델의 정확도:\", tree_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(tree_report)\n",
    "\n",
    "model = tree_model\n",
    "\n",
    "result, probability = predict_survival(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21068de6",
   "metadata": {},
   "source": [
    "### 서포트 벡터 머신 (SVM)\n",
    "서포트 벡터 머신 역시 같은 방식으로 모델을 만듭니다.\n",
    "sklearn 라이브러리는 서포트 벡터 머신 분류기(SVC=Support Vector Classification)을 제공합니다.\n",
    "\n",
    "[ 참고 ]\n",
    "서포트 벡터 머신 모델 생성 함수\n",
    "~~~\n",
    "SVC(random_state=시드값, probability=True/False)\n",
    "\n",
    "- random_state: 임의의 숫자로 설정된 시드로, 어떤 숫자를 사용해도 상관없습니다.\n",
    "\n",
    "- probability: 모델이 클래스의 확률을 제공할 수 있도록 하는 옵션입니다.\n",
    "\n",
    "- C: 마진의 너비와 오류 데이터(Margin Violation)를 얼마나 허용할지를 결정하는 파라미터입니다.\n",
    "\n",
    "- kernel: 데이터를 어떤 공간에서 바라볼지 결정합니다.\n",
    "\n",
    "- gamma: 비선형 커널에서만 의미가 있는 파라미터입니다. 하나의 데이터 샘플이 경계선에 영향을 미치는 범위를 결정합니다.\n",
    "~~~\n",
    "\n",
    "위에서 주어진 참고 코드를 바탕으로 아래 주석에 맞게 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ad91ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.svm에서 SVC를 import 해오세요.\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# svm_model 단, random_state는 42, probability=True로 합니다.\n",
    "svm_model = SVC(random_state=42, probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be58a7",
   "metadata": {},
   "source": [
    "이제 모델을 학습, 평가하고 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c78b3924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 모델의 정확도: 0.7415730337078652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.99      0.85       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.75      0.25      0.38        12\n",
      "\n",
      "    accuracy                           0.74       178\n",
      "   macro avg       0.50      0.41      0.41       178\n",
      "weighted avg       0.59      0.74      0.65       178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/var/folders/3q/pn9k9hgx12l2ck39s3x225r00000gn/T/ipykernel_6121/1060574916.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]  # 예측된 클래스의 확률을 반환합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('S', np.float64(0.16628248561834877))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107b7a0c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1049460c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1074460c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1051320c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1035260c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106fe20c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1077ca0c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1127ea0c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1065f60c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103bda0c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# SVM 예측 결과 생성\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(\"SVM 모델의 정확도:\", svm_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "svm_report = classification_report(y_test, svm_pred)\n",
    "print(svm_report)\n",
    "\n",
    "# 생성한 모델로 예측값과 확률 도출\n",
    "model = svm_model\n",
    "\n",
    "result, probability = predict_survival(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921903ff",
   "metadata": {},
   "source": [
    "### kNN\n",
    "kNN 역시 같은 방식으로 모델을 만듭니다.\n",
    "sklearn 라이브러리는 kNN 모델(KNeighborsClassifier)을 제공합니다.\n",
    "\n",
    "[ 참고 ]\n",
    "kNN 모델 생성 함수\n",
    "~~~\n",
    "KNeighborsClassifier(n_neighbors=이웃 수)\n",
    "\n",
    "- n_neighbors: 고려할 최근접 이웃의 개수입니다.\n",
    "\n",
    "- weights: k개의 이웃을 찾았을 때, 그들의 의견을 어떤 가중치로 반영할지 결정합니다.\n",
    "\n",
    "- metric: 데이터 포인트 사이의 '거리'를 어떤 방식으로 측정할지 결정합니다.\n",
    "~~~\n",
    "\n",
    "위에서 주어진 참고 코드를 바탕으로 아래 주석에 맞게 코드를 작성해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4045e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.neighbors에서 KNeighborsClassifier를 import 해오세요.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# knn_model이라는 변수에 kNN 모델을 생성해주세요. 단, n_neighbors=5로 합니다.\n",
    "knn_model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89faa12a",
   "metadata": {},
   "source": [
    "이제 모델을 학습, 평가하고 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aed45a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN 모델의 정확도 :  0.6966292134831461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.88      0.81       130\n",
      "           2       0.32      0.19      0.24        36\n",
      "           3       0.50      0.25      0.33        12\n",
      "\n",
      "    accuracy                           0.70       178\n",
      "   macro avg       0.53      0.44      0.46       178\n",
      "weighted avg       0.65      0.70      0.67       178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/pn9k9hgx12l2ck39s3x225r00000gn/T/ipykernel_6121/1060574916.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]  # 예측된 클래스의 확률을 반환합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('S', np.float64(0.2))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 예측 수행\n",
    "knn_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(\"kNN 모델의 정확도 : \", knn_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "knn_report = classification_report(y_test, knn_pred)\n",
    "print(knn_report)\n",
    "\n",
    "# 생성한 모델로 예측값과 확률 도출\n",
    "model = knn_model\n",
    "\n",
    "result, probability = predict_survival(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "\n",
    "result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6bf7b",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 튜닝\n",
    "\n",
    "마지막으로 하이퍼파라미터 튜닝을 통해 모델의 성능을 개선하는 방법을 알아봅시다.\n",
    "\n",
    "의사결정나무에 Grid Search와 Random Search를 적용해봅시다!\n",
    "\n",
    "[ 참고 ]\n",
    "의사결정나무 모델 주요 하이퍼파라미터\n",
    "~~~\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "- max_depth: 트리의 최대 깊이를 제한합니다. 이 값을 작게 설정할수록 모델이 단순해집니다.\n",
    "\n",
    "- min_samples_split: 노드를 분할하기 위해 필요한 최소한의 데이터(샘플) 개수를 지정합니다. 이 값을 높게 설정하면 트리의 성장을 억제하여 과적합을 방지하는 효과가 있습니다.\n",
    "\n",
    "- min_samples_leaf: 분할 후, 리프 노드가 가져야 하는 최소한의 데이터(샘플) 개수를 지정합니다. min_samples_split과 비슷하지만, 분할 이후의 조건을 검사합니다. 예를 들어, 어떤 노드를 분할했을 때 자식 노드 중 하나의 데이터 개수가 이 값보다 작아진다면 해당 분할은 수행되지 않습니다. 이 역시 모델을 부드럽게(smoothing) 하고 과적합을 막는 역할을 합니다.\n",
    "\n",
    "- ccp_alpha:(Cost-Complexity Pruning) 비용 복잡도 가지치기(Pruning)에 사용되는 파라미터입니다. 값이 클수록 더 많은 가지가 잘려나가 트리가 단순해집니다.\n",
    "\n",
    "- criterion: 노드를 분할할 때 어떤 기준으로 불순도(Impurity)를 측정할지 결정합니다. 불순도는 한 노드에 여러 클래스의 데이터가 얼마나 섞여 있는지를 나타내는 지표입니다. 'gini' 아니면 'entropy'를 선택할 수 있습니다.\n",
    "\n",
    "- max_features: 최적의 분할을 찾기 위해 고려할 피처(변수)의 최대 개수를 지정합니다. 매 분할마다 모든 피처를 고려하는 대신, 무작위로 선택된 일부 피처 중에서만 최적의 분할 기준을 찾습니다. 이는 트리가 특정 피처에 과도하게 의존하는 것을 막아주며, 특히 피처가 매우 많을 때 과적합 방지 및 훈련 속도 향상에 도움이 됩니다.\n",
    "~~~\n",
    "\n",
    "\n",
    "💡 하이퍼파라미터 최적화 방법\n",
    "- Grid Search: 정해진 범위에서 Hyperparameter를 모두 순회\n",
    "- Random Search: 정해진 범위에서 Hyperparameter를 무작위로 탐색\n",
    "- Bayesian Optimization: 사전 정보를 바탕으로 Hyperparameter 값을 확률적으로 추정하며 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d4167",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "정해진 범위에서 Hyperparameter를 모두 순회하며 가장 좋은 성능을 내는 값을 찾는 기법\n",
    "- **장점**: 범위가 넓고 step이 작을수록 꼼꼼하게 전 범위를 탐색하니 최적해를 **정확히 찾을 수 있다**.\n",
    "- **단점**: 시간이 너무 오래 걸린다.\n",
    "- **적용**: 넓은 범위, 큰 step을 활용해 범위를 좁힌다.\n",
    "\n",
    "[ 참고 ]\n",
    "Grid Search 주요 하이퍼파라미터\n",
    "~~~\n",
    "GridSearchCV()\n",
    "\n",
    "- estimator: 튜닝할 모델 객체를 지정합니다.\n",
    "\n",
    "- param_grid: 테스트할 하이퍼파라미터들의 목록을 사전(dictionary) 형태로 전달합니다.\n",
    "\n",
    "- cv: 교차 검증(Cross-Validation)을 어떻게 수행할지 지정합니다.\n",
    "\n",
    "- scoring: 최적의 하이퍼파라미터를 선택하기 위한 평가 지표를 지정합니다.\n",
    "\n",
    "- n_jobs: 튜닝을 수행할 때 사용할 CPU 코어의 개수를 지정합니다.\n",
    "\n",
    "- verbose: 튜닝 과정에서 출력되는 메시지의 양을 조절합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3d78cd8-7c8d-4c1a-9b4b-687e66e52311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "최적 하이퍼파라미터: {'max_depth': 3, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "최고 교차검증 정확도: 0.7257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Decision Tree 모델 생성\n",
    "tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# 튜닝할 하이퍼파라미터의 후보 값들 설정\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],         # 트리의 최대 깊이\n",
    "    'min_samples_split': [2, 5, 10],    # 노드를 나누기 위한 최소 샘플 수\n",
    "    'min_samples_leaf': [1, 3, 5]       # 리프 노드가 되기 위한 최소 샘플 수\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성 (cv: 5겹 교차검증)\n",
    "# n_jobs=-1 은 사용 가능한 모든 CPU 코어를 사용하여 학습 속도를 높입니다.\n",
    "grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, \n",
    "                           cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 찾기 위해 모델 학습\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 그때의 최고 점수 출력\n",
    "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Grid Search가 찾은 최적의 모델을 저장\n",
    "best_tree_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e22afb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "튜닝된 Decision Tree 모델의 정확도: 0.7696629213483146\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.93      0.86       130\n",
      "           2       0.63      0.33      0.44        36\n",
      "           3       0.57      0.33      0.42        12\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.67      0.53      0.57       178\n",
      "weighted avg       0.75      0.77      0.74       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델로 예측 결과 생성\n",
    "tree_pred = best_tree_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"\\n튜닝된 Decision Tree 모델의 정확도:\", tree_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cf7f3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[새로운 데이터에 대한 예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.20469798657718122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/pn9k9hgx12l2ck39s3x225r00000gn/T/ipykernel_6121/1060574916.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]  # 예측된 클래스의 확률을 반환합니다.\n"
     ]
    }
   ],
   "source": [
    "# 최적화된 모델인 'best_tree_model'을 사용합니다.\n",
    "model = best_tree_model\n",
    "\n",
    "result, probability = predict_survival(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "print(\"\\n[새로운 데이터에 대한 예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd552b",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "정해진 범위에서 Hyperparameter를 **무작위**로 탐색해 가장 좋은 성능을 내는 값을 찾는 기법\n",
    "- **장점**: 속도가 Grid Search보다 빠르다.\n",
    "- **단점**: 무작위라는 한계 때문에 **정확도가 떨어진다**. 따라서 Grid Search나 Bayesian Optimization에 비해 사용 빈도가 적다.\n",
    "\n",
    "[ 참고 ]\n",
    "Grid Search 주요 하이퍼파라미터\n",
    "~~~\n",
    "RandomizedSearchCV()\n",
    "\n",
    "- estimator: 튜닝할 모델 객체를 지정합니다.\n",
    "\n",
    "- param_distributions: 탐색할 하이퍼파라미터의 분포 또는 목록을 사전(dictionary) 형태로 지정합니다.\n",
    "\n",
    "- n_iter: 지정된 param_distributions에서 몇 개의 하이퍼파라미터 조합을 무작위로 추출하여 테스트할지 그 횟수를 결정합니다.\n",
    "\n",
    "- random_state: 결과의 재현성(reproducibility)을 위한 파라미터입니다.\n",
    "\n",
    "- cv: 교차 검증 분할 개수\n",
    "\n",
    "- scoring: 최적 모델 선택을 위한 평가 지표\n",
    "\n",
    "- n_jobs: 사용할 CPU 코어 수\n",
    "\n",
    "- verbose: 진행 과정 출력 메시지 양"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83bd28b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "최적 하이퍼파라미터: {'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 3, 'criterion': 'gini'}\n",
      "최고 교차검증 정확도: 0.7257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 기본 Decision Tree 모델 생성\n",
    "tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# 튜닝할 하이퍼파라미터의 후보 값들 설정\n",
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, 20, None], # None은 깊이 제한 없음을 의미\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV 객체 생성\n",
    "# n_iter: 시도할 파라미터 조합의 수 (많을수록 좋은 조합을 찾을 확률이 높지만, 시간이 오래 걸림)\n",
    "# cv: 5겹 교차검증\n",
    "# n_jobs=-1: 사용 가능한 모든 CPU 코어를 사용하여 학습 속도 향상\n",
    "random_search = RandomizedSearchCV(estimator=tree_model, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=100, # 100개의 파라미터 조합을 무작위로 테스트합니다.\n",
    "                                   cv=5, \n",
    "                                   verbose=1, \n",
    "                                   random_state=42, # 결과를 재현하기 위해 random_state 설정\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 찾기 위해 모델 학습\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 그때의 최고 점수 출력\n",
    "print(\"최적 하이퍼파라미터:\", random_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Random Search가 찾은 최적의 모델을 저장\n",
    "best_tree_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14879d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "튜닝된 Decision Tree 모델의 정확도: 0.7696629213483146\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.93      0.86       130\n",
      "           2       0.63      0.33      0.44        36\n",
      "           3       0.57      0.33      0.42        12\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.67      0.53      0.57       178\n",
      "weighted avg       0.75      0.77      0.74       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델로 예측 결과 생성\n",
    "tree_pred = best_tree_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"\\n튜닝된 Decision Tree 모델의 정확도:\", tree_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ee1dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[새로운 데이터에 대한 예측 결과]\n",
      "예측 결과: S\n",
      "생존 확률: 0.20469798657718122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3q/pn9k9hgx12l2ck39s3x225r00000gn/T/ipykernel_6121/1060574916.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = prediction_proba[0][int(prediction)]  # 예측된 클래스의 확률을 반환합니다.\n"
     ]
    }
   ],
   "source": [
    "# 3. 튜닝된 최적 모델로 새로운 데이터 예측\n",
    "model = best_tree_model\n",
    "\n",
    "result, probability = predict_survival(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "print(\"\\n[새로운 데이터에 대한 예측 결과]\")\n",
    "print(\"예측 결과:\", result)\n",
    "print(\"생존 확률:\", probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45544d",
   "metadata": {},
   "source": [
    "## 끝으로...\n",
    "\n",
    "이번 세션에서 배운 모델들(로지스틱 회귀, 의사결정나무, SVM, kNN)의 하이퍼파라미터를 튜닝하여 가장 성능이 좋은 모델을 만들어주세요!\n",
    "\n",
    "정확도가 가장 높은 1등에게는 소정의 상품이 지급될 예정입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "최적 하이퍼파라미터: {'C': 1, 'coef0': 0, 'degree': 3, 'gamma': 0.5, 'kernel': 'poly'}\n",
      "최고 교차검증 정확도: 0.7328\n"
     ]
    }
   ],
   "source": [
    "svm_model=SVC(random_state=42, probability=True)\n",
    "\n",
    "# 튜닝할 하이퍼파라미터의 후보 값들 설정\n",
    "param_grid = {\n",
    "    'C': [1],        \n",
    "    'gamma': [0.5],  \n",
    "    'kernel': ['poly'],\n",
    "    'degree':[3, 4, 5, 6],\n",
    "    'coef0' : [-1, -0.5, 0, 0.5, 1, 2]\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성 (cv: 5겹 교차검증)\n",
    "# n_jobs=-1 은 사용 가능한 모든 CPU 코어를 사용하여 학습 속도를 높입니다.\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, \n",
    "                           cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 찾기 위해 모델 학습\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 그때의 최고 점수 출력\n",
    "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Grid Search가 찾은 최적의 모델을 저장\n",
    "best_svc_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853852ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "튜닝된 SVC 모델의 정확도: 0.7303370786516854\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.98      0.84       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.43      0.25      0.32        12\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.39      0.41      0.39       178\n",
      "weighted avg       0.57      0.73      0.64       178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델로 예측 결과 생성\n",
    "svm_pred = best_svc_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(\"\\n튜닝된 SVC 모델의 정확도:\", svm_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "svm_report = classification_report(y_test, svm_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3972f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼파라미터: {'C': 0.0001, 'l1_ratio': 0.1, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "최고 교차검증 정확도: 0.7229\n"
     ]
    }
   ],
   "source": [
    "lr_model=LogisticRegression()\n",
    "\n",
    "# 튜닝할 하이퍼파라미터의 후보 값들 설정\n",
    "param_grid = {\n",
    "    'penalty': ['elasticnet'],       \n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], \n",
    "    'l1_ratio':[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    'solver':['saga'],\n",
    "    'max_iter':[1000, 2000, 3000, 4000, 10000]\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성 (cv: 5겹 교차검증)\n",
    "# n_jobs=-1 은 사용 가능한 모든 CPU 코어를 사용하여 학습 속도를 높입니다.\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid, \n",
    "                           cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 찾기 위해 모델 학습\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 그때의 최고 점수 출력\n",
    "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Grid Search가 찾은 최적의 모델을 저장\n",
    "best_lr_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ddd86999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "튜닝된 로지스틱 회귀 모델의 정확도: 0.7303370786516854\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      1.00      0.84       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.24      0.33      0.28       178\n",
      "weighted avg       0.53      0.73      0.62       178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델로 예측 결과 생성\n",
    "lr_pred = best_lr_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(\"\\n튜닝된 로지스틱 회귀 모델의 정확도:\", lr_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "lr_report = classification_report(y_test, lr_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(lr_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34bdc248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "최적 하이퍼파라미터: {'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 3, 'criterion': 'gini'}\n",
      "최고 교차검증 정확도: 0.7257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 90 is smaller than n_iter=100. Running 90 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "390 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or None. Got 3.1 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or None. Got 3.2 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or None. Got 2.9 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of DecisionTreeClassifier must be an int in the range [1, inf) or None. Got 3.5 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan 0.72433763 0.72433763        nan 0.72432778 0.72432778\n",
      "        nan 0.72573624 0.72573624        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.71588693 0.70329952\n",
      "        nan 0.70329952 0.70329952        nan 0.70329952 0.71588693\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 기본 Decision Tree 모델 생성\n",
    "tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# 튜닝할 하이퍼파라미터의 후보 값들 설정\n",
    "param_dist = {\n",
    "    'max_depth': [3, 3.1, 3.2, 2.9, 3.5], # None은 깊이 제한 없음을 의미\n",
    "    'min_samples_split': [1, 2, 5],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV 객체 생성\n",
    "# n_iter: 시도할 파라미터 조합의 수 (많을수록 좋은 조합을 찾을 확률이 높지만, 시간이 오래 걸림)\n",
    "# cv: 5겹 교차검증\n",
    "# n_jobs=-1: 사용 가능한 모든 CPU 코어를 사용하여 학습 속도 향상\n",
    "random_search = RandomizedSearchCV(estimator=tree_model, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=100, # 100개의 파라미터 조합을 무작위로 테스트합니다.\n",
    "                                   cv=5, \n",
    "                                   verbose=1, \n",
    "                                   random_state=42, # 결과를 재현하기 위해 random_state 설정\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 찾기 위해 모델 학습\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터와 그때의 최고 점수 출력\n",
    "print(\"최적 하이퍼파라미터:\", random_search.best_params_)\n",
    "print(f\"최고 교차검증 정확도: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Random Search가 찾은 최적의 모델을 저장\n",
    "best_tree_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88953ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "튜닝된 Decision Tree 모델의 정확도: 0.7696629213483146\n",
      "\n",
      "[튜닝된 모델의 분류 보고서]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.93      0.86       130\n",
      "           2       0.63      0.33      0.44        36\n",
      "           3       0.57      0.33      0.42        12\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.67      0.53      0.57       178\n",
      "weighted avg       0.75      0.77      0.74       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델로 예측 결과 생성\n",
    "tree_pred = best_tree_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 측정\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"\\n튜닝된 Decision Tree 모델의 정확도:\", tree_accuracy)\n",
    "\n",
    "# 분류 보고서 생성\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(\"\\n[튜닝된 모델의 분류 보고서]\")\n",
    "print(tree_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
