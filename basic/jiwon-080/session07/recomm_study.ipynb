{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2ed5cd",
   "metadata": {},
   "source": [
    "> ### 1. 추천시스템이란?\n",
    "\n",
    "사용자의 정보 데이터를 분석 -> 추천하는 알고리즘  \n",
    "예) 상품, 음악, 영상 추천\n",
    "\n",
    "- 추천시스템에 사용되는 데이터들  \n",
    "    1. 명시적 데이터  \n",
    "    고객들에 의해 입력된 데이터, 선호도가 직접 표시된 데이터  \n",
    "    예) 별점, 좋아요\n",
    "    취향과 선호도를 수치화된 것으로 직접 알 수 있으나, 평점이 없는 리뷰처럼 데이터 수집 자체가 어렵다.  \n",
    "\n",
    "    2. 암시적 데이터  \n",
    "    고객들의 행동을 통해 수집한 데이터, 선호도가 간접적으로 표현된 데이터  \n",
    "    예) 조회수, 열람 기간, 구매 기록, 로그데이터 등  \n",
    "    데이터를 수집하기는 쉽지만, 취향과 선호도를 직접 알 수는 없다.\n",
    "\n",
    "\n",
    "- 추천시스템의 분류  \n",
    "    1. 내용 기반 필터링  \n",
    "    **콘텐츠/아이템의 속성(특징)유사도**를 기반으로 추천  \n",
    "    사용자가 기존에 선택한 아이템과 유사한 아이템을 추천  \n",
    "\n",
    "    2. 협업 필터링  \n",
    "    다수의 사용자로부터 선호도 정보를 취합  \n",
    "    -> 유사한 관심사를 가진 사용자(A,B) 중 A의 데이터를 바탕으로 다른 사용자 B에게 추천  \n",
    "        - 사용자 기반:  \n",
    "        A와 유사한 취향인 B가 구매하는 아이템을 추천하는 것  \n",
    "        - 아이템 기반:  \n",
    "        A가 자주 구매하는 아이템 ◇가 있고, ◇를 좋아하는 다른 사용자들이 ◆도 좋아한다면  \n",
    "        A에게 ◆를 추천해 주는 것  \n",
    "    3. 하이브리드 필터링  \n",
    "    2가지 이상의 추천시스템 알고리즘을 조합한 것  \n",
    "        - Weighted Ensemble: 보팅, 앙상블 기법처럼 여러 모델의 추천 결과를 합침  \n",
    "        - Mixed: 여러 추천 알고리즘의 결과를 보여줌  \n",
    "        - Switch: 상황을 고려하여 여러 추천 알고리즘의 결과를 '선택적으로' 보여줌  \n",
    "        - Feature Combination: 피쳐들을 조합하여 추천 알고리즘을 학습시키고 추천 결과를 보여줌  \n",
    "        - Meta-Level: 여러 추천 알고리즘을 직렬적으로 연결(첫 모델의 결과가 다음 모델의 인풋이 되는)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c9f50",
   "metadata": {},
   "source": [
    "> ### 2. 내용 기반 필터링  \n",
    "\n",
    "**사용자의 프로필**과 **아이템 특징**의 일치도를 계산 -> 추천 하는 알고리즘  \n",
    "\n",
    "- 사용자 프로필이란?  \n",
    "사용자가 좋아했던 항목들의 특징을 모은 데이터  \n",
    "> 인풋: 아이템들에 대한 정보  \n",
    "> 아웃풋(프로필): 사용자에 맞는 분류기  \n",
    "\n",
    "- 유사도  \n",
    "아이템 정보 데이터를 **벡터화** -> 벡터들 간 유사도 측정  \n",
    "-> 유사도를 바탕으로 추천!\n",
    "\n",
    "- 유사도 측정 과정  \n",
    "    1. 데이터 수집/전처리  \n",
    "    피쳐(아이템의 정보)가 카테고리 형식일 경우가 많으므로 원핫인코딩으로 0/1 변경  \n",
    "\n",
    "    2. 유저 정보 활용  \n",
    "    유저 프로필과 이용 기록을 통해 유저를 n개의 피쳐로 표현  \n",
    "    (1번의 아이템 피쳐와 동일한 기준의 피쳐를 사용해야 함)  \n",
    "    -> 아이템 피쳐와 유저정보 피쳐를 n차원의 벡터로 구성 -> 두 벡터를 계산 가능해짐\n",
    "\n",
    "    3. 유사도 계산  \n",
    "        - 자카드 유사도(집합): 집합 간의 교집합 크기를 이용  \n",
    "        - 코사인 유사도(각도): 벡터 사이의 각도를 이용  \n",
    "        - 유클라디안 거리(거리): 벡터 사이의 거리를 이용  \n",
    "        - 피어슨 상관계수(상관관계): 벡터 간 선형 상관관계를 이용  \n",
    "\n",
    "        ![다양한거리측정](https://blog.kakaocdn.net/dna/7PyTd/btsy9eivA5l/AAAAAAAAAAAAAAAAAAAAAFBfqaQ-lE6AR9pVVMVgGLEUyYjjFm-Lb5TX9ou-nsia/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=7uaR3kqHB1VcAbOdeJl7xtwWD04%3D)  \n",
    "        자카드 거리는 교집합/합집합  \n",
    "        ![코사인유사도1](https://blog.kakaocdn.net/dna/bz5z8H/btsHPNLPPpF/AAAAAAAAAAAAAAAAAAAAAKXY2JypjgFjlP79LgskkH-9BHkdejoAz1Y_upHk1xki/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=8gAkezgqsoWw2BBZsspA7G5swzc%3D)  \n",
    "        코사인 유사도는 이렇게 측정한다.  \n",
    "\n",
    "- 사용자 프로필을 구성하기  \n",
    "    - 사용되는 데이터의 종류  \n",
    "        1. 직접 지정형: 사용자가 직접 입력  \n",
    "        2. 간접 지정형: 사용자의 이용 내역에 기반  \n",
    "    - 특성 가중치: 사용자가 가지고 있는 아이템 특성 가중치의 평균을 활용  \n",
    "    - 명시적 데이터와 암시적 데이터를 모두 활용하여 좋은 사용자 프로필을 구성하는 것이 중요하다~  \n",
    "\n",
    "- 아이템 특징을 벡터로 표현: 도메인에 따라 어떤 피쳐를 적용하느냐가 달라진다.  \n",
    "    - 예) 영화: 장르, 감독, 배우 등  \n",
    "    음악: 작곡자, 시기, 음높이, 음량, 빠르기 등  \n",
    "\n",
    "    - 아이템 분석 알고리즘  \n",
    "        - 클러스터링  \n",
    "        - 머신러닝  \n",
    "        - **TF-IDF**  \n",
    "\n",
    "    - TF-IDF(Term Frequency - Inverse Document Frequency) 알고리즘이란?  \n",
    "        - TF: 특정 문서 내에 특정 단어가 자주 등장하는지의 단어 빈도  \n",
    "        - IDF - **전체 문서**에서 특정 단어가 자주 등장하는지의 역문서 빈도  \n",
    "    -> 가중치를 계산, 벡터화하여 유사도 계산  \n",
    "    -> 전체 문서 대비 특정 문서에서 자주 등장하는 단어의 중요도가 높다고 판단함.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # TF-IDF 벡터화\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    ```  \n",
    "    TfidfVectorizer 라이브러리  \n",
    "\n",
    "    - 내용기반 필터링의 장점  \n",
    "    콜드 스타트 문제를 해결 가능(협업 필터링은 일정 서비스 기간, 다른 이용자의 평점이 필요)  \n",
    "    추천 이유를 설명하기 용이\n",
    "        - 콜드 스타트 문제: 새로운 유저에 대한 정보 수집이 충분하지 않은 상태    \n",
    "\n",
    "    - 단점  \n",
    "    아이템에 대한 정확한 피쳐를 추출해야 하는 어려움  \n",
    "    사용자 입장에서 매너리즘 같은 문제  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba425a36",
   "metadata": {},
   "source": [
    "> ### 3. 협업 필터링  \n",
    "\n",
    "기존 사용자들과 아이템의 상관관계 -> **새로운 사용자와 아이템의 상관관계** 예측  \n",
    "\n",
    "> 인풋: 아이템에 대한 사용자들의 등급(평점)  \n",
    "> 아웃풋: 사용자와 비슷한 다른 사용자를 판별 -> 그 다른 사용자들의 아이템 등급  \n",
    "- 메모리 기반(=이웃 기반) 협업 필터링  \n",
    ": 사용자 A와 비슷한 취향을 가진 사용자가 선호하는 아이템을 A에게 추천  \n",
    "\n",
    "    1. 사용자 기반 접근: **유저 간의 유사도**를 중심으로 추천  \n",
    "예) 내가 식탁보 같은 패턴을 좋아해서 그런 원피스들에 높은 평점을 남겼다  \n",
    "-> 나처럼 식탁보 좋아하는 유저에게 높은 가중치를 주고, 그 유저들이 구입한 다른 옷들을 추천해줌  \n",
    "        - 아이템 수>사용자 수 일 경우 추천 정확, 시스템 효율적  \n",
    "        - 아이템이 수시로 바뀔 때 적합  \n",
    "        - 독창적 아이템 추천 가능(취향은 다양하기 때문에)  \n",
    "\n",
    "    2. 아이템 기반 접근: 사용자들의 아이템 **선호(good/bad) 평가 점수**를 통해 추천  \n",
    "예) 트레이닝복/빈티지 양말 중 중 원피스+빈티지 양말에 좋은 평점을 줬거나, 같이 구매한 유저가 많다  \n",
    "-> 나는 트레이닝복보다 양말을 추천받을 것이다  \n",
    "        - 사용자 수>아이템 수 일 경우 추천 정확, 시스템 효율적(사용자별 계산이 없어 계산이 빠름)  \n",
    "        - 아이템 리스트의 변화가 적을 경우 적합  \n",
    "        - 참신성이 비교적 부족할 수 있음  \n",
    "\n",
    "    - 메모리 기반 협업필터링의 한계  \n",
    "        - 아이템, 유저, 평점 데이터의 수 간의 균형을 생각하며 방법을 선택해야 함  \n",
    "        - 유저에 비해 아이템이 지나치게 많다면 **비어 있는 평점 행렬 문제** 발생 -> 모델 기반 협업필터링 이용  \n",
    "        - 유저가 많아 계산이 지나치게 많아질 경우 -> KNN CF 이용  \n",
    "\n",
    "\n",
    "- 모델 기반(=잠재 요인) 협업 필터링  \n",
    "사용자-아이템 평점 행렬 중 **잠재 요인을 추출**해서 추천하는 방식\n",
    "잠재 요인을 학습할 때에는 기계학습 모델을 사용  \n",
    "-> 벡터 계산을 통해 평점을 예측하는 방식  \n",
    "\n",
    "    - 잠재 요인  \n",
    "    모델이 데이터를 바탕으로 추정하는 **취향, 성향, 특징** 등  \n",
    "    평점 패턴을 분석하여 수치로 추정하는 값  \n",
    "        - Factor Model  \n",
    "        좌표계에 아이템, 유저의 구분 없이 표시하여 유사도를 계산  \n",
    "        - Latent Factor Model  \n",
    "        Factor Model에서 축이 무엇을 의미하는지, 몇 개의 차원이 있는지 알 수 없다.  \n",
    "        -> 사람이 명시적으로 이해할 수 없는 잠재적인 차원을 통해 평점을 예측하는 모델  \n",
    "    - 행렬 분해  \n",
    "    유저-아이템 행렬을 -> 유저 행렬*아이템 행렬로 분해  \n",
    "    -> 평점을 유저의 잠재 요인과 아이템의 잠재 요인의 내적으로 설명 -> 평점을 예측  \n",
    "\n",
    "    - 정리  \n",
    "    행렬 분해 -> 유저 잠재 요인, 아이템 잠재 요인 벡터 생성 -> 잠재 요인 벡터 간 계산으로 평점 예측  \n",
    "    (Latent Factor Model의 보이지 않는 축, 차원에서)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b864745",
   "metadata": {},
   "source": [
    "> ### 4. 추천시스템 평가  \n",
    "추천시스템의 성장을 위해 꼭 필요한 평가과정  \n",
    "\n",
    "1. 오프라인 평가(실시간 연동 x)  \n",
    "사용자 행동의 과거의 로그를 사용 -> 미래의 사용자 행동에 대한 예측  \n",
    "    - 평가 지표  \n",
    "        - 예측 오차 지표: MAE, MSE, RMSE  \n",
    "        - 집합 평가 지표: Precision, Recall, F1-score  \n",
    "        - 순위 평가 지표: PR곡선(k를 조정하면서, Precision과 Recall의 AUC)  \n",
    "        ![pr곡선](https://blog.kakaocdn.net/dna/UJbvM/btrHTrCh89y/AAAAAAAAAAAAAAAAAAAAADa0IepdD8c3xO2W-7X8OqJtM-5zsMVdnrIVTTBAHXDl/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=7EbIC35JTakiYTkvF4UTjZoorIY%3D)  \n",
    "        MRR(최초의 적합 아이템이 사용자 순위에서 얼마나 상위에 위치하는지)  \n",
    "        AP(순위의 k번째까지 아이템들의 Precision의 평균)  \n",
    "        MAP(AP를 각 사용자에 대해 평균)  \n",
    "        nDCG(PR, MRR, AP, MAP에 구매 유무 등의 가중치를 붙여서 평가하는 방법)  \n",
    "        - 기타 지표 -> 필터 버블(비슷한 상품만 추천하는 문제)을 해결할 수 있음  \n",
    "        카탈로그 커버리지(추천된 아이템/모든 아이템): 인기 상품에 치우치는 문제 해결  \n",
    "        사용자 커버리지(추천이 수행된 사용자/모든 사용자): 콜드 스타트 문제 해결  \n",
    "        신규성: 사용자에 대해 어떤 아이템이 과거에 추천된 경우를 사용  \n",
    "        다양성: 유사도 거리를 활용  \n",
    "        흥미로움: 사용자 순위에서 유용함과 의외성을 측정  \n",
    "\n",
    "2. 온라인 평가(실시간 연동 o)  \n",
    "추천 모델, 인터페이스를 실제로 표시하여 평가를 수행  \n",
    "    - A/B 테스트  \n",
    "    사용자들 두 그룹으로 나누어, 한 그룹에 추천 모델과 UI를 적용  \n",
    "    -> 각 그룹의 행동로그를 수집하여 판단  \n",
    "\n",
    "        - 평가 지표\n",
    "        - OEC 지표: 테스트의 성공/실패를 판단  \n",
    "        행복감, 몰입, 새 사용자, 사용 유지, 일의 효율성  \n",
    "        - 가드레일 지표: 테스트 사용자들에게 나쁜 영향(저하)을 미치지 않았는지 판단  \n",
    "        열람 수, 사용자 수, 수익금, 속도, 기동률 등  \n",
    "        - 주의점  \n",
    "        그룹 편향에 유의  \n",
    "        충분한 사용자 수 필요  \n",
    "        A/B 집단의 로그를 혼합할 필요  \n",
    "        집계 기간 중 부정적 반응 우려  \n",
    "\n",
    "    - 인터리빙(더 효율적인 방식)  \n",
    "    평가 대상의 각 순위를 하나의 순위로 섞어 사용자에게 제시  \n",
    "    -> 뒤섞인 순위에 대한 클릭으로 원래 순위를 평가함\n",
    "\n",
    "3. 사용자 스터디  \n",
    "사용자에게 직접 인터뷰나 설문을 통해 데이터 취득  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc504fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32b387",
   "metadata": {},
   "source": [
    "> ### 1. 연관 분석이란\n",
    "\n",
    "상품/서비스 구매, 합병증 등 **사건에 존재하는 항목 간의 연관 규칙**을 발견하는 분석  \n",
    "\n",
    "> 연관분석의 특성  \n",
    "-  'A를 구매하면 B또한 구매할 것이다' 식의 **명제 형식**으로 나타남  \n",
    "조건절: A를 구매하면  \n",
    "결과절: B또한 구매할 것이다\n",
    "아이템 집합(Item set): A, B (여러개 아이템이 있어도 되지만, 상호 배반이어야 한다.)  \n",
    "\n",
    "- **인과관계를 알 수 없다**  \n",
    "연관분석으로는 상관관계를 판단할 뿐, 인과관계를 알 수 없다.  \n",
    "'A->B의 신뢰도가 0.8': A를 산 사람 중 **80%는** B**도** 샀다. (A를 사면 B를 산다 X)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be03724",
   "metadata": {},
   "source": [
    "> ### 2. 연관분석의 주요 개념  \n",
    "\n",
    "> 적절한 연관규칙의 조건  \n",
    "1. 일정 이상의 지지도: 두 품목(A,B)을 함께 구매한 경우의 수가 일정 이상  \n",
    "2. 일정 이상의 신뢰도: A를 포함하는 모든 거래 중 B를 구입하는 경우의 수가 일정 이상  \n",
    "\n",
    "- 지지도: 명제에서 조건절이 발생할 확률, 즉 A거래와 B거래의 교집합  \n",
    "-> 이 규칙이 현실에서 의미 있는가?를 판단하는 1차 기준  \n",
    "\n",
    "- 신뢰도: A가 포함된 거래 전체에서 A,B가 포함된 거래의 비율  \n",
    "즉, $P(A \\cap B)/P(A)$  \n",
    "\n",
    "> 연관분석의 평가 측도  \n",
    "- 향상도(Lift)  \n",
    "\"A와 B가 자주 같이 등장하는 게 과연 우연일까? 진짜 상관관계일까?\"  \n",
    "A가 주어지지 않았을때 B의 확률 대비, A가 주어질 때 B의 확률의 **증가 비율**  \n",
    "즉, 우연적 기회보다 높을 확률  \n",
    "\n",
    "    공식: $향상도=P(A \\cap B)/P(A)P(B)=신뢰도/P(B)$  \n",
    "\n",
    "    향상도=1: $P(A \\cap B)=P(A)P(B)$이므로 A를 사는 것과 B를 사는 것은 독립적  \n",
    "    향상도>1: 우연적 기회보다 높은 상관성  \n",
    "    향상도<1: 우연적 기회보다 낮은 상관성  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf21029",
   "metadata": {},
   "source": [
    "> ### 3. 연관분석 알고리즘 - Apriori  \n",
    "\n",
    "상위 조합부터 차례로 스캔 -> 특정 조합이 자주 발생하지 않으면(설정된 최소 지지도를 넘지 못하면), 후속 조합들을 배제하는 알고리즘  \n",
    "-> 장점: 연산량을 줄일 수 있다.\n",
    "\n",
    "- 과정: 빈발 항목 집합(최소 지지도를 넘는 조합)을 찾고 -> 단계적으로 조합 생성, 필터링  \n",
    "    1. 단일 항목 집합 생성  \n",
    "    모든 개별 상품에 대한 지지도를 계산 -> 최소 지지도를 넘는 항목 선별  \n",
    "    2. 2개 항목 집합{A,B} 생성  \n",
    "    1번에서 2개 항목에 대한 지지도를 계산, 최소 지지도를 넘지 못하면 제거  \n",
    "    3. 더 큰 항목 집합 생성  \n",
    "    2번에서 살아남은 집합을 바탕으로 3개 이상의 항목으로 구성된 조합 생성  \n",
    "    최소 지지도를 넘지 못한 조합 제거  \n",
    "    더 이상 조합을 생성할 수 없을 때까지 반복  \n",
    "    4. 최종 빈발 항목 집합 생성  \n",
    "    5. 연관 규칙 생성, 지지도&신뢰도&향상도를 통해 유용한 규칙을 판단  \n",
    "\n",
    "\n",
    "- 장점  \n",
    "수많은 상품에 대한 연관 구매패턴 발견 가능  \n",
    "다른 가설 탐지  \n",
    "원리와 분석이 간단  \n",
    "\n",
    "- 단점  \n",
    "비즈니스 측면에서 복잡한 연관 규칙을 이해하기는 부족  \n",
    "데이터가 많아지면 계산이 느림  \n",
    "\n",
    "- 파이썬 라이브러리  \n",
    "```python\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# 최소 지지도=0.06 으로 설정\n",
    "frequent_itemsets = apriori(df, min_support=0.06, use_colnames=True)\n",
    "\n",
    "# 연관 규칙을 추출하고, 그 중 신뢰도 0.8 이상의 규칙을 살아남게 함\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.8)\n",
    "\n",
    "# 향상도(lift)를 기준으로 내림차순 정렬\n",
    "top_rules = rules.sort_values(by='lift', ascending=False).head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c926e7d",
   "metadata": {},
   "source": [
    "> ### 4. 연관분석 알고리즘 - FP Growth\n",
    "\n",
    "apriori의 계산 속도 문제를 해결하기 위해 FP-tree라는 트리형 자료구조를 도입한 알고리즘  \n",
    "\n",
    "- FP-tree 구조\n",
    "    1. 모든 거래 확인, 아이템별 지지도 계산  \n",
    "    2. 높은 지지도의 아이템부터 가지를 뻗어나감  \n",
    "    3. 부모 노드를 중심으로, 거래를 자식 노드로 추가  \n",
    "    4. 새로운 아이템은 새 부모 노드로 추가  \n",
    "    5. 트리에서 최소 지지도 이상의 패턴만 추출  \n",
    "\n",
    "- 과정  \n",
    "    1. 빈발 항목 필터링  \n",
    "    모든 항목의 빈도 계산 -> 최소 지지도를 넘는 항목 선별  \n",
    "    2. 데이터 재정렬  \n",
    "    1번의 항목들을 거래의 빈도별(많이 거래되는 순)로 재정렬한다.  \n",
    "    3. FP-tree 생성  \n",
    "    위의 트리 과정을 따라 트리를 생성한다.  \n",
    "    4. 빈발 항목 집합 추출  \n",
    "    3번의 트리를 바탕으로, 특정 항목을 기준으로 한 부분 트리를 만든다.  \n",
    "    이 부분 트리는 기준 상품을 기반으로 빈발 항목 집합을 빠르게 도출한다.  \n",
    "    5. 연관 규칙 생성, 지지도&신뢰도&향상도를 통해 유용한 규칙을 판단  \n",
    "\n",
    "- 장점  \n",
    "데이터를 두 번만 스캔한다. -> (매번 스캔하는) Apriori보다 빠르다  \n",
    "아이템 셋 대신에 트리를 구성하면 되므로 효율적이다  \n",
    "\n",
    "- 단점  \n",
    "메모리의 효율성이 떨어진다  \n",
    "설계가 복잡하고, 트리의 생성 이후 지지도를 계산할 수 있다.  \n",
    "\n",
    "- 파이썬 라이브러리  \n",
    "```python\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# 최소 지지도=0.06 으로 설정\n",
    "frequent_itemsets = fpgrowth(df, min_support=0.06, use_colnames=True)\n",
    "\n",
    "# 연관 규칙을 추출하고, 그 중 신뢰도 0.8 이상의 규칙을 살아남게 함\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.8)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
