{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7cfce6",
   "metadata": {},
   "source": [
    "### 머신러닝\n",
    "1. 머신러닝이란?\n",
    ": 인공지능의 한 분야로, 모델이라는 소프트웨어를 학습하여 새로운 데이터를 예측하거나 결정을 내릴 수 있도록 하는 기술\n",
    "\n",
    "2. 머신러닝의 종류\n",
    "1) 지도학습: 정답이 있는 데이터 사용 | 예측값을 사전에 만들어둔 정답과 같아지도록 기계 학습 | 회귀, 분류\n",
    "2) 비지도학습: 정답이 없는 데이터 사용 | 데이터 속의 패턴이나 유사도를 기계가 학습하도록 하는 것 | 군집화\n",
    "3) 강화학습: 시행착오를 반복하여 정답을 찾음 | 알파고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c78480",
   "metadata": {},
   "source": [
    "### 비지도학습 추가\n",
    "1. target이나 label 없이 feature만 있는 데이터. \n",
    "2. 인간 개입 없이 '스스로' 유사도(similarity)를 학습해 분류되지 않은 데이터에서 구조나 패턴을 찾음\n",
    "3. 비지도 학습의 종류\n",
    "* 군집화: 비슷한 데이터를 묶어 큰 단위로 만듦\n",
    "* 밀도 추정: 데이터 분포를 예측함\n",
    "* 차원 축소: 데이터 차원을 간추림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6374382a",
   "metadata": {},
   "source": [
    "### 지도 학습 추가 : 회귀와 분류\n",
    "1. labeled data: 독립변수(feature)와 종속변수(target/label)이 모두 존재하는 데이터\n",
    "2. labeled data를 traning set과 test set을 나눔\n",
    "3. training set을 통해 모델을 학습 = 미리 설정한 종속변수에 독립변수가 가까워지도록 만듦\n",
    "4. 기계의 예측이 우리가 의도한 정답이 되도록 지도(supervise)함\n",
    "\n",
    "* train data:모델을 학습(훈련)\n",
    "* test data: 학습된 모델을 검증 -> 안보이는 데이터 (단순 암기일 수도 있으니까...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae57b3",
   "metadata": {},
   "source": [
    "### 회귀와 분류\n",
    "1. 회귀: 주어진 데이터를 기반으로 정답을 잘맞추는 함수 (x값 기반으로 y를 얼마나 잘 맞출 수 있을까?)\n",
    "* 연속형 범주를 예측하기 위해 사용 \n",
    "2. 분류: 기존 데이터가 어떤 레이블에 속하는지 패턴을 인지한 뒤에 새로운 데이터도 레이블을 판별\n",
    "* 범주형 범주를 예측하기 위해 사용\n",
    "\n",
    "이때, 예측하고자 하는 값은 종속변수를 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdefba",
   "metadata": {},
   "source": [
    "### 회귀와 모델링\n",
    "1. 회귀란?\n",
    "* 데이터에서 패턴을 찾아내어 미래 값을 예측하는 것\n",
    "* 통계나 머신러닝의 주요 개념으로 연속적인 숫자를 다룸\n",
    "\n",
    "2. 회귀의 종류\n",
    "선형회귀, 비선형회귀, 릿지회귀, 라쏘회귀, 다항회귀 등\n",
    "\n",
    "3. 선형회귀란?\n",
    ": 데이터를 가장 잘 설명하는 회귀선 (y=ax+b)를 찾는 과정\n",
    "* 이는 현재의 데이터를 요약하고 관측되지 않은 미래 값을 예측하는 도구가 됨\n",
    "* 예를 들어 시간에 따른 주가 예측을 하고자 하면 x=시간, y=주가\n",
    "* 선형회귀 기본 가정 (다음 회귀 심화 세션에서 배운다고 한다! 커밍 순,,,)\n",
    "1. 선형성: 종속- 독립 관계가 선형적이어야 함\n",
    "2. 독립성: 관측치가 서로에게 영향을 주지 않는 독립성을 지녀야 함\n",
    "3. 등분산성: 오차 항의 분산이 일정해야 함.\n",
    "4. 정규성: 오차 항이 정규 분포를 따라야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4731e2b0",
   "metadata": {},
   "source": [
    "### 단순 선형 회귀 분석 (1)\n",
    "1. 단순: 하나의 독립변수만 존재하는 선형 회귀\n",
    "2. y=ax+b를 찾는 과정이며, a는 기울기이자 회귀계수, b는 y절편을 의미한다.\n",
    "3. 그렇다면 어떻게 a와 b를 잘 찾을 수 있을까? => 잔차를 줄여나가자!\n",
    "* 참고: 오차와 잔차의 차이\n",
    "* 오차: 실제값 - 실제 평균값 간의 차이\n",
    "* 잔차: 실제값 - 예측값 간의 차이\n",
    "4. 최소제곱법: 잔차의 제곱의 합이 최소가 되는 지점으로 최적의 회귀선을 구하는 방식\n",
    "* 왜 제곱을 할까? 양수, 음수가 서로 상쇄하는 것을 방지하기 위해... 등등\n",
    "5. 경사하강법: 최소제곱법을 통해 구한 함수가 복잡하여 최솟값을 구하기 어려울 때\n",
    "* 함수가 닫힌 상태거나, 미분계수 구하기 어렵거나, Gradient Descent를 구현하는게 미분 계수를 구하는 것보다 더 귑거나, 데이터 양이 너무 많은 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead372e",
   "metadata": {},
   "source": [
    "### 단순 선형 회귀 분석 (2)\n",
    "0. 들어가기에 앞서...\n",
    "1. 목적함수: 최적화를 위해 오차를 최소화하는 것이 목적이 함수\n",
    "* 모델의 예측이 얼마나 잘 맞는지 평가하는 기준이 필요할 텐데, 그게 목적 함수!\n",
    "\n",
    "2. 손실함수: 한 개의 데이터 포인트에 대해 모델이 얼마나 틀렸는지를 평가\n",
    "* 예측값과 실제값의 차이를 계산 -> 개별 데이터의 오차를 측정한다고 보면 편함.\n",
    "\n",
    "3. 비용함수: 전체 데이터셋에서 평균적인 손실을 측정하는 함수\n",
    "* 손실함수를 모든 데이터 포인트에 대해 계산한 후 평균 혹은 합산한 값\n",
    "* 머신러닝에서는 대부분 모델을 훈련할 때 비용함수를 최적화 하는 것이 목표!!\n",
    "* 손실함수에 시그마 한다고 보면 편할 듯!\n",
    "* 대부분은 비용함수를 '최소화'하는 것이 목표이지만, 강화학습의 경우 '최대화'가 목표이기도 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d65a49",
   "metadata": {},
   "source": [
    "0. 손실함수 원리\n",
    "* 만약 현재 값이 최솟값의 왼쪽, 기울기(미분 값)가 음수 -> 현재 값 - 미분 값(음수) = **오른쪽으로 점이 이동**\n",
    "- 만약 현재 값이 최솟값의 오른쪽, 기울기(미분 값)가 양수 -> 현재 값 - 미분 값(양수) = **왼쪽으로 점이 이동**\n",
    "- **최솟값 도달시, 미분값이 0** = 변화 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c5b8ad",
   "metadata": {},
   "source": [
    "1. 학습률 원리 - 얼만큼?!\n",
    "** 적당히 ** 가 가장 좋음!\n",
    "* 만약 Learning Rate가 너무 작으면, 모델까지 너무 오래 걸림\n",
    "* 만약 Learning Rate가 너무 크다면, 수렴하지 못하고 발산 = 손실값이 계속 커짐\n",
    "* 학습률은 누가 정해줄까? -> 개발자가 직접 설정! ... 더 자세한 사항은 커밍순..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ed2653",
   "metadata": {},
   "source": [
    "2. Local Minima 문제 : 실제 이동량을 보면 작은 기울기에서 조금씩, 큰 기울기에서 많이 이동함\n",
    "* 왜냐하면 모든 비용함수가 하나의 최솟값을 가지는 매끈한 곡선이 아니라서 필연적임\n",
    "* 따라서 중간에 울퉁불퉁한 부분 = local minima를 탈출하는 방법이 필요함!\n",
    "* **해결법 = 모멘텀**\n",
    "* 경사하강법은 현재 기울기만 기준으로 움직이지만, 모멘텀은 이전의 기울기나 이동해오던 방향을 고려하도록 관성을 부여해주는 방식이다.\n",
    "* 작은 기울기를 쉽게 넘어갈 수 있게 만들어줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562e36d",
   "metadata": {},
   "source": [
    "### 다중선형회귀분석 \n",
    "1. 독립변수가 2개 이상인 경우의 선형회귀\n",
    "2. 단순회귀분석과 마찬가지로 최소제곱법을 사용함. 파악이 힘들 땐 경사하강법을 사용하는 것도 동일.\n",
    "3. 다중공선성 : 회귀분석에서 독립 변수들 간에 상관관계가 큰 경우 발생함.\n",
    "* 변수들끼리 독립적이지 않으면, 어떤 변수가 종속변수가 영향을 미쳤는지 정확하게 알기 어려워서 회귀분석의 정확도가 낮아지는 문제가 발생함 -> 따라서 매우 중요한 체크 사항 !!\n",
    "* **다중공선성 확인 방법**\n",
    "1. 상관관계 활용 : 상관계수(r)는 -1과 1 사이에 존재하는데, -1과 1에 가까울 수록 상관성이 높음.\n",
    "2. sns. heatmap 혹은  corr() 함수를 통해 활용할 수 있음\n",
    "3. VIF지수 (분산 팽창 인수) : VIF가 높으면 다중공선성이 존재한다고 판단한다. (10이상이면 큰 것!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ea9cd",
   "metadata": {},
   "source": [
    "### 규제선형모델 : 모델이 학습데이터에 과적합 되지 않도록 규제를 가하고자 등장한 것\n",
    "1. 선형 회귀모델에서는 특성에 곱해지는 계수(기울기)의 크기를 조정하는 것\n",
    "2. 기존 선형 모델에서는 최소제곱법처럼 잔차제곱합을 최소화하면서 비용함수를 설정했지만, 회귀계수가 커지면서 **overfitting** 이 발생\n",
    "3. 결국, 오류는 최대한 줄이면서도, 특정 변수에 집착하지 않도록 균형을 맞춰 과적합을 방지\n",
    "4. **규제 (Regularization)**\n",
    "= 비용 함수에 alpha 값으로 페널티를 부여해, 회귀 계수 크기를 감소시켜 과적합을 개선하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07511f",
   "metadata": {},
   "source": [
    "규제선형모델의 종류\n",
    "1. L2규제 = 회귀계수 제곱에 대해 페널티 부여 = **릿지회귀**\n",
    "* 기둥크기에 따라 다른 힘으로 누르는 망치 => 전체적인 크기가 작아짐\n",
    "* 모든 변수를 유지하면서도 크기를 적절히 줄여 과적합 방지\n",
    "* 예측 변수가 많을 때, 다중공선성이 존재할 때\n",
    "2. L1규제 = 회귀계수의 절댓값에 대해 패널티 부여 = **라쏘회귀**\n",
    "* 모든 기둥을 같은 힘으로 누르는 회귀\n",
    "* 비중이 낮은 변수는 아예 사라지고 중요한 변수만 남음\n",
    "* 예측 변수 수가 많고, 중요한 건 일부일 때 | 모델의 해석을 간단하게 유지하고자 할 때\n",
    "3. L2규제 + L1규제 = **엘라스틱넷 회귀**\n",
    "* 불필요한 변수는 제거하고, 남은 변수들은 적절한 크기로 유지\n",
    "* 안정적인 예측과 희소성을 동시에 달성할 수 있음\n",
    "* 예측 변수 수가 많고 그 중 중요한 변수를 선택하면서도 다중공선성을 관리할 때"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e8a3b",
   "metadata": {},
   "source": [
    "### 모델 평가 방법\n",
    "성능 평가지표\n",
    "1. **평균제곱오차 **\n",
    "* 오차제곱의 평균을 의미\n",
    "* 모델의 예측 성능을 평가하는 지표 중 하나\n",
    "2. 평균 절대 오차 \n",
    "* 예측값과 실제 관측값 사이의 절대값 오차의 평균\n",
    "* 모델의 예측 성능을 평가하는 지표 중 하나\n",
    "\n",
    "변수 유의성 평가\n",
    "1. t-검정\n",
    "* 독립변수의 회귀계수가 유의미한지 검정하는데에 사용\n",
    "* t 값이 크면 귀무가설을 기각할 가능성이 높아짐\n",
    "2. p-value 확인 및 판단\n",
    "* p-value가 작을 수록 해당 변수는 종속변수에 더 큰 영향을 줄 확률이 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb663d87",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
