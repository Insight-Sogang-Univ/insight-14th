{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c18567",
   "metadata": {},
   "source": [
    "# 군집화(Clusting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5022c86",
   "metadata": {},
   "source": [
    "## 머신러닝 - 비지도 학습\n",
    "**머신러닝**: 인공지능의 한 분야로, **컴퓨터가 스스로 학습**할 수 있도록 도와주는 알고리즘이나\n",
    "기술을 개발하는 분야, 크게 지도학습과 비지도학습으로 구분됨. <br>\n",
    "<br>\n",
    "비지도학습은 지도학습과 달리 정답이 없는 데이터를 사용하며, 데이터 속의 패턴 또는 각 데이터 간의 유사도를 기계가 학습하도록 하는 것으로, 군집화에서 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12a16a",
   "metadata": {},
   "source": [
    "### 비지도학습의 특징 <br>\n",
    "1. 데이터 자체에 내제된 구조를 파악해서 학습함\n",
    "2. 정답이 없어서 에이전트가 해야하는 작업이 명확히 정의되지 않음. <br>\n",
    "즉, **모델의 성능을 정확히 측정할 수 없다**\n",
    "3. 표현 학습(또는 피처 학습)을 통해 데이터셋의 고유 패턴을 식별할 수 있다.\n",
    "<br>\n",
    "<br>\n",
    "**목표 자체가 명확하지 않고, 데이터에서 새로운 특성을 찾는 등의 목적을 수행하기에 적합함**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af4764",
   "metadata": {},
   "source": [
    "### 비지도학습이 적합한 케이스\n",
    "1. 패턴이 아직 알려지지 않은 경우 -> 정답을 아직 알 수 없어서\n",
    "2. 패턴이 계속해서 변하는 경우 -> 답이 계속 변하니까 정답을 익혀도 큰 의미가 없음\n",
    "3. 열린 문제를 해결하고 지식을 일반화해야 하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab8cd38",
   "metadata": {},
   "source": [
    "## 군집화란?\n",
    ": 데이터를 비슷한 특성을 가진 그룹(군집)으로 나누는 비지도 학습 기법!\n",
    "<br>\n",
    "+ 군집: 유사한 데이터들의 집합 | 군집이 다르면 개체들이 겹치면 안됨!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0aaff0",
   "metadata": {},
   "source": [
    "### 비지도학습:군집화\n",
    ":종속 변수를 설정하지 않고, 데이터 내부의 패턴을 인식해 유사성을 가진 그룹으로 나눔.\n",
    "<br>\n",
    "즉, **비지도학습**이다! 목표 설정을 미리 안하니까!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8cc37",
   "metadata": {},
   "source": [
    "### 군집화의 목표\n",
    ": 유사성을 기반으로 비슷한 특징을 지닌 개체를 그룹화하며, 두 개의 목표를 지닌다.\n",
    "<br>\n",
    "1. 응집도 최대화: 같은 군집에 속하는 데이터끼리 최대한 비슷하게 만들기\n",
    "2. 분리도 최대한: 서로 다른 군집은 최대한 분리되도록 하기\n",
    "<br> -> 즉, 데이터간 유사성을 잘 유지하면서, 서로 다른 그룹은 구별될 수 있도록 만드는 것이 목표!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84efce93",
   "metadata": {},
   "source": [
    "### 군집화의 기본 과정\n",
    "**1️. 피처 선택 또는 추출** - 군집화에 사용할 데이터의 피처(특징)을 선택 <br>\n",
    "**2️. 군집화 알고리즘 선택** - 데이터의 특성과 목표에 따라 적합한 군집화 알고리즘을 선택<br>\n",
    "**3️. 군집 유효성 검증** - 군집화가 얼마나 잘 되었는지 평가<br>\n",
    "**4️. 결과 해석** - 각 군집이 지닌 특성 분석 및 해석<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead72e18",
   "metadata": {},
   "source": [
    "## 군집화를 위한 데이터 준비\n",
    "주의사항: 한 번의 시도로 끝나는 것이 아니라, 반복 시도를 통해 최적의 결과를 찾아내는 과정이다. <br>\n",
    "효과적인 군집화를 하려면 세가지 주요 사항이 있다.\n",
    "<br>\n",
    "<br>\n",
    "1. 변수 유형 이해\n",
    "* 피처의 종류와 특성을 명확하게 이해해야 함!\n",
    "2. 거리/ 유사도 정의와 측정\n",
    "* 거리와 유사도로 군집화가 되기 때문에, 거리 측정 방법에 대한 정의가 중요함!\n",
    "3. 차원 축소\n",
    "* 모델의 성능을 향상시키려면 유사한 변수를 묶어 처리하는 차원 축소를 고려해야 함\n",
    "* 변수가 많아지면 성능과 효율성이 떨어지기 때문에 불필요한 변수를 제거해서 변수 개수를 줄일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f01fdc",
   "metadata": {},
   "source": [
    "####  변수 유형 이해\n",
    "1. 연속형 변수 (키, 몸무게 등) | 스케일링(단위 맞추기) 필수\n",
    "2. 명목형 변수 (성별, 지역 등) | 원-핫 인코딩 또는 더미 변수 변환\n",
    "3. 혼합형 변수 | 각 변수 유형에 맞는 거리 함수를 조합하여 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fe792",
   "metadata": {},
   "source": [
    "#### 거리 / 유사도 정의와 측정\n",
    "<br>\n",
    "<데이터의 거리 측정 방법> <br>\n",
    "1. 유클리디안 거리: 직선거리(x,y 좌표들 빼고 제곱하고 sum해서 루트)\n",
    "2. 맨하탄 거리: 절댓값의 합\n",
    "3. 코사인 유사도: 백터간의 각도를 측정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2f845",
   "metadata": {},
   "source": [
    "#### 6가지 연결 방법\n",
    "1. 단일 연결법 = 최단 연결법 <br>\n",
    "* 군집 A와 B 사이의 가장 가까운 두 점 간 거리로 군집 간 거리를 정의\n",
    "* 고립된 군집을 찾는데 중점을 두고 있음\n",
    "* 이상치에 취약함 -> 연쇄적으로 잘못된 클러스터링을 유발할 수 있음\n",
    "<br>\n",
    "2. 완전 연결법 = 최장 연결법 \n",
    "* 군집 A와 B 사이의 가장 먼 두 점 간 거리로 군집 간 거리 정의\n",
    "* 나타날 수 있는 거리의 최댓값으로 측정하여 유사성이 큰 군집으로 병합해 나가는 방법\n",
    "* 군집들의 내주 응집성에 중점을 둔 방법\n",
    "* 이상치에 민감함\n",
    "<br>\n",
    "3. 평균 연결법\n",
    "* 군집 A와 B의 모든 점 쌍 사이 거리의 평균\n",
    "* 모든 항목에 대한 거리 평균을 구함\n",
    "* 계산량이 불필요하게 많아질 수 있음\n",
    "<br>\n",
    "4. 중심 연결법\n",
    "* 각 군집의 중심점 간의 거리\n",
    "* 두 군집이 결합될 때 새로운 군집의 평균은 가중평균을 통해 구함\n",
    "* 시간이 오래 걸림 -> 군집들의 중심을 계산해야 해서!\n",
    "* inversion(거리 축이 위에서 아래로 줄어듦)이 발생할 가능성이 있음\n",
    "<br>\n",
    "5. 중앙 연결법\n",
    "* 두 군집을 합친 뒤의 중심점과 기존 군집의 중심점 간의 거리 기번\n",
    "* 군집간의 거리를 두 군집 내 모든 샘플의 중앙값으로 정의\n",
    "* 데이터의 중앙값에 기반해 군집 간 거리를 정의 -> 극단값 영향을 덜 받음\n",
    "* 기하학적 구조 파악은 어렵다\n",
    "<br>\n",
    "6. Ward 연결법\n",
    "* 군집 내 제곱합이 증가하지 않도록 병합\n",
    "* 군집의 병합 후 군집내 오차제곱합의 증가분이 최소인 것을 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f343c9",
   "metadata": {},
   "source": [
    "### 차원 축소\n",
    "1. 차원의 저주: 피처 공간이 너무 커서 알고리즘이 데이터를 효과적으로 훈련 못하는 현상<br>\n",
    "이는 고차원일수록 모든 점이 비슷하게 멀어져, 거리 기반 알고리즘의 분별력이 감소함\n",
    "<br>\n",
    "따라서\n",
    "<br>\n",
    "<br>\n",
    "**차원 축소**를 수행해야 한다. 쉽게 말하면, 변수의 개수를 줄이는 것!\n",
    "<br>\n",
    "차원 축소의 목표ㅣ 고차원 데이터를 저차원 공간에 투영하면서도 핵심 정보는 가능한 지켜내는 것 <br>\n",
    "차원 축소의 유형<br>\n",
    "1. 선형 투영 : 고-> 저차원으로 선형적으로 데이터 투영 <br>\n",
    "2. 비선형 차원 축소: 유클리드 거리가 아닌 곡선거리를 고려하며 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed80de",
   "metadata": {},
   "source": [
    "#### **PCA**: 가장 정보량이 큰 방향을 찾고, 그 방향을 기준으로 데이터를 투영하여 차원을 줄이는 것 <br>\n",
    "* 분산을 최대한 보전하면서 차원을 축소함\n",
    "* 원본의 고차원 데이터에서 최대 분산 방향을 찾아 상관관계를 감소시키고, 저차원 공간에 투영하는데, 새로 파생된 성분을 *주성분* 이라고 함\n",
    "<br>\n",
    "<br>\n",
    "주의 사항 <br>\n",
    "1. 표준화 필수\n",
    "2. 결측값 처리\n",
    "3. 해석의 어려움\n",
    "4. 정보 손실"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f0a009",
   "metadata": {},
   "source": [
    "## 군집화 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447871d",
   "metadata": {},
   "source": [
    "### 계층적 군집화\n",
    ": 데이터 간의 유사성을 기반으로 트리 구조를 형성하며, 상향식 또는 하향식 방식으오 군집을 형성해 나가는 방법 <br>\n",
    "<br>\n",
    "계층적 군집화의 특징\n",
    "* 데이터셋의 알고리즘은 데이터셋의 관측치를 사용해 덴드로그램(두 군집이 병합될 때 군집간 거리)을 만듬. \n",
    "* 군집의 개수를 사전에 설정하지 않고, 클러스팅 종료 후 원하는 군집의 개수를 선택할 수 있음\n",
    "* 트리구조 상향식 - 응집형 계층적 군집화 | 트리구조 하향식 - 분리형 계층적 군집화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86443323",
   "metadata": {},
   "source": [
    "#### 응집형 계층적 군집화\n",
    ": 모든 데이터 포인트를 하나의 클러스터로 간주하고 시작해, 가까운 클러스터들을 병합해 나가는 방식\n",
    "* 단일연결 (가장 가까운 거리) | 완전 연결(가장 먼 두 샘플의 거리)\n",
    "<br>\n",
    "<br> \n",
    "\n",
    "1. **거리 행렬 계산**: 모든 데이터 포인트 간의 거리를 계산하여 거리 행렬을 만듭니다.\n",
    "2. **단일 클러스터 시작**: 각 데이터 포인트를 개별적인 클러스터로 초기화합니다.\n",
    "3. **가장 가까운 클러스터 병합**: 정의된 기준(가장 멀리 있는 샘플 간의 거리)에 따라, 가장 가까운 두 클러스터를 병합하여 새로운 클러스터를 만듭니다.\n",
    "4. **거리 행렬 업데이트**: 새로 생성된 클러스터와 나머지 클러스터들 간의 거리를 다시 계산하여 거리 행렬을 업데이트합니다.\n",
    "5. **반복**: 모든 데이터 포인트가 하나의 클러스터에 속할 때까지 3, 4번 과정을 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c90ee",
   "metadata": {},
   "source": [
    "#### 계층적 군집화 \n",
    "-> 계산량이 많아서 대규모 데이터에 적용하기보다, 소규모 데이터에 대해 군집 수를 탐색하거나 시각적 분석 시에 유용함!_!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be9ac8",
   "metadata": {},
   "source": [
    "### K-means\n",
    ": 데이터를 정해진 개수의 그룹으로 나누되, 각 그룹의 중심점과 거리가 가장 가까운 데이터끼리 묶는 군집화 알고리즘\n",
    "* 주요 단계 \n",
    "1. 데이터 표본들 중에서 랜덤하게 k개의 중심점(centroid)을 초기 클러스터 중심으로 선택\n",
    "2. 각 표본들을 가장 가까운 중심점에 할당 <br>\n",
    "How?  보통 **유클리디안 거리의 제곱(squared Euclidean distance)**을 사용\n",
    "3. 각 클러스터에 할당된 표본들의 데이터 평균을 계산하여 중심점(centroid)을 이동\n",
    "4. 클러스터 할당이 변하지 않거나 사용자가 지정한 허용 오차 또는 최대 반복 횟수(max_iter)에 도달할 때까지 2, 3번을 반복\n",
    "* 장점: 직관적이고 구현이 쉬움\n",
    "* 단점: 초기 중심점 값에 민감함 | 군집 수 결정이 어려움 | 아웃라이어에 민감 | 기하학적 파악 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155e319",
   "metadata": {},
   "source": [
    "### K-means ++ 알고리즘\n",
    ":  k-means에서 초기 중심점들을 서로 멀리 떨어진 곳에 위치시켜 더 일관되고 좋은 결과를 도출하는 개선된 초기화 방법\n",
    "* 초기 중심점들을 서로 멀리 떨어진 곳에 위치시킴 -> k-mean보다 좋은 결과 도출 가능!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd1ff3",
   "metadata": {},
   "source": [
    "### 엘보우 방법\n",
    ":클래스 내 SSE를 바탕으로 그래프를 활용해 최적 클러스터 개수 k를 추정하는 방법\n",
    "* 왜곡이 빠르게 감소하는 지점의 k값을 찾는 것! -> 최적 클러스터의 개수로 추정\n",
    "* 장점: 직관적 | 구현이 간단\n",
    "* 단점 : 주관적 판단이 들어감 | 모호한 경우가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1efaf8",
   "metadata": {},
   "source": [
    "### DBSCAN \n",
    ": 밀도가 높은 지역의 데이터를 하나의 군집으로 묶고, 밀도 기준을 만족하지 못하는 점은 군집에 포함시키지 않는 군집화 알고리즘\n",
    "<br>\n",
    "밀집도 기반 군집화는 밀도 분포를 기반으로 고밀도 영역을 클러스터로 인식함!\n",
    "* 특징 : 이상치를 명시적으로 지정해 클러스터링에서 제외 | 이상치로부터 자유로움\n",
    "* 주요 단계\n",
    "1. 샘플 분류 : 핵심샘플|경계샘플|잡음샘플\n",
    "2. 클러스터 생성\n",
    "3. 경계 샘플 할당\n",
    "* 장점 : 이상치에 민감하지 않음\n",
    "* 딘점: epsilon 조절이 어려움 | 속도가 느림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d06e1",
   "metadata": {},
   "source": [
    "### HDBSCAN \n",
    ": 계층적으로 DBSCAN을 계층적 군집화처럼 변환한 버전\n",
    "* 밀도 기반으로 1차 군집화 한 뒤 거리 기준으로 밀도 기반 군집들을 반복적으로 연결\n",
    "* 장점: 여러 밀도 기준으로 반복 수행 | 한계 보안"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2f061",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model(GMM) \n",
    ": 데이터가 여러 다른 모양의 가우시안 분포로 구성되었다고 가정하고, 각 분포를 클러스터로 인식하는 군집화 방법\n",
    "* 단일 분포로 표현하기 어려운 형태의 확률 분포를 여러 개의 가우시안 분포를 합쳐서 표현\n",
    "* 데이터 생성 매커니즘까지 모델링 가능\n",
    "* 가정\n",
    "**관측된 데이터**: 특정 가우시안 확률 분포에 의해 생성됨 <br>\n",
    "**전체 데이터셋**: 여러 개의 다변량 가우시안 분포가 섞여있음<br>\n",
    "**개별 데이터**: 우도에 따라 K개의 가우시안 분포 중 하나에 속함<br>\n",
    "* 진행 과정<br>\n",
    "주어진 전체 데이터셋의 분포를 확인<br>\n",
    "전체 데이터 셋은 서로 다른 정규 분포 형태의 확률 분포 곡선으로 구성되어 있다고 가정 <br>\n",
    "전체 데이터셋을 구성하는 여러 개의 정규분포 곡선 추출, 개별 데이터가 이 중 어떤 정규분포에 속하는지 결정<br>\n",
    "* 장점 : k-mean보다 유연하게 적용 가능 | 타원형 분포에서도 사용 가능\n",
    "* 단점 : 군집화를 위한 수행 시간이 오래 걸림 | 계산 복잡도가 높아질 가능성 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca467f9",
   "metadata": {},
   "source": [
    "## 군집화 평가 방법\n",
    "1. 외부평가 : 정답 레이블이 존재하는 경우 정답과 비교해서 유사도 평가\n",
    "2. 내부평가: 정답 레이블이 없는 경우 군집 내부 응집도와 군집 간 분리도를 기반으로 품질을 정량적 측정 -> **데이터 자체의 구조를 기반으로 군집 품질을 판단**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5065e",
   "metadata": {},
   "source": [
    "### 실루엣 계수\n",
    ": 클러스터 내 샘플들이 얼마나 조밀하게 모여 있는지를 측정하는 도구 -> 품질 확인 가능\n",
    "* 해석\n",
    "* -1과 1사이 값을 가짐\n",
    "* 분리도 > 응집도 = 1에 가까움 = 군집화가 잘됨\n",
    "* 분리도 = 응집도 = 0에 가까움 = 군집 간 분리가 명확하지 않음\n",
    "* 분리도 < 응집도 = -1에 가까움 = 군집화가 잘못됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a416d",
   "metadata": {},
   "source": [
    "### Dunn Index\n",
    ":: 클러스터 간 최소 거리(분리도)와 클러스터 내 최대 거리(응집도)의 비율을 계산해 클러스터링의 품질을 평가하는 지표\n",
    "* Dunn Index 값이 클수록 좋은 군집화 결과를 의미\n",
    "* 일반적으로 0 이상의 값을 가지며, 무한대까지 가능\n",
    "* 다만, 이상치에 민감하게 반응해 수치가 급격하게 감소할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb045a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
