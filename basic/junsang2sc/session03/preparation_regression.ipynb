{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0940d85e",
   "metadata": {},
   "source": [
    "># **회귀 기초**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a34d1",
   "metadata": {},
   "source": [
    "## **머신러닝과 모델링**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead4be4",
   "metadata": {},
   "source": [
    "### 1. 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4bdd4b",
   "metadata": {},
   "source": [
    "머신러닝: 인공지능의 한 분야로 모델이라는 소프트웨어를 학습하여 새로운 데이터를 예측하거나 결정을 내릴 수 있도록 하는 기술       \n",
    "> 패턴을 찾아내고, 패턴을 바탕으로 새로운 데이터에 대한 예측을 가능하게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d310631d",
   "metadata": {},
   "source": [
    "1. 지도학습: 정답이 있는 데이터를 활용\n",
    "- 예측값을 이미 만들어둔 정답과 같도록 만드는 것 (회귀, 분류)\n",
    "2. 비지도학습: 정답이 없는 데이터를 활용\n",
    "- 데이터 속의 패턴 또는 각 데이터 간의 유사도를 기계가 학습하도록 하는 것 (군집분석)\n",
    "3. 강화학습: 시행착오를 반복하여 정답을 찾는 과정 (알파고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f3a37",
   "metadata": {},
   "source": [
    "## **회귀와 모델링**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1322163",
   "metadata": {},
   "source": [
    "### 1. 회귀란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99de84f",
   "metadata": {},
   "source": [
    "- 데이터에서 패턴을 찾아내어 미래 값을 예측하는 것\n",
    "- 통계나 머신러닝의 주요 개념 중 하나\n",
    "- 집값 예측, 주식 가격 예측 등과 같이 연속적인 숫자를 다룸    \n",
    "(목표변수가 불연속일때는( 범주형) 분류를 이용함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278248ff",
   "metadata": {},
   "source": [
    "### 2. 회귀의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4516e",
   "metadata": {},
   "source": [
    "- 선형회귀\n",
    "- 비선형회귀\n",
    "- 릿지회귀\n",
    "- 라쏘회귀\n",
    "- 다항회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ae0d3",
   "metadata": {},
   "source": [
    "### 3. 선형회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cbc9e3",
   "metadata": {},
   "source": [
    "![선형회귀](./Untitled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9668f6",
   "metadata": {},
   "source": [
    "> 선형회귀: 데이터를 가장 잘 설명하는 회귀선(ex. 직선 y=ax+b)을 찾는 과정    \n",
    "현재 데이터를 예측하는 동시에, 아직 관측되지 않은 미래 값을 예측하는 도구가 됨     \n",
    "예측하고자 하는 것을 종속변수 y, 예측을 위해 사용하는 변수를 독립변수 x 라 함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbb497",
   "metadata": {},
   "source": [
    "선형회귀 기본과정\n",
    "- 선형성\n",
    "- 독립성\n",
    "- 등분산성\n",
    "- 정규성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae059dd",
   "metadata": {},
   "source": [
    "### 3-0. 단순선형회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f46a088",
   "metadata": {},
   "source": [
    "![단순회귀](./2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb20cee",
   "metadata": {},
   "source": [
    "> 하나의 독립변수(x)만 존재하는 선형 회귀      \n",
    "- 데이터를 가장 잘 설명하는 직선 y=ax+b 을 찾는 과정에 해당\n",
    "- y=ax+b에서 a는 회귀계수(기울기) b는 y절편"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5f6cf",
   "metadata": {},
   "source": [
    "- 오차: 실제값 - 실제 평균값\n",
    "- 잔차: 실제값 - 예측값 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732b2f12",
   "metadata": {},
   "source": [
    "> 최소제곱법 : 최적의 회귀선을 찾는 방식    \n",
    "- 잔차의 제곱의 합 (RSS)이 최소가 되는 지점으로 최적의 회귀선을 구하는 방식\n",
    "- 제곱하는 이유: 양수 - 음수 오차의 상쇄 방지, 큰 오차에 큰 벌, 미분가능한 형태가 되도록     \n",
    "- 최소제곱법을 통해 구한 함수가 너무 복잡할 경우 경사하강법을 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76112c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3-1. 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a919800",
   "metadata": {},
   "source": [
    "#### 3-1-1. 목적함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79293f37",
   "metadata": {},
   "source": [
    "목적함수: 달성하고자 하는 목표, 즉 최적화를 위해 오차를 최소화하는 것이 목적인 함수    \n",
    "모델의 예측이 얼마나 잘 맞는지 평가하는 기준"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94a13f",
   "metadata": {},
   "source": [
    "#### 3-1-2. 손실함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3947b67",
   "metadata": {},
   "source": [
    "개별 데이터 샘플에 대한 오차를 측정하는 함수\n",
    "- 한 개의 데이터 포인트에 대해 모델이 얼마나 틀렸는지 평가\n",
    "- 예측값 ^y 와 실제값 y의 차이를 계산\n",
    "- 회귀분석 --> 평균제곱오차 (MSE), 평균절대오차 (MAE)\n",
    "- 분류문제 --> 교차 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda88b0",
   "metadata": {},
   "source": [
    "#### 3-1-3. 비용함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e86d2",
   "metadata": {},
   "source": [
    "전체 데이터셋에서 평균적인 손실을 측정하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf6432",
   "metadata": {},
   "source": [
    "- 손실함수를 모든 데이터 포인트에 대해 계산한 후 평균 or 합산한 값\n",
    "- 머신러닝에서는 대부분 모델을 훈련할 때 비용함수를 최적화 하는 것이 목표\n",
    "- 비용함수 = 목적함수 로 봐도 무방"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70877b98",
   "metadata": {},
   "source": [
    "### 3-2. 다중선형회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9783a",
   "metadata": {},
   "source": [
    "독립 변수가 2개 이상인 경우의 선형회귀 (N가지의 독립변수)\n",
    "- 단순선형회귀분석과 마찬가지로 최소제곱법 사용, 관측치와 평면간의 차이가 잔차가 됨\n",
    "- 파악이 힘들땐 경사하강법 사용하는 것도 마찬가지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa571780",
   "metadata": {},
   "source": [
    "#### 3-2-1. 다중공선성 (Multicollinearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311502c",
   "metadata": {},
   "source": [
    "> 회귀분석에서 독립 변수들 간에 상관관계가 큰 경우 발생    \n",
    "- 다중공선성이 높은 경우 어떤 독립 변수가 종속 변수에 얼마나 영향을 미치는지를 정확하게 구분하기 어렵기 때문에 회귀 모델은 어떤 변수의 영향을 반영해야 할지 불확실해지고, 그 결과 회귀분석의 정확도가 낮아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0e7c3",
   "metadata": {},
   "source": [
    "> 확인방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07077e7d",
   "metadata": {},
   "source": [
    "1. 상관계수\n",
    "- 상관계수는 변수들 간의 통계적 관계, 즉 상관관계의 정도를 수치로 나타낸 것\n",
    "- r 값이 -1과 1 에 가까울 수록 두 변수의 상관성이 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee821eb",
   "metadata": {},
   "source": [
    "2. VIF 지수 (분산 팽창 지수)\n",
    "- 회귀 모델의 결정계수 R Square를 사용하여 계산\n",
    "- VIF 가 높으면 다중공선성이 높다고 판단 (VIF>10 이상)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7216c8",
   "metadata": {},
   "source": [
    "> 다중공선성 대처 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12b10d",
   "metadata": {},
   "source": [
    "1. 변수제거: 독립변수로서 사용할 변수를 선택\n",
    "2. 변수 변환\n",
    "- 변수들을 더하거나 빼서 새로운 변수 생성\n",
    "3. 규제 선형 모델 활용\n",
    "- 릿지, 라쏘, 엘라스틱넷 등의 방법을 통해 모델의 복잡도를 줄이는 방법\n",
    "4. PCA (주성분분석)\n",
    "- 데이터의 차원을 축소하는 데 사용되는 통계적 기법\n",
    "- 상관 있는 변수들을 묶어서 더 적은 수의 대표 축으로 바꾸는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b422ce",
   "metadata": {},
   "source": [
    "### 4. 규제선형모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9fb09",
   "metadata": {},
   "source": [
    "규제 선형 모델\n",
    "- 모델이 학습 데이터에 과적합 되지 않도록 규제를 가하고자 등장한 모델\n",
    "- 선형 회귀 모델에서는 특성에 곱해지는 계수의 크기를 조정하는 것\n",
    "- 기존 선형 모델에서 사용하는 최소제곱법 등은 회귀계수가 쉽게 커지게 되어 과적합 발생할 수 있음\n",
    "- 비용 함수는 오류는 최대한 줄이면서도 특정 변수에 집착하지 않도록 균형을 맞춰 과적합을 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c59168",
   "metadata": {},
   "source": [
    "#### 4-1. 릿지 회귀 (L2 규제)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f018f6b",
   "metadata": {},
   "source": [
    "> 기둥 크기에 따라 다른 힘으로 누르는 망치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3a329",
   "metadata": {},
   "source": [
    "![릿지](./3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb241d",
   "metadata": {},
   "source": [
    "- 회귀계수의 제곱을 패널티로 받기 때문에, 큰 회귀계수일수록 강한 패널티 받음\n",
    "- 모든 변수를 유지하면서도 크기를 적절히 줄여 과적합 방지\n",
    "- 모든 게수의 크기는 작아지지만 완전히 사라지지는 않음 (변수 제거 X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf099a8",
   "metadata": {},
   "source": [
    "#### 4-2. 라쏘 회귀 (L1 규제)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668aaa54",
   "metadata": {},
   "source": [
    "![라쏘](./5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15863648",
   "metadata": {},
   "source": [
    "> 모든 기둥을 같은 힘으로 누르는 망치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2d03f",
   "metadata": {},
   "source": [
    "- 회귀계수의 절댓값을 패널티로 주기 때문에 회귀계수의 크기와 상관없이 같은 패널티 받음\n",
    "- 작은 계수는 0이 되기도 함 (변수 선택 가능)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cabadba",
   "metadata": {},
   "source": [
    "#### 4-3. 엘라스틱넷 (L1+L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891994ff",
   "metadata": {},
   "source": [
    "![엘라스틱](6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca802c6",
   "metadata": {},
   "source": [
    "- L1 망치 : 불필요한 변수를 제거\n",
    "- L2 망치 : 남은 기둥을 균형 잡히게 눌러서 크기를 조절\\\n",
    "- 안정적인 예측(모든 변수가 균형 있게 줄어듦)과 희소성(변수 제거)을 동시에 달성할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259a5c9",
   "metadata": {},
   "source": [
    "### 5. 모델 평가방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6fb946",
   "metadata": {},
   "source": [
    "#### 5-1. 성능 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b253beb1",
   "metadata": {},
   "source": [
    "> 평균제곱오차 (Mean Squared Error, MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b4f20",
   "metadata": {},
   "source": [
    "![mse](7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb6298f",
   "metadata": {},
   "source": [
    "모델의 예측값과 실제 관측값 사이의 오차 제곱의 평균을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b831885",
   "metadata": {},
   "source": [
    "> 평균절대오차 (Mean Absolute Error, MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382197c",
   "metadata": {},
   "source": [
    "![mae](./8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6966b",
   "metadata": {},
   "source": [
    "모델의 예측값과 실제 관측값 사이의 절대값 오차의 평균을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0851ae",
   "metadata": {},
   "source": [
    "#### 5-2. 변수 유의성 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a3702",
   "metadata": {},
   "source": [
    "> #### t 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0858b62",
   "metadata": {},
   "source": [
    "![t값](./9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0b03d",
   "metadata": {},
   "source": [
    "H0: 회귀계수가 0이다  = 독립변수가 종속변수에 영향을 주지 않는다      \n",
    "H1: 회귀계수가 0이 아니다 = 독립변수가 종속변수에 영향을 준다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f8da4e",
   "metadata": {},
   "source": [
    "- p-value < 0.05 → 유의 수준 5%에서 H0 기각 → 해당 변수는 유의미하다.\n",
    "- p-value ≥ 0.05 → H0 기각 불가 → 해당 변수는 유의미하지 않다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
