{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c65817",
   "metadata": {},
   "source": [
    "# INSIGHT 사전학습 과제\n",
    "## 4차시_회귀 기초 세션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aec740",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478302a",
   "metadata": {},
   "source": [
    "## <span style=\"background-color:#E0F7FA; color:#1565C0; padding:4px; border-radius:5px;\"> **머신러닝과 모델링** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa7f6a",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#FFFFE0; color:#CD5C5C; padding:4px; border-radius:5px;\"> **머신러닝** </span>   \n",
    "\n",
    "**머신러닝**: 인공지능의 한 분야로, 모델을 학습해 데이터의 패턴을 찾아내고, 새로운 데이터를 예측&결정을 내릴 수 있도록 하는 기술   \n",
    "\n",
    "**머신러닝의 종류**\n",
    "- 지도 학습: 문제와 정답을 모두 알려준 후 예측값=결과가 되도록 학습시키는 것\n",
    "    - ex. 회귀, 분류\n",
    "- 비지도 학습: 답을 가르쳐주지 않고 데이터 속 패턴이나 유사도를 학습시키는 것\n",
    "    - ex. 군집화\n",
    "- 강화 학습: 시행착오를 반복해 정답을 찾아내는 것\n",
    "    - ex. 알파고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada877b",
   "metadata": {},
   "source": [
    "#### <span style=\"background-color:#FFC2D0; color:#HD234C; padding:4px; border-radius:5px;\"> **지도 학습: 회귀와 분류** </span>\n",
    "\n",
    "**지도 학습**: 입력 값과 함께 결과 값(정답 레이블)을 같이 주고 학습을 시키는 방법   \n",
    "학습의 방향:  예측값(prediction)과  정답(label)이 최대한 같아지도록 학습 \n",
    "\n",
    "과정)\n",
    "![step](./Untitled.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a8d54",
   "metadata": {},
   "source": [
    "**회귀(Regression)**: 주어진 데이터(X)를 기반으로 정답(Y)를 잘 맞추는(fit)하는 함수   \n",
    "- 데이터가 연속형 변수를 예측하기 위해 사용될 때\n",
    "**분류(Classification)**: 기존 데이터가 어떤 레이블에 속하는지 패턴을 알고리즘으로 인지한 뒤에 새롭게 관측된 데이터에 대한 레이블을 판별하는 것\n",
    "- 데이터가 범주형 변수를 예측하기 위해 사용될 때\n",
    "\n",
    "즉, 예측하고자 하는 값(=종속 변수)가 연속형이면 회귀, 범주형이면 분류를 사용!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b1086",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87506cac",
   "metadata": {},
   "source": [
    "## <span style=\"background-color:#E0F7FA; color:#1565C0; padding:4px; border-radius:5px;\"> **회귀와 모델링** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede3199",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#FFFFE0; color:#CD5C5C; padding:4px; border-radius:5px;\"> **선형회귀** </span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f6a22f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "![선형회귀](./image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6437b409",
   "metadata": {},
   "source": [
    "- **선형 회귀: 데이터를 가장 잘 설명하는 회귀선(ex. 직선 y=ax+b)을 찾는 과정**\n",
    "- 이러한 회귀선은 **현재 데이터를 요약**하는 동시에, 아직 관측되지 않은 **미래 값을 예측하는 도구**가 됨\n",
    "- 예측하고자 하는 것: **종속 변수(y)**\n",
    "- 예측을 위해 사용하는 변수: **독립 변수(x)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4bfde5",
   "metadata": {},
   "source": [
    "**선형 회귀의 종류**\n",
    "\n",
    "- **다중 선형 회귀**: 데이터를 **두 개 이상의 독립 변수**를 사용하여 표현\n",
    "- **단순 선형 회귀**: 데이터를 **직선 형태**로 표현(독립 변수 1개)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e79175",
   "metadata": {},
   "source": [
    "#### <span style=\"background-color:#FFC2D0; color:#HD234C; padding:4px; border-radius:5px;\"> **단순선형회귀분석** </span>\n",
    "\n",
    "- **단순 → 하나의 독립변수(x)만 존재하는 선형 회귀.**\n",
    "- y=ax+b에서 **a는 회귀계수(기울기)** **b는 y절편**을 의미한다.\n",
    "- 직선을 결정짓는 적절한 회귀계수(a)와 절편(b)를 찾는 과정이다.\n",
    "\n",
    "즉, 데이터를 가장 잘 설명하는 **직선 y=ax+b** 을 찾는 과정!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c0ff0",
   "metadata": {},
   "source": [
    "<span style=\"color:#CD5C5C\"> **최소제곱법(=최소자승법): 최적의 회귀선을 찾는 방식** </span>\n",
    "- **잔차의 제곱의 합이 최소**가 되는 지점으로 **최적의 회귀선**을 구하는 방식이다.\n",
    "- **잔차**: **실제값과 예측값의 차이**를 의미   \n",
    "\n",
    "회귀선과 실제 데이터와의 차이를 최소화하기 위한 시도!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f90734",
   "metadata": {},
   "source": [
    "최소제곱법을 통해 구한 함수가 복잡하여 최소값을 구하기 어려울 때는 보통 경사하강법을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60e08f",
   "metadata": {},
   "source": [
    "<span style=\"color:#CD5C5C\"> **경사하강법** </span>  \n",
    "\n",
    "최소제곱법과 마찬가지로 y = ax + b에서 a와 b를 잘 찾고자 하는 방법   \n",
    "\n",
    "**잔차제곱을 줄이려는 목적**은 그대로이며,   \n",
    "계산 과정이 복잡할 때 최소로 가는 과정에서 경사하강법을 쓴다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a3a34",
   "metadata": {},
   "source": [
    "#### <span style=\"background-color:#FFC2D0; color:#HD234C; padding:4px; border-radius:5px;\"> **목적함수, 비용함수, 손실함수** </span>\n",
    "\n",
    "**목적함수 (Objective Function): 최적화를 위해 오차를 최소화하는 것이 목적인 함수**\n",
    "- 즉, 최적화하려는 대상을 수학적으로 표현한 함수\n",
    "    - 시험점수를 최대화\n",
    "    - 실수를 최소화\n",
    "    \n",
    "    → case별로 어떤 방향으로 최적화하는지 달라짐 \n",
    "\n",
    "**손실함수 (Loss Function): 개별 데이터 샘플에 대한 오차를 측정하는 함수**\n",
    "\n",
    "- 한 개의 데이터 포인트에 대해 모델이 얼마나 틀렸는지를 평가\n",
    "- 예측값 $\\hat{y}$와 실제값 $y$의 차이를 계산\n",
    "    \n",
    "    *Ex:* \n",
    "    \n",
    "    - **회귀 분석** → 평균제곱오차(MSE), 평균절대오차(MAE)\n",
    "        \n",
    "        $\\text{(MSE for one sample)} = (y - \\hat{y})^2$\n",
    "        \n",
    "    - **분류 문제** → 교차 엔트로피(Cross-Entropy Loss)\n",
    "\n",
    "**비용함수 (Cost Function): 전체 데이터셋에서 평균적인 손실을 측정하는 함수**\n",
    "\n",
    "- 손실함수를 모든 데이터 포인트에 대해 계산한 후 **평균 or 합산**한 값.\n",
    "- 머신러닝에서는 대부분 모델을 훈련할 때 비용함수를 최적화(최소화)하는 것이 목표.\n",
    "    \n",
    "    *예시 :* \n",
    "    \n",
    "    - MSE를 비용함수로 사용할 경우\n",
    "        \n",
    "        $\\text{(MSE)} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$\n",
    "        \n",
    "        *$N$은 전체 샘플 수\n",
    "\n",
    "→ 모델 학습에서 대부분의 목표는 비용함수를 최소화하는 것이기에, 이럴 때는 비용함수 그 자체가 목적함수인 것으로 보아도 무방하다!\n",
    "\n",
    "<span style=\"color:#CD5C5C\"> **BUT** </span> 강화학습(보상 높이는 것이 목표), 생성모델(두 목적 충돌 경우) 등 예외도 존재\n",
    "\n",
    "또, 머신러닝 과정에서는 **모델을 평가하고 최적화하는 함수** 찾는게 핵심이므로 엄밀하게는 **손실함수와 비용함수**는 개별, 합계로서 차이가 있으나 혼용하는 경우가 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfca4bf",
   "metadata": {},
   "source": [
    "**1) 손실함수**\n",
    "\n",
    "![손실함수](./image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351120a",
   "metadata": {},
   "source": [
    "- $t_i$ : $i$번째 데이터포인트 실제값\n",
    "- $y_i$ : $i$번째 예측값\n",
    "\n",
    "잔차를 제곱한 뒤 합하는 형태!   \n",
    "**E를 최소화하는 W와 b 값을 찾아내는 것이 목표**\n",
    "\n",
    "*경사하강법에서 '학습한다'는 말은 '오차의 최솟값을 찾아나간다'는 의미다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822c23a",
   "metadata": {},
   "source": [
    "**2) 학습률(α: learning rate)**\n",
    "\n",
    "얼마나 이동하는지를 나타내는 것!\n",
    "- Learning Rate가 너무 **작다면**, 모델이 수렴할 때 까지 너무 오랜 시간이 걸림\n",
    "- Learning Rate가 너무 **크다면**, 모델은 수렴하지 못하고 발산 (=손실 값이 계속해서 커지는 것) 하게 됨\n",
    "- 따라서 적당한 것이 BEST!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941c340",
   "metadata": {},
   "source": [
    "**3) Local Minima 문제**\n",
    "\n",
    "경사하강법에서 실제 이동량을 보면 작은 기울기에서 조금씩, 큰 기울기에서 많이 이동하는 것을 확인할 수 있음\n",
    "\n",
    "- 모든 비용함수가 하나의 최솟값을 가지는 매끈한 곡선 형태는 아니기에 Local Minima, Global Minima가 존재할 수 있음\n",
    "- 또 작은 기울기에서는 업데이트가 조금씩 이루어지므로 **Local Minima에서 빠져나오기 어려움**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45b441",
   "metadata": {},
   "source": [
    "**4) 해결법 - 모멘텀**\n",
    "\n",
    "- 기존 경사하강법은 **현재 기울기만** 기준으로 움직임\n",
    "    \n",
    "    **→ 이전의 기울기, 이동해오던 방향**을 고려하도록 **관성**을 부여해 해결!\n",
    "\n",
    "- 모멘텀의 장점\n",
    "    - 기울기에 **관성**을 부여하여 작은 기울기는 쉽게 넘어갈 수 있도록 만든 것\n",
    "    - 지역 최소값을 탈출할 수 있게 함\n",
    "    - 모멘텀을 사용하지 않으면 아주 작은 언덕도 빠져나오지 못할 수 있으며 기울기가 매우 작은 구간을 빠져나오는데 아주 오랜 시간이 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed51b6",
   "metadata": {},
   "source": [
    "#### <span style=\"background-color:#FFC2D0; color:#HD234C; padding:4px; border-radius:5px;\"> **다중선형회귀분석** </span>\n",
    "\n",
    ": 독립 변수가 2개 이상인 경우의 선형회귀 → N가지의 독립변수\n",
    "\n",
    "- 독립 변수 $x_i$가 2개인 경우 3차원 공간에 표현되며 회귀선은 평면이 됨\n",
    "- 단순과 마찬가지로 최소제곱법을 사용할 수 있음\n",
    "- 관측치와 평면간의 차이가 잔차가 됩니다. → 파악이 힘들 땐 경사하강법(gradient descent) 사용해야하는 것도 단순회귀와 마찬가지!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419de5e9",
   "metadata": {},
   "source": [
    "#### <span style=\"background-color:#FFC2D0; color:#HD234C; padding:4px; border-radius:5px;\"> **다중공산성** </span>\n",
    "\n",
    "- 변수들끼리 겹치는 상황을 상상\n",
    "- **다중공선성**은 회귀 분석에서 **독립 변수들 간에 상관관계**가 큰 경우 발생함.\n",
    "\n",
    "**⇒ 다중공선성이 높은 경우 어떤 독립 변수가 종속 변수에 얼마나 영향을 미치는지를 정확하게 구분하기 어렵기 때문에 회귀 모델은 어떤 변수의 영향을 반영해야 할지 불확실해지고, 그 결과 회귀분석의 정확도가 낮아짐.**\n",
    "\n",
    "**[다중공산성 확인 방법]**\n",
    "1) **상관계수**\n",
    "- 상관계수는 변수간의  통계적 관계 즉. **상관관계의 정도를 수치**로 나타낸 것\n",
    "    - 상관계수 값 r은 **-1과 1**사이에 존재\n",
    "    - r이 -1과 1에 가까울수록 두 변수의 **상관성이 높음**\n",
    "    - r이 음수라면 음의 상관관계, 양수라면 양의 상관관계를 뜻함\n",
    "    - 0은 선형 상관 **관계 없음**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d71f50",
   "metadata": {},
   "source": [
    "아래와 같이 **히트맵** 혹은 **corr()함수**를 통해 상관계수를 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d74a2d",
   "metadata": {},
   "source": [
    "```\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap( df.corr(), annot = True)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6fd7c",
   "metadata": {},
   "source": [
    "**pairplot**과 같은 시각화로 산점도를 찍어 상관성을 직접 눈으로 확인할 수도 있음!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722e6dc",
   "metadata": {},
   "source": [
    "2. **VIF지수 (분산 팽창 인수)**\n",
    "- **회귀 모델의 결정계수 R square를 사용하여 계산**\n",
    "- VIF가 **높으면 다중공선성이 존재**한다고 판단.\n",
    "    - **VIF = 1**: 해당 독립 변수는 다른 변수와 상관관계가 전혀 없음을 의미\n",
    "    - **VIF < 5**: 일반적으로 다중공선성 문제가 없다고 간주\n",
    "    - **VIF > 5**: 다중공선성의 징후가 있을 수 있으며, 주의를 요함\n",
    "    - **VIF > 10**: 다중공선성이 심각하다고 간주되며, 이 변수를 포함한 회귀 모델은 불안정할 가능성이 큼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69919ed3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**[다중공선성 대처 방법]**\n",
    "\n",
    "1. **변수 제거(변수 선택법)**\n",
    "    - 말그대로 독립변수로서 사용할 변수를 선택하는 방법\n",
    "2. **변수 변환**\n",
    "    - 변수들을 더하거나 빼서 새로운 변수 생성\n",
    "    - 독립변수를 더하거나 빼더라도 문제가 없는 경우\n",
    "    - 예) 남편의 수입과 아내의 수입이 서로 상관성이 높다면, 두 개를 더해 가족 수입이라는 하나의 변수로 투입\n",
    "3. **규제 선형 모델 활용:** \n",
    "    - 릿지, 라쏘, 엘라스틱넷 등의 방법을 통해 모델의 복잡도를 줄이는 방법 사용\n",
    "4. **PCA(주성분분석)**\n",
    "    - **데이터의 차원을 축소**하는 데 사용되는 통계적 기법. PCA는 고차원 데이터에서 중요한 정보를 최대한 보존하면서 데이터의 복잡성을 줄이는 것을 목표로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de88003",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#FFFFE0; color:#CD5C5C; padding:4px; border-radius:5px;\"> **규제선형모델** </span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761fbd4",
   "metadata": {},
   "source": [
    ": 모델이 학습 데이터에 **과적합(overfitting) 되지 않도록 규제를 가하고자** 등장한 모델   \n",
    "→ 선형 회귀 모델에서는 특성에 곱해지는 **계수(기울기)의 크기를 조정**하는 것\n",
    "- 특히 여러 독립 변수를 사용하여 예측하므로 모델이 복잡해지는 다중회귀에서 과적합(overfitting)될 가능성 증가\n",
    "- 기존 선형 모델에서는 최소제곱법과 같이 RSS(잔차 제곱합)를 **최소화**하는 방식으로 비용 함수 설정\n",
    "**→ 회귀 계수가 쉽게 커지게 되어** 과적합(overfitting) 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b48608",
   "metadata": {},
   "source": [
    "**규제선형모델의 종류**\n",
    "\n",
    "1. L2규제 : W(회귀계수)의 **제곱**에 대해 페널티를 부여하는 방식, **릿지(Ridge)회귀**\n",
    "2. L1규제 :  W(회귀계수)의 **절댓값**에 대해 페널티를 부여하는 방식, **라쏘(Lasso) 회귀**\n",
    "3. L2규제 + L1규제 결합 **: 엘라스틱넷(Elastic Net) 회귀**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2bfe67",
   "metadata": {},
   "source": [
    "##### <span style=\"background-color:#FFC2D0; color:#HD234C; padding:4px; border-radius:5px;\"> **릿지회귀(L2 규제)** </span> \n",
    "**= 회귀계수의 제곱 합에 페널티 부여**\n",
    "\n",
    "(1) 예측 변수가 많을 때   \n",
    "     → 고차원 데이터에서 모든 변수에 작은 가중치를 부여하고자 할 때 유용\n",
    "(2) 다중공선성 존재할 때   \n",
    "     → 변수 선택이 필요하지 않은 상황\n",
    "\n",
    "\n",
    "##### <span style=\"background-color:#FFC2D0; color:#HD234C; padding:4px; border-radius:5px;\"> **라쏘회귀 (L1 규제)** </span> \n",
    "**= 회귀계수의 절댓값 합에 페널티 부여**\n",
    "\n",
    "(1) 예측 변수 수가 많고, 그 중 일부만이 실제로 중요할 때   \n",
    "     → 계수 중 일부를 정확히 0으로 만들어 변수 선택 효과 부여\n",
    "(2) 모델의 해석을 간단하게 유지하고자 할 때   \n",
    "     → 불필요한 변수를 제거하고 모델을 단순화\n",
    "\n",
    "- L1 규제를 사용하는 라쏘는 최적화 문제가 비선형적이고 복잡할 수 있으며, 특정 상황에서는 수치적으로 불안정할 수 있음\n",
    "- L2 규제를 사용하는 릿지는 수치적으로 더 안정적\n",
    "\n",
    "\n",
    "##### <span style=\"background-color:#FFC2D0; color:#HD234C; padding:4px; border-radius:5px;\"> **엘라스틱넷 (L1 + L2 규제)** </span> \n",
    "**= 릿지의 계수 축소 기능과 라쏘의 변수 선택 기능 모두 가짐**\n",
    "\n",
    "(1) 예측 변수 수가 많고, 그 중 중요한 변수를 선택하면서도 다중공선성을 관리할 때   \n",
    "     → 변수 간의 상관관계가 높은 경우 릿지만 사용할 때보다 더 나은 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc1f4c",
   "metadata": {},
   "source": [
    "### <span style=\"background-color:#FFFFE0; color:#CD5C5C; padding:4px; border-radius:5px;\"> **모델평가방법** </span>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1534b",
   "metadata": {},
   "source": [
    "<span style=\"color:#CD5C5C\"> **성능 평가 지표** </span>  \n",
    "\n",
    "**1) 평균 제곱 오차 (Mean Squared Error, MSE)**:\n",
    "\n",
    "- MSE는 Mean Squared Error의 약어\n",
    "- 회귀 분석에서 모델의 예측값과 실제 관측값 사이의 **오차 제곱의 평균**을 의미\n",
    "- 모델의 **예측 성능을 평가하는 지표** 중 하나\n",
    "\n",
    "**2) 평균 절대 오차 (Mean Absolute Error, MAE)**:\n",
    "\n",
    "- MAE는 Mean Absolute Error의 약어\n",
    "- 회귀 분석에서 모델의 예측값과 실제 관측값 사이의 **절대값 오차의 평균**을 의미\n",
    "- 모델의 **예측 성능을 평가하는 지표** 중 하나로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c21c5",
   "metadata": {},
   "source": [
    "<span style=\"color:#CD5C5C\"> **변수 유의성 평가** </span>  \n",
    "\n",
    "**1) t검정**\n",
    "\n",
    "t-검정은 **독립 변수의 회귀계수가 유의미한지** 검정하는 데 사용\n",
    "\n",
    "- **귀무가설 (**$H_0$**)**: 회귀계수(a)가 0이다 → 독립변수가 종속변수에 영향을 주지 않는다.\n",
    "- **대립가설 (**$H_1$**)**: 회귀계수(a)가 0이 아니다 → 독립변수가 종속변수에 영향을 준다.\n",
    "\n",
    "과정: t-값 계산 → p-value 확인 및 판단 → 해석"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
