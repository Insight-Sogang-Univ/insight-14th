{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51a61dd",
   "metadata": {},
   "source": [
    "# ë¶„ë¥˜ ì´ë¡ \n",
    "ì €ë²ˆ ì„¸ì…˜ì—ì„œ ë°°ìš´ ë¶„ë¥˜ ì´ë¡ ì„ ë³µìŠµí•´ë´…ì‹œë‹¤.\n",
    "\n",
    "ë…¸ì…˜ì— ìˆëŠ” ë¶„ë¥˜ ì´ë¡  íŒŒíŠ¸ë¥¼ ì°¸ê³ í•´ë„ ì¢‹ì•„ìš”! \n",
    "\n",
    "ë‚´ìš©ì„ ë‹¤ì‹œ ì½ì–´ë³´ë©´ì„œ ì •ë¦¬í•œë‹¤ëŠ” ëŠë‚Œìœ¼ë¡œ ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b92f6a",
   "metadata": {},
   "source": [
    "##\n",
    "***ë¨¸ì‹ ëŸ¬ë‹ì´ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•˜ì„¸ìš”.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d72df",
   "metadata": {},
   "source": [
    "ë‹µ: ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ë¡œ, ëª¨ë¸ì´ë¼ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ í•™ìŠµí•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ê±°ë‚˜ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì„ í†µí•´ ë°ì´í„°ì—ì„œ íŒ¨í„´ì„ ì°¾ì•„ë‚´ê³ , ì´ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7acbdf",
   "metadata": {},
   "source": [
    "##\n",
    "***ë¨¸ì‹ ëŸ¬ë‹ì—ëŠ” ì§€ë„í•™ìŠµê³¼ ë¹„ì§€ë„í•™ìŠµì´ ìˆìŠµë‹ˆë‹¤. ì§€ë„í•™ìŠµê³¼ ë¹„ì§€ë„í•™ìŠµì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d53342",
   "metadata": {},
   "source": [
    "ë‹µ:   \n",
    "ì§€ë„ í•™ìŠµì€ ì •ë‹µ(label)ì´ ìˆëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë©°, ì˜ˆì¸¡ê°’(prediction)ì„ ì´ë¯¸ ë§Œë“¤ì–´ë‘” ì •ë‹µê³¼ ê°™ì•„ì§€ë„ë¡ ê¸°ê³„ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ëŒ€í‘œì ìœ¼ë¡œ íšŒê·€ì™€ ë¶„ë¥˜ê°€ ìˆë‹¤.   \n",
    "ë¹„ì§€ë„ í•™ìŠµì€ ì •ë‹µ(label)ì´ ì—†ëŠ” ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë©°, ë°ì´í„° ì†ì˜ íŒ¨í„´ ë˜ëŠ” ê° ë°ì´í„° ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê¸°ê³„ê°€ í•™ìŠµí•˜ë„ë¡ í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ëŒ€í‘œì ìœ¼ë¡œ êµ°ì§‘í™”ê°€ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73ef87",
   "metadata": {},
   "source": [
    "##\n",
    "***ëŒ€í‘œì ì¸ ì§€ë„í•™ìŠµ ëª¨ë¸ë¡œëŠ” íšŒê·€ì™€ ë¶„ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. íšŒê·€ì™€ ë¶„ë¥˜ì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9ee24",
   "metadata": {},
   "source": [
    "ë‹µ: íšŒê·€ëŠ” ì£¼ì–´ì§„ ë°ì´í„°(X)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë‹µ(Y)ë¥¼ ì˜ ë§ì¶”ëŠ” í•¨ìˆ˜ë¥¼ ì°¾ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë¶„ë¥˜ëŠ” ê¸°ì¡´ ë°ì´í„°ê°€ ì–´ë–¤ ë ˆì´ë¸”ì— ì†í•˜ëŠ”ì§€ íŒ¨í„´ì„ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì¸ì§€í•œ ë’¤ì— ìƒˆë¡­ê²Œ ê´€ì¸¡ëœ ë°ì´í„°ì— ëŒ€í•œ ë ˆì´ë¸”ì„ íŒë³„í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë”°ë¼ì„œ íšŒê·€ëŠ” ë°ì´í„°ê°€ ì—°ì†í˜• ë³€ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë  ë•Œ í™œìš©ë˜ë©°, ë¶„ë¥˜ëŠ” ë°ì´í„°ê°€ ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë  ë•Œ í™œìš©ëœë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de61db",
   "metadata": {},
   "source": [
    "##\n",
    "***ì´ì§„ë¶„ë¥˜ì™€ ë‹¤ì¤‘ë¶„ë¥˜ì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1740665",
   "metadata": {},
   "source": [
    "ë‹µ:   \n",
    "ì´ì§„ ë¶„ë¥˜(Binary Classification)ëŠ” ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ë³€ìˆ˜ê°€ ì–´ë–¤ ê¸°ì¤€ì— ëŒ€í•˜ì—¬ ì°¸(True) ë˜ëŠ” ê±°ì§“(False)ì˜ ê°’ë§Œì„ ê°€ì§ˆ ë•Œ ì‚¬ìš©í•œë‹¤.    \n",
    "ë‹¤ì¤‘ ë¶„ë¥˜(Multiclass Classification)ëŠ” ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ë³€ìˆ˜ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ê°’ì´ 3ê°œ ì´ìƒì¼ ë•Œ ì‚¬ìš©í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec4ade",
   "metadata": {},
   "source": [
    "##\n",
    "***ì„¸ì…˜ì—ì„œ ê³µë¶€í•œ ë„¤ ì¢…ë¥˜ì˜ ë¶„ë¥˜ ëª¨ë¸ì„ ê°„ëµíˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec7b0e",
   "metadata": {},
   "source": [
    "ë‹µ :\n",
    "1. ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "    - ì´ì§„ ë¶„ë¥˜ ë¬¸ì œë¥¼ í‘¸ëŠ” ëŒ€í‘œì ì¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, ìƒ˜í”Œì´ íŠ¹ì • í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ ì„ ì¶”ì •í•˜ì—¬ ê¸°ì¤€ì¹˜ì— ë”°ë¼ ë¶„ë¥˜í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.\n",
    "2. ì˜ì‚¬ê²°ì •ë‚˜ë¬´\n",
    "    - ì¡°ê±´ì— ë”°ë¼ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ë©°, ìµœì¢…ì ìœ¼ë¡œ ë°ì´í„°ê°€ ìˆœìˆ˜í•œ labelì˜ ì§‘í•©ìœ¼ë¡œ êµ¬ì„±ë  ë•Œê¹Œì§€ ë¶„ë¥˜ë¥¼ ë°˜ë³µí•˜ëŠ” ë¶„ì„ ë°©ë²•ì´ë‹¤.\n",
    "3. SVM\n",
    "    - í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ê²½ê³„ì„  ì¤‘ ìµœì ì˜ ë¼ì¸ì„ ì°¾ì•„ë‚´ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.\n",
    "4. KNN\n",
    "    - ë°ì´í„°ë¡œë¶€í„° ê±°ë¦¬ê°€ ê°€ê¹Œìš´ kê°œì˜ ë‹¤ë¥¸ ë°ì´í„° ë ˆì´ë¸”ì„ ì°¸ì¡°í•˜ì—¬ ë¶„ë¥˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a1b55",
   "metadata": {},
   "source": [
    "# ë¶„ë¥˜ ì‹¤ìŠµ: íƒ‘ìŠ¹í•œ í•­êµ¬ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ ë§Œë“¤ê¸°\n",
    "ì €ë²ˆ ì„¸ì…˜ ì‹œê°„ì—, íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ **ìƒì¡´ ì—¬ë¶€(Survived)** ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ì—ˆì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ ëª¨ë¸ì€ **Survived/Not Survived** ë¥¼ ì˜ˆì¸¡í•˜ëŠ” **ì´ì§„ ë¶„ë¥˜ ëª¨ë¸** ì´ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆ ê³¼ì œì—ì„œëŠ”, **íƒ‘ìŠ¹í•œ í•­êµ¬(Embarked)** ë¥¼ ì˜ˆì¸¡í•˜ëŠ” **ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸** ì„ ë§Œë“¤ì–´ ë³¼ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "(íƒ‘ìŠ¹í•œ í•­êµ¬ ì»¬ëŸ¼ì˜ ê°’ì€ S, C, Që¡œ ë‚˜ë‰˜ê¸° ë•Œë¬¸ì—, 'ì´ì§„ ë¶„ë¥˜'ê°€ ì•„ë‹Œ 'ë‹¤ì¤‘ ë¶„ë¥˜'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd3b34",
   "metadata": {},
   "source": [
    "ğŸ“Œ ì–´ë–¤ ì‚¬ëŒì— ëŒ€í•œ ì •ë³´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, **ê·¸ ì‚¬ëŒì´ ì–´ë–¤ í•­êµ¬ì—ì„œ íƒ‘ìŠ¹í–ˆëŠ”ì§€ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸**ë§Œë“¤ì–´ë´…ì‹œë‹¤.\n",
    "- ì£¼ì–´ì§€ëŠ” ì •ë³´: ìƒì¡´ ì—¬ë¶€, ì¢Œì„ ë“±ê¸‰, ì„±ë³„, ë‚˜ì´ ë“±ì˜ ì •ë³´ (ëª¨ë¸ì˜ ë…ë¦½ ë³€ìˆ˜)\n",
    "- ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ì •ë³´: íƒ‘ìŠ¹í•œ í•­êµ¬ (ëª¨ë¸ì˜ ì¢…ì† ë³€ìˆ˜)\n",
    "\n",
    "[ ë³€ìˆ˜ ì„¤ëª… ]\n",
    "\n",
    "- PassengerId : ê° ìŠ¹ê°ì˜ ê³ ìœ  ë²ˆí˜¸\n",
    "\n",
    "- Survived : ìƒì¡´ ì—¬ë¶€(ì¢…ì† ë³€ìˆ˜)\n",
    "\n",
    "        0 = ì‚¬ë§\n",
    "        1 = ìƒì¡´\n",
    " \n",
    "- Pclass : ê°ì‹¤ ë“±ê¸‰ - ìŠ¹ê°ì˜ ì‚¬íšŒì , ê²½ì œì  ì§€ìœ„\n",
    "\n",
    "        1st = Upper\n",
    "        2nd = Middle\n",
    "        3rd = Lower\n",
    "\n",
    "- Name : ì´ë¦„\n",
    "\n",
    "- Sex : ì„±ë³„\n",
    "\n",
    "- Age : ë‚˜ì´\n",
    "\n",
    "- SibSp : ë™ë°˜í•œ Sibling(í˜•ì œìë§¤)ì™€ Spouse(ë°°ìš°ì)ì˜ ìˆ˜\n",
    "\n",
    "- Parch : ë™ë°˜í•œ Parent(ë¶€ëª¨) Child(ìì‹)ì˜ ìˆ˜\n",
    "\n",
    "- Ticket : í‹°ì¼“ì˜ ê³ ìœ ë„˜ë²„\n",
    "\n",
    "- Fare : í‹°ì¼“ì˜ ìš”ê¸ˆ\n",
    "\n",
    "- Cabin : ê°ì‹¤ ë²ˆí˜¸\n",
    "\n",
    "- Embarked : ìŠ¹ì„ í•œ í•­"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37822baa",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì½ê¸° ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8d5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seabornì„ sns, pandasë¥¼ pd, numpyë¥¼ npë¡œ importí•´ì£¼ì„¸ìš”\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ì„œ dfì— ì €ì¥í•´ì£¼ì„¸ìš”\n",
    "df = pd.read_csv(\"./titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbcf9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ft/29lgxt556sxbnx3pxr3y53r40000gn/T/ipykernel_52999/2791606022.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Mr' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'Initial'] = initial_search\n"
     ]
    }
   ],
   "source": [
    "# initial ì»¬ëŸ¼ì„ ë§Œë“¤ê³  ì¼ì‹œì ìœ¼ë¡œ ê°’ì„ 0ìœ¼ë¡œ ì´ˆê¸°í™”\n",
    "df['Initial'] = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    initial_search = row['Name'].split(',')[1].split('.')[0].strip() # Name ì»¬ëŸ¼ì—ì„œ .(dot)ì„ ê¸°ì¤€ìœ¼ë¡œ ì•ŒíŒŒë²³ ë¬¸ìì—´ ì¶”ì¶œ\n",
    "    df.at[index, 'Initial'] = initial_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49c49ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ft/29lgxt556sxbnx3pxr3y53r40000gn/T/ipykernel_52999/2395359540.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Initial'].replace([\n"
     ]
    }
   ],
   "source": [
    "# ìœ ì¶” ê°€ëŠ¥í•œ ê°’ë“¤ë¡œ ëŒ€ì²´í•˜ê³ , í”í•˜ì§€ ì•Šì€ Initialë“¤ì€ Otherë¡œ ëŒ€ì²´í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "df['Initial'].replace([\n",
    "    'Mlle', 'Mme', 'Ms', 'Dr', 'Major', 'Lady', 'Countess', 'Jonkheer', 'Col',\n",
    "    'Rev', 'Capt', 'Sir', 'Don','the Countess' \n",
    "], [\n",
    "    'Miss', 'Miss', 'Miss', 'Mr', 'Mr', 'Mrs', 'Mrs', 'Other', 'Other',\n",
    "    'Other', 'Mr', 'Mr', 'Mr', 'Other'\n",
    "],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a0b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ì¸¡ê°’ì„ Initialë³„ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "df.loc[(df['Age'].isnull()) & (df['Initial']=='Mr'), 'Age'] = 33 \n",
    "df.loc[(df['Age'].isnull()) & (df['Initial']=='Mrs'), 'Age'] = 36\n",
    "df.loc[(df['Age'].isnull()) & (df['Initial']=='Master'), 'Age'] = 5 \n",
    "df.loc[(df['Age'].isnull()) & (df['Initial']=='Miss'), 'Age'] = 22\n",
    "df.loc[(df['Age'].isnull()) & (df['Initial']=='Other'), 'Age'] = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "190b3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embarked ì—´ì˜ ê²°ì¸¡ê°’ì„ ì œê±°í•´ì£¼ì„¸ìš”\n",
    "df.dropna(subset=['Embarked'], inplace=True)\n",
    "\n",
    "# 'Cabin', 'Name', 'PassengerId', 'Ticket' ì—´ì€ ë¶„ì„ì—ì„œ ì œì™¸í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "df.drop(['Cabin', 'Name','PassengerId','Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab65413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚˜ì¤‘ì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì„ ì €ì¥í•´ë‘¡ë‹ˆë‹¤.\n",
    "df_org = df.copy()\n",
    "\n",
    "# SibSp í–‰ê³¼ Parch í–‰ì„ ì´ìš©í•´ Relatives ì—´ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "df['Relatives'] = df[\"SibSp\"] + df[\"Parch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6079c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex ì—´ ì¸ì½”ë”©\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "# Age ì—´ì„ 10ë…„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì¸ì½”ë”©\n",
    "df['Age'] = (df['Age'] // 10).astype(int)\n",
    "# Fare ì—´ì„ 9ë¶„ìœ„ë¡œ êµ¬ê°„í™”í•˜ê³  ì¸ì½”ë”©\n",
    "df['Fare'] = pd.qcut(df['Fare'], q=9, labels=range(9))\n",
    "# Embarked ì—´ ì¸ì½”ë”©\n",
    "df['Embarked'] = df['Embarked'].map({'S': 1, 'C': 2, 'Q': 3})\n",
    "# Initial ì—´ ì¸ì½”ë”©\n",
    "initial_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other':4}\n",
    "df['Initial'] = df['Initial'].map(initial_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adf59a",
   "metadata": {},
   "source": [
    "## ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ targetê³¼ feature ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3aa332",
   "metadata": {},
   "source": [
    "ì•ì„œ ë§í–ˆì§€ë§Œ, ìš°ë¦¬ì˜ ëª©í‘œëŠ” ì–´ë–¤ ì‚¬ëŒì˜ ì •ë³´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ê·¸ ì‚¬ëŒì´ íƒ‘ìŠ¹í•œ í•­êµ¬ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ëª¨ë¸ì˜ targetê³¼ featureê°€ ë¬´ì—‡ì¸ì§€ ì •ì˜í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1d5eb",
   "metadata": {},
   "source": [
    "- feature(ì˜ˆì¸¡ì„ ìœ„í•´ ì£¼ì–´ì§€ëŠ” ì •ë³´ = ë…ë¦½ ë³€ìˆ˜): ***(ë‹µ) í•œ ì‚¬ëŒì— ëŒ€í•œ ì •ë³´ = Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Initial, Relatives***\n",
    "- target(ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ê°’ = ì¢…ì† ë³€ìˆ˜): ***(ë‹µ) Embarked***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4b46e0",
   "metadata": {},
   "source": [
    "ì´ targetê³¼ featureì— ë”°ë¼ ìƒì¡´ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜ predict_survivalë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ í•¨ìˆ˜ì— modelê³¼ ë…ë¦½ ë³€ìˆ˜ë“¤ì„ ë„£ì–´ì£¼ë©´, ìŠ¹ì„ í•œ í•­ ì˜ˆì¸¡ ê°’ê³¼ í™•ë¥ ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "- í•¨ìˆ˜ì˜ input: model, scaler, ë…ë¦½ ë³€ìˆ˜(pclass, sex, age, sibsp, parch, fare, survived, initial)\n",
    "- í•¨ìˆ˜ì˜ output: ìŠ¹ì„ í•œ í•­êµ¬, í™•ë¥ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a81fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_embarked(model, scaler, survived, pclass, sex, age, sibsp, parch, fare, initial):\n",
    "    # ì…ë ¥ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ìƒì„±\n",
    "    input_data = pd.DataFrame({\n",
    "        'Survived': [survived],\n",
    "        'Pclass': [pclass],\n",
    "        'Sex': [0 if sex == 'male' else 1],\n",
    "        'Age': [age // 10],\n",
    "        'SibSp': [sibsp],\n",
    "        'Parch': [parch],\n",
    "        'Fare': [fare],\n",
    "        'Initial': [\n",
    "            'Mr' if initial in ['Mr', 'Dr', 'Major', 'Col', 'Rev', 'Capt', 'Sir', 'Don'] else\n",
    "            'Miss' if initial in ['Miss', 'Mlle', 'Mme', 'Ms'] else\n",
    "            'Mrs' if initial in ['Mrs', 'Lady', 'Countess'] else\n",
    "            'Master' if initial == 'Master' else\n",
    "            'Other'\n",
    "        ],\n",
    "        'Relatives': [sibsp + parch],\n",
    "    })\n",
    "\n",
    "    # Fareë¥¼ ë²”ì£¼í™” (ê¸°ì¡´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ bins ìƒì„±)\n",
    "    fare_bins = pd.qcut(df_org['Fare'], 9, retbins=True)[1]\n",
    "    input_data['Fare'] = pd.cut(input_data['Fare'], bins=fare_bins, labels=False, include_lowest=True)\n",
    "\n",
    "    # ì¤‘ìš”í•œ ìˆ˜ì • ë¶€ë¶„: Initialì„ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë§¤í•‘ ì¶”ê°€\n",
    "    initial_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other': 4}\n",
    "    input_data['Initial'] = input_data['Initial'].map(initial_mapping)\n",
    "\n",
    "    # í•™ìŠµ ì‹œ ì»¬ëŸ¼ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ ë§ì¶”ê¸°\n",
    "    input_data = input_data[X_train.columns]\n",
    "\n",
    "    # ìŠ¤ì¼€ì¼ë§\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    prediction = model.predict(input_data_scaled)[0]\n",
    "    prediction_proba = model.predict_proba(input_data_scaled)\n",
    "\n",
    "    # í´ë˜ìŠ¤ ë§¤í•‘\n",
    "    embarked_mapping = {1: \"S\", 2: \"C\", 3: \"Q\"}\n",
    "    result = embarked_mapping[prediction]\n",
    "\n",
    "    # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ì˜ í™•ë¥ \n",
    "    probability = prediction_proba[0][prediction - 1]\n",
    "\n",
    "    return result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81076609",
   "metadata": {},
   "source": [
    "## targetê³¼ feature ë¶„ë¦¬\n",
    "ë°ì´í„° ì…‹ì„ targetê³¼ featureë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ê°’ì¸ targetê³¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì£¼ì–´ì§„ ê°’ì¸ featureë¥¼ ê°ê° ë³€ìˆ˜ì— ë‹´ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- target = ì¢…ì† ë³€ìˆ˜ (ë³€ìˆ˜ëª…=y): 'Embarked'\n",
    "- feature = ë…ë¦½ ë³€ìˆ˜ (ë³€ìˆ˜ëª…=X): 'Pclass', 'Sex', 'Age', 'Sibsp', 'Parch', 'Fare', `Survived', 'Initial'\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "\n",
    "drop() í•¨ìˆ˜ëŠ” dropí•œ í›„ì˜ ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "drop('dropí•˜ê³ ì í•˜ëŠ” ì—´', axis=1)\n",
    "\n",
    "ìœ„ì—ì„œ ì£¼ì–´ì§„ ì°¸ê³  ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì£¼ì„ì— ë§ê²Œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bd393bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ìˆ˜ Xì— feature(= 'Embarked' ì—´ì„ dropí•œ ë°ì´í„°í”„ë ˆì„)ë¥¼ ë‹´ì•„ì£¼ì„¸ìš”.\n",
    "X=df.drop('Embarked', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e958b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Initial</th>\n",
       "      <th>Relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  SibSp  Parch Fare  Initial  Relatives\n",
       "0           0       3    0    2      1      0    0        0          1\n",
       "1           1       1    1    3      1      0    7        2          1\n",
       "2           1       3    1    2      0      0    2        1          0\n",
       "3           1       1    1    3      1      0    7        2          1\n",
       "4           0       3    0    3      0      0    2        0          0\n",
       "..        ...     ...  ...  ...    ...    ...  ...      ...        ...\n",
       "886         0       2    0    2      0      0    3        4          0\n",
       "887         1       1    1    1      0      0    6        1          0\n",
       "888         0       3    1    2      1      2    5        1          3\n",
       "889         1       1    0    2      0      0    6        0          0\n",
       "890         0       3    0    3      0      0    1        0          0\n",
       "\n",
       "[889 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f73cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ìˆ˜ yì— target(= 'Embarked' ì—´)ì„ ë‹´ì•„ì£¼ì„¸ìš”.\n",
    "y = df['Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ee19ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      2\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "886    1\n",
       "887    1\n",
       "888    1\n",
       "889    2\n",
       "890    3\n",
       "Name: Embarked, Length: 889, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1860e",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì…‹ì„ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ê¸°\n",
    "- í›ˆë ¨ ì„¸íŠ¸ -> ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "- í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ -> ì™„ì„±ëœ ëª¨ë¸ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë…ë¦½ë³€ìˆ˜(X)ì™€ ì¢…ì†ë³€ìˆ˜(y)ë¥¼ ëª¨ë‘ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ì–´ë´…ì‹œë‹¤.\n",
    "\n",
    "[ ë³€ìˆ˜ëª… ]\n",
    "\n",
    "- ë…ë¦½ë³€ìˆ˜ í›ˆë ¨ ì„¸íŠ¸: X_train\n",
    "- ë…ë¦½ë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: X_test\n",
    "- ì¢…ì†ë³€ìˆ˜ í›ˆë ¨ ì„¸íŠ¸: y_train\n",
    "- ì¢…ì†ë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: y_test\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "\n",
    "tran_test_split í•¨ìˆ˜ëŠ” ë³€ìˆ˜ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ì–´ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "~~~\n",
    "train_test_split(ë…ë¦½ë³€ìˆ˜, ì¢…ì†ë³€ìˆ˜, test_size=í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í¬ê¸°, random_state=ì‹œë“œê°’)\n",
    "~~~\n",
    "-> ë…ë¦½ë³€ìˆ˜ í›ˆë ¨ ì„¸íŠ¸, ë…ë¦½ë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸, ì¢…ì†ë³€ìˆ˜ í›ˆë ¨ ì„¸íŠ¸, ì¢…ì†ë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë°˜í™˜\n",
    "\n",
    "- test_size: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ í¬ê¸°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ê°ê° 70%ì™€ 30%ë¡œ í•˜ê³  ì‹¶ìœ¼ë©´, test_size=0.3ìœ¼ë¡œ í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "- random_state: ì„ì˜ì˜ ìˆ«ìë¡œ ì„¤ì •ëœ ì‹œë“œë¡œ, ì–´ë–¤ ìˆ«ìë¥¼ ì‚¬ìš©í•´ë„ ìƒê´€ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìœ„ì—ì„œ ì£¼ì–´ì§„ ì°¸ê³  ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì£¼ì„ì— ë§ê²Œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024dfaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.model_selectioì˜ train_test_split í•¨ìˆ˜ë¥¼ import í•´ì£¼ì„¸ìš”.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# tran_test_split í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ë…ë¦½ë³€ìˆ˜(X)ì™€ ì¢…ì†ë³€ìˆ˜(y)ë¥¼ ê°ê° í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ì–´ì£¼ì„¸ìš”. ê° í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ë³€ìˆ˜ ëª…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "# ë…ë¦½ë³€ìˆ˜ í›ˆë ¨ ì„¸íŠ¸: X_train, ë…ë¦½ë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: X_test, ì¢…ì†ë³€ìˆ˜ í›ˆë ¨ ì„¸íŠ¸: y_train, ì¢…ì†ë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: y_test\n",
    "# ë‹¨, random_stateëŠ” 42ë¡œ í•©ë‹ˆë‹¤.\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edcb2f",
   "metadata": {},
   "source": [
    "# featureì— scaler ì ìš©\n",
    "MinMaxScalerë¥¼ ì´ìš©í•´ì„œ ëª¨ë“  feature(ë…ë¦½ë³€ìˆ˜, X)ë¥¼ ìŠ¤ì¼€ì¼ë§ í•´ì¤ë‹ˆë‹¤. \n",
    "\n",
    "[ ë³€ìˆ˜ëª… ]\n",
    "- ìŠ¤ì¼€ì¼ë§ëœ ë…ë¦½ë³€ìˆ˜ í›ˆë ¨ ì„¸íŠ¸: X_train_scaled\n",
    "- ìŠ¤ì¼€ì¼ë§ëœ ë…ë¦½ë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: X_test_scaled\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "\n",
    "1. MinMaxScaler í•¨ìˆ˜ëŠ” MinMaxScalerë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "~~~\n",
    "MinMaxScaler()\n",
    "~~~\n",
    "2. fit_transform í•¨ìˆ˜ëŠ” í›ˆë ¨ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§ì„ ìˆ˜í–‰í•˜ê³ , ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "~~~\n",
    "ìŠ¤ì¼€ì¼ëŸ¬.fit_transform(í›ˆë ¨ ë°ì´í„°)\n",
    "~~~\n",
    "3. transform í•¨ìˆ˜ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§ì„ ìˆ˜í–‰í•˜ê³ , ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "~~~\n",
    "ìŠ¤ì¼€ì¼ëŸ¬.transform(í…ŒìŠ¤íŠ¸ ë°ì´í„°)\n",
    "~~~\n",
    "\n",
    "cf) í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” fitê³¼ transformì„, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” transformë§Œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ìœ„ì—ì„œ ì£¼ì–´ì§„ ì°¸ê³  ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì£¼ì„ì— ë§ê²Œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8137a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.preprocessingì—ì„œ MinMaxScalerë¥¼ import í•´ì˜µë‹ˆë‹¤.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scalerë¼ëŠ” ë³€ìˆ˜ë¥¼ MinMaxScaler í•¨ìˆ˜ë¡œ ì„ ì–¸í•©ë‹ˆë‹¤.\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# X_train_scaledë¼ëŠ” ë³€ìˆ˜ì— ìŠ¤ì¼€ì¼ë§ëœ ë…ë¦½ë³€ìˆ˜ í›ˆë ¨ ì„¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# X_test_scaledë¼ëŠ” ë³€ìˆ˜ì— ìŠ¤ì¼€ì¼ë§ëœ ë…ë¦½ë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5c414",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ìƒì„± ë° í‰ê°€\n",
    "ìœ„ì—ì„œ ë§Œë“  í•¨ìˆ˜ì— inputìœ¼ë¡œ ë“¤ì–´ê°ˆ modelì„ ë§Œë“­ë‹ˆë‹¤. ì´ 4ê°œì˜ ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³¼ ê²ƒì…ë‹ˆë‹¤.\n",
    "1. ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "2. ì˜ì‚¬ ê²°ì • ë‚˜ë¬´\n",
    "3. ì„œí¬íŠ¸ë²¡í„°ë¨¸ì‹ (SVM)\n",
    "4. kNN\n",
    "\n",
    "ë˜í•œ, ìƒì„±í•œ ëª¨ë¸ë“¤ì„ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "1. accuracy\n",
    "2. ë¶„ë¥˜ ë³´ê³ ì„œ\n",
    "\n",
    "cf) í˜¼ë™ í–‰ë ¬ì€ ì´ì§„ë¶„ë¥˜ì— ëŒ€í•´ ë§Œë“¤ì–´ì§€ë¯€ë¡œ, ì´ë²ˆ ì‹¤ìŠµì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f4e36",
   "metadata": {},
   "source": [
    "### ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "ë¡œì§€ìŠ¤í‹± íšŒê·€ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "sklearn ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸(LogisticRegression)ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ìƒì„± í•¨ìˆ˜\n",
    "~~~\n",
    "LogisticRegression()\n",
    "\n",
    "- penalty: ì–´ë–¤ ë°©ì‹ì˜ ê·œì œë¥¼ ì ìš©í• ì§€ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "- C: ê·œì œì˜ ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.\n",
    "\n",
    "- solver: ëª¨ë¸ì˜ ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ì°¾ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "~~~\n",
    "ìœ„ì—ì„œ ì£¼ì–´ì§„ ì°¸ê³  ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì£¼ì„ì— ë§ê²Œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a365483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.linear_modelì—ì„œ LogisticRegression í•¨ìˆ˜ë¥¼ import í•´ì˜¤ì„¸ìš”.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# lr_modelì„ ë³€ìˆ˜ëª…ìœ¼ë¡œ í•´ì„œ ë¡œì§€ìŠ¤í‹±íšŒê·€ ëª¨ë¸ ê°ì²´ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdfa6f2",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , í‰ê°€í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b57eab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì˜ ì •í™•ë„: 0.7303370786516854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      1.00      0.84       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       178\n",
      "   macro avg       0.24      0.33      0.28       178\n",
      "weighted avg       0.53      0.73      0.62       178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1033ddbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1077d1bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107ed1bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1058d1bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104c3dbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103279bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x105301bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x110065bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104065bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106e11bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# ì •í™•ë„ ì¸¡ì •\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "print(\"ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ì˜ ì •í™•ë„:\", lr_accuracy)\n",
    "\n",
    "# ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„±\n",
    "lr_report = classification_report(y_test, lr_pred)\n",
    "print(lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2b3a8",
   "metadata": {},
   "source": [
    "ì´ì œ, ìƒì„±í•œ ëª¨ë¸ì„ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "2ë²ˆì—ì„œ í–‰ì„±í–ˆë˜ predict_survival í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ê°’ê³¼ í™•ë¥ ì„ êµ¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ëŠ” ì–´ë–¤ ì‚¬ëŒì— ëŒ€í•œ ì •ë³´ì…ë‹ˆë‹¤. ìƒì„±í•œ lr ëª¨ë¸ì„ ì´ìš©í•´ì„œ ì´ ì‚¬ëŒì´ ìƒì¡´í• ì§€ ìƒì¡´í•˜ì§€ ëª»í• ì§€, ë˜ ê·¸ ì˜ˆì¸¡ì´ ë§ì„ í™•ë¥ ì€ ì–´ëŠ ì •ë„ì¸ì§€ êµ¬í•˜ì„¸ìš”.\n",
    "\n",
    "[ ì •ë³´ ]\n",
    "- pclass: 2\n",
    "- sex: 'female'\n",
    "- age: 32 \n",
    "- sibsp: 1\n",
    "- parch: 2 \n",
    "- fare: 60\n",
    "- survived: 1\n",
    "- initial: 'Mrs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b82e4f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C', np.float64(0.23511793872537384))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lr_model\n",
    "\n",
    "result, probability = predict_embarked(\n",
    "    model, scaler, survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2f735",
   "metadata": {},
   "source": [
    "### ì˜ì‚¬ ê²°ì • ë‚˜ë¬´\n",
    "ì´ë²ˆì—ëŠ” ì˜ì‚¬ ê²°ì • ë‚˜ë¬´ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê³¼ì •ì€ ëª¨ë‘ ë˜‘ê°™ê³ , ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ëŒ€ì‹  ì˜ì‚¬ ê²°ì • ë‚˜ë¬´ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "sklearn ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì˜ì‚¬ ê²°ì • ë‚˜ë¬´ ëª¨ë¸(DecisionTreeClassifier)ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "ì˜ì‚¬ ê²°ì • ë‚˜ë¬´ ëª¨ë¸ ìƒì„± í•¨ìˆ˜\n",
    "~~~\n",
    "DecisionTreeClassifier(random_state=ì‹œë“œê°’)\n",
    "\n",
    "- random_state: ì„ì˜ì˜ ìˆ«ìë¡œ ì„¤ì •ëœ ì‹œë“œë¡œ, ì–´ë–¤ ìˆ«ìë¥¼ ì‚¬ìš©í•´ë„ ìƒê´€ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- max_depth: íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ë¥¼ ì œí•œí•©ë‹ˆë‹¤. ì´ ê°’ì„ ì‘ê²Œ ì„¤ì •í• ìˆ˜ë¡ ëª¨ë¸ì´ ë‹¨ìˆœí•´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "- min_samples_split: ë…¸ë“œë¥¼ ë¶„í• í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ìµœì†Œí•œì˜ ë°ì´í„°(ìƒ˜í”Œ) ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì´ ê°’ì„ ë†’ê²Œ ì„¤ì •í•˜ë©´ íŠ¸ë¦¬ì˜ ì„±ì¥ì„ ì–µì œí•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- min_samples_leaf: ë¶„í•  í›„, ë¦¬í”„ ë…¸ë“œê°€ ê°€ì ¸ì•¼ í•˜ëŠ” ìµœì†Œí•œì˜ ë°ì´í„°(ìƒ˜í”Œ) ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. min_samples_splitê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ, ë¶„í•  ì´í›„ì˜ ì¡°ê±´ì„ ê²€ì‚¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–´ë–¤ ë…¸ë“œë¥¼ ë¶„í• í–ˆì„ ë•Œ ìì‹ ë…¸ë“œ ì¤‘ í•˜ë‚˜ì˜ ë°ì´í„° ê°œìˆ˜ê°€ ì´ ê°’ë³´ë‹¤ ì‘ì•„ì§„ë‹¤ë©´ í•´ë‹¹ ë¶„í• ì€ ìˆ˜í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ì—­ì‹œ ëª¨ë¸ì„ ë¶€ë“œëŸ½ê²Œ(smoothing) í•˜ê³  ê³¼ì í•©ì„ ë§‰ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ccp_alpha:(Cost-Complexity Pruning) ë¹„ìš© ë³µì¡ë„ ê°€ì§€ì¹˜ê¸°(Pruning)ì— ì‚¬ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. ê°’ì´ í´ìˆ˜ë¡ ë” ë§ì€ ê°€ì§€ê°€ ì˜ë ¤ë‚˜ê°€ íŠ¸ë¦¬ê°€ ë‹¨ìˆœí•´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "- criterion: ë…¸ë“œë¥¼ ë¶„í• í•  ë•Œ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ë¶ˆìˆœë„(Impurity)ë¥¼ ì¸¡ì •í• ì§€ ê²°ì •í•©ë‹ˆë‹¤. ë¶ˆìˆœë„ëŠ” í•œ ë…¸ë“œì— ì—¬ëŸ¬ í´ë˜ìŠ¤ì˜ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì„ì—¬ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤. 'gini' ì•„ë‹ˆë©´ 'entropy'ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- max_features: ìµœì ì˜ ë¶„í• ì„ ì°¾ê¸° ìœ„í•´ ê³ ë ¤í•  í”¼ì²˜(ë³€ìˆ˜)ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ë§¤ ë¶„í• ë§ˆë‹¤ ëª¨ë“  í”¼ì²˜ë¥¼ ê³ ë ¤í•˜ëŠ” ëŒ€ì‹ , ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì¼ë¶€ í”¼ì²˜ ì¤‘ì—ì„œë§Œ ìµœì ì˜ ë¶„í•  ê¸°ì¤€ì„ ì°¾ìŠµë‹ˆë‹¤. ì´ëŠ” íŠ¸ë¦¬ê°€ íŠ¹ì • í”¼ì²˜ì— ê³¼ë„í•˜ê²Œ ì˜ì¡´í•˜ëŠ” ê²ƒì„ ë§‰ì•„ì£¼ë©°, íŠ¹íˆ í”¼ì²˜ê°€ ë§¤ìš° ë§ì„ ë•Œ ê³¼ì í•© ë°©ì§€ ë° í›ˆë ¨ ì†ë„ í–¥ìƒì— ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
    "~~~\n",
    "\n",
    "ìœ„ì—ì„œ ì£¼ì–´ì§„ ì°¸ê³  ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì£¼ì„ì— ë§ê²Œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72cf8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.treeì—ì„œ DecisionTreeClassifierë¥¼ import í•´ì˜¤ì„¸ìš”.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# tree_modelì´ë¼ëŠ” ë³€ìˆ˜ì— ì˜ì‚¬ ê²°ì • ë‚˜ë¬´ ëª¨ë¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”. ë‹¨, random_stateëŠ” 42ë¡œ í•©ë‹ˆë‹¤.\n",
    "tree_model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce444b31",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì„ í•™ìŠµ, í‰ê°€í•˜ê³  ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16e6ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree ëª¨ë¸ì˜ ì •í™•ë„: 0.702247191011236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.88      0.82       130\n",
      "           2       0.38      0.22      0.28        36\n",
      "           3       0.38      0.25      0.30        12\n",
      "\n",
      "    accuracy                           0.70       178\n",
      "   macro avg       0.51      0.45      0.47       178\n",
      "weighted avg       0.66      0.70      0.67       178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Q', np.float64(0.0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\n",
    "tree_pred = tree_model.predict(X_test_scaled)\n",
    "\n",
    "# ì •í™•ë„ ì¸¡ì •\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"Decision Tree ëª¨ë¸ì˜ ì •í™•ë„:\", tree_accuracy)\n",
    "\n",
    "# ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„±\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(tree_report)\n",
    "\n",
    "model = tree_model\n",
    "\n",
    "result, probability = predict_embarked(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21068de6",
   "metadata": {},
   "source": [
    "### ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  (SVM)\n",
    "ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ì—­ì‹œ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "sklearn ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë¶„ë¥˜ê¸°(SVC=Support Vector Classification)ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ëª¨ë¸ ìƒì„± í•¨ìˆ˜\n",
    "~~~\n",
    "SVC(random_state=ì‹œë“œê°’, probability=True/False)\n",
    "\n",
    "- random_state: ì„ì˜ì˜ ìˆ«ìë¡œ ì„¤ì •ëœ ì‹œë“œë¡œ, ì–´ë–¤ ìˆ«ìë¥¼ ì‚¬ìš©í•´ë„ ìƒê´€ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- probability: ëª¨ë¸ì´ í´ë˜ìŠ¤ì˜ í™•ë¥ ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "- C: ë§ˆì§„ì˜ ë„ˆë¹„ì™€ ì˜¤ë¥˜ ë°ì´í„°(Margin Violation)ë¥¼ ì–¼ë§ˆë‚˜ í—ˆìš©í• ì§€ë¥¼ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.\n",
    "\n",
    "- kernel: ë°ì´í„°ë¥¼ ì–´ë–¤ ê³µê°„ì—ì„œ ë°”ë¼ë³¼ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- gamma: ë¹„ì„ í˜• ì»¤ë„ì—ì„œë§Œ ì˜ë¯¸ê°€ ìˆëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. í•˜ë‚˜ì˜ ë°ì´í„° ìƒ˜í”Œì´ ê²½ê³„ì„ ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë²”ìœ„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "~~~\n",
    "\n",
    "ìœ„ì—ì„œ ì£¼ì–´ì§„ ì°¸ê³  ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì£¼ì„ì— ë§ê²Œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad91ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.svmì—ì„œ SVCë¥¼ import í•´ì˜¤ì„¸ìš”.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# svm_model ë‹¨, random_stateëŠ” 42, probability=Trueë¡œ í•©ë‹ˆë‹¤.\n",
    "svm_model = SVC(random_state=42,probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be58a7",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì„ í•™ìŠµ, í‰ê°€í•˜ê³  ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c78b3924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM ëª¨ë¸ì˜ ì •í™•ë„: 0.7415730337078652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.99      0.85       130\n",
      "           2       0.00      0.00      0.00        36\n",
      "           3       0.75      0.25      0.38        12\n",
      "\n",
      "    accuracy                           0.74       178\n",
      "   macro avg       0.50      0.41      0.41       178\n",
      "weighted avg       0.59      0.74      0.65       178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('S', np.float64(0.16628248561834877))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ í›ˆë ¨\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# SVM ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# ì •í™•ë„ ì¸¡ì •\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(\"SVM ëª¨ë¸ì˜ ì •í™•ë„:\", svm_accuracy)\n",
    "\n",
    "# ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„±\n",
    "svm_report = classification_report(y_test, svm_pred)\n",
    "print(svm_report)\n",
    "\n",
    "# ìƒì„±í•œ ëª¨ë¸ë¡œ ì˜ˆì¸¡ê°’ê³¼ í™•ë¥  ë„ì¶œ\n",
    "model = svm_model\n",
    "\n",
    "result, probability = predict_embarked(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921903ff",
   "metadata": {},
   "source": [
    "### kNN\n",
    "kNN ì—­ì‹œ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "sklearn ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” kNN ëª¨ë¸(KNeighborsClassifier)ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "kNN ëª¨ë¸ ìƒì„± í•¨ìˆ˜\n",
    "~~~\n",
    "KNeighborsClassifier(n_neighbors=ì´ì›ƒ ìˆ˜)\n",
    "\n",
    "- n_neighbors: ê³ ë ¤í•  ìµœê·¼ì ‘ ì´ì›ƒì˜ ê°œìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "- weights: kê°œì˜ ì´ì›ƒì„ ì°¾ì•˜ì„ ë•Œ, ê·¸ë“¤ì˜ ì˜ê²¬ì„ ì–´ë–¤ ê°€ì¤‘ì¹˜ë¡œ ë°˜ì˜í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- metric: ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì´ì˜ 'ê±°ë¦¬'ë¥¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì¸¡ì •í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "~~~\n",
    "\n",
    "ìœ„ì—ì„œ ì£¼ì–´ì§„ ì°¸ê³  ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì£¼ì„ì— ë§ê²Œ ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4045e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.neighborsì—ì„œ KNeighborsClassifierë¥¼ import í•´ì˜¤ì„¸ìš”.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# knn_modelì´ë¼ëŠ” ë³€ìˆ˜ì— kNN ëª¨ë¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”. ë‹¨, n_neighbors=5ë¡œ í•©ë‹ˆë‹¤.\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89faa12a",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ì„ í•™ìŠµ, í‰ê°€í•˜ê³  ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aed45a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN ëª¨ë¸ì˜ ì •í™•ë„ :  0.6966292134831461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.88      0.81       130\n",
      "           2       0.32      0.19      0.24        36\n",
      "           3       0.50      0.25      0.33        12\n",
      "\n",
      "    accuracy                           0.70       178\n",
      "   macro avg       0.53      0.44      0.46       178\n",
      "weighted avg       0.65      0.70      0.67       178\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C', np.float64(0.2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "knn_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# ì •í™•ë„ ì¸¡ì •\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(\"kNN ëª¨ë¸ì˜ ì •í™•ë„ : \", knn_accuracy)\n",
    "\n",
    "# ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„±\n",
    "knn_report = classification_report(y_test, knn_pred)\n",
    "print(knn_report)\n",
    "\n",
    "# ìƒì„±í•œ ëª¨ë¸ë¡œ ì˜ˆì¸¡ê°’ê³¼ í™•ë¥  ë„ì¶œ\n",
    "model = knn_model\n",
    "\n",
    "result, probability = predict_embarked(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "\n",
    "result, probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6bf7b",
   "metadata": {},
   "source": [
    "## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\n",
    "\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ì‹œë‹¤.\n",
    "\n",
    "ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì— Grid Searchì™€ Random Searchë¥¼ ì ìš©í•´ë´…ì‹œë‹¤!\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ëª¨ë¸ ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "~~~\n",
    "DecisionTreeClassifier()\n",
    "\n",
    "- max_depth: íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ë¥¼ ì œí•œí•©ë‹ˆë‹¤. ì´ ê°’ì„ ì‘ê²Œ ì„¤ì •í• ìˆ˜ë¡ ëª¨ë¸ì´ ë‹¨ìˆœí•´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "- min_samples_split: ë…¸ë“œë¥¼ ë¶„í• í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ìµœì†Œí•œì˜ ë°ì´í„°(ìƒ˜í”Œ) ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì´ ê°’ì„ ë†’ê²Œ ì„¤ì •í•˜ë©´ íŠ¸ë¦¬ì˜ ì„±ì¥ì„ ì–µì œí•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- min_samples_leaf: ë¶„í•  í›„, ë¦¬í”„ ë…¸ë“œê°€ ê°€ì ¸ì•¼ í•˜ëŠ” ìµœì†Œí•œì˜ ë°ì´í„°(ìƒ˜í”Œ) ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. min_samples_splitê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ, ë¶„í•  ì´í›„ì˜ ì¡°ê±´ì„ ê²€ì‚¬í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–´ë–¤ ë…¸ë“œë¥¼ ë¶„í• í–ˆì„ ë•Œ ìì‹ ë…¸ë“œ ì¤‘ í•˜ë‚˜ì˜ ë°ì´í„° ê°œìˆ˜ê°€ ì´ ê°’ë³´ë‹¤ ì‘ì•„ì§„ë‹¤ë©´ í•´ë‹¹ ë¶„í• ì€ ìˆ˜í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ ì—­ì‹œ ëª¨ë¸ì„ ë¶€ë“œëŸ½ê²Œ(smoothing) í•˜ê³  ê³¼ì í•©ì„ ë§‰ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ccp_alpha:(Cost-Complexity Pruning) ë¹„ìš© ë³µì¡ë„ ê°€ì§€ì¹˜ê¸°(Pruning)ì— ì‚¬ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤. ê°’ì´ í´ìˆ˜ë¡ ë” ë§ì€ ê°€ì§€ê°€ ì˜ë ¤ë‚˜ê°€ íŠ¸ë¦¬ê°€ ë‹¨ìˆœí•´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "- criterion: ë…¸ë“œë¥¼ ë¶„í• í•  ë•Œ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ë¶ˆìˆœë„(Impurity)ë¥¼ ì¸¡ì •í• ì§€ ê²°ì •í•©ë‹ˆë‹¤. ë¶ˆìˆœë„ëŠ” í•œ ë…¸ë“œì— ì—¬ëŸ¬ í´ë˜ìŠ¤ì˜ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì„ì—¬ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤. 'gini' ì•„ë‹ˆë©´ 'entropy'ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- max_features: ìµœì ì˜ ë¶„í• ì„ ì°¾ê¸° ìœ„í•´ ê³ ë ¤í•  í”¼ì²˜(ë³€ìˆ˜)ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ë§¤ ë¶„í• ë§ˆë‹¤ ëª¨ë“  í”¼ì²˜ë¥¼ ê³ ë ¤í•˜ëŠ” ëŒ€ì‹ , ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì¼ë¶€ í”¼ì²˜ ì¤‘ì—ì„œë§Œ ìµœì ì˜ ë¶„í•  ê¸°ì¤€ì„ ì°¾ìŠµë‹ˆë‹¤. ì´ëŠ” íŠ¸ë¦¬ê°€ íŠ¹ì • í”¼ì²˜ì— ê³¼ë„í•˜ê²Œ ì˜ì¡´í•˜ëŠ” ê²ƒì„ ë§‰ì•„ì£¼ë©°, íŠ¹íˆ í”¼ì²˜ê°€ ë§¤ìš° ë§ì„ ë•Œ ê³¼ì í•© ë°©ì§€ ë° í›ˆë ¨ ì†ë„ í–¥ìƒì— ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
    "~~~\n",
    "\n",
    "\n",
    "ğŸ’¡ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë°©ë²•\n",
    "- Grid Search: ì •í•´ì§„ ë²”ìœ„ì—ì„œ Hyperparameterë¥¼ ëª¨ë‘ ìˆœíšŒ\n",
    "- Random Search: ì •í•´ì§„ ë²”ìœ„ì—ì„œ Hyperparameterë¥¼ ë¬´ì‘ìœ„ë¡œ íƒìƒ‰\n",
    "- Bayesian Optimization: ì‚¬ì „ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ Hyperparameter ê°’ì„ í™•ë¥ ì ìœ¼ë¡œ ì¶”ì •í•˜ë©° íƒìƒ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d4167",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "ì •í•´ì§„ ë²”ìœ„ì—ì„œ Hyperparameterë¥¼ ëª¨ë‘ ìˆœíšŒí•˜ë©° ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ê°’ì„ ì°¾ëŠ” ê¸°ë²•\n",
    "- **ì¥ì **: ë²”ìœ„ê°€ ë„“ê³  stepì´ ì‘ì„ìˆ˜ë¡ ê¼¼ê¼¼í•˜ê²Œ ì „ ë²”ìœ„ë¥¼ íƒìƒ‰í•˜ë‹ˆ ìµœì í•´ë¥¼ **ì •í™•íˆ ì°¾ì„ ìˆ˜ ìˆë‹¤**.\n",
    "- **ë‹¨ì **: ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.\n",
    "- **ì ìš©**: ë„“ì€ ë²”ìœ„, í° stepì„ í™œìš©í•´ ë²”ìœ„ë¥¼ ì¢íŒë‹¤.\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "Grid Search ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "~~~\n",
    "GridSearchCV()\n",
    "\n",
    "- estimator: íŠœë‹í•  ëª¨ë¸ ê°ì²´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- param_grid: í…ŒìŠ¤íŠ¸í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì˜ ëª©ë¡ì„ ì‚¬ì „(dictionary) í˜•íƒœë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "- cv: êµì°¨ ê²€ì¦(Cross-Validation)ì„ ì–´ë–»ê²Œ ìˆ˜í–‰í• ì§€ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- scoring: ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•˜ê¸° ìœ„í•œ í‰ê°€ ì§€í‘œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- n_jobs: íŠœë‹ì„ ìˆ˜í–‰í•  ë•Œ ì‚¬ìš©í•  CPU ì½”ì–´ì˜ ê°œìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- verbose: íŠœë‹ ê³¼ì •ì—ì„œ ì¶œë ¥ë˜ëŠ” ë©”ì‹œì§€ì˜ ì–‘ì„ ì¡°ì ˆí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d78cd8-7c8d-4c1a-9b4b-687e66e52311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: 0.7243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Decision Tree ëª¨ë¸ ìƒì„±\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# íŠœë‹í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ í›„ë³´ ê°’ë“¤ ì„¤ì •\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],         # íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´\n",
    "    'min_samples_split': [2, 5, 10],    # ë…¸ë“œë¥¼ ë‚˜ëˆ„ê¸° ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜\n",
    "    'min_samples_leaf': [1, 3, 5]       # ë¦¬í”„ ë…¸ë“œê°€ ë˜ê¸° ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜\n",
    "}\n",
    "\n",
    "# GridSearchCV ê°ì²´ ìƒì„± (cv: 5ê²¹ êµì°¨ê²€ì¦)\n",
    "# n_jobs=-1 ì€ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  CPU ì½”ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
    "grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, \n",
    "                           cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ê¸° ìœ„í•´ ëª¨ë¸ í•™ìŠµ\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ê·¸ë•Œì˜ ìµœê³  ì ìˆ˜ ì¶œë ¥\n",
    "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\", grid_search.best_params_)\n",
    "print(f\"ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Grid Searchê°€ ì°¾ì€ ìµœì ì˜ ëª¨ë¸ì„ ì €ì¥\n",
    "best_tree_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e22afb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "íŠœë‹ëœ Decision Tree ëª¨ë¸ì˜ ì •í™•ë„: 0.7696629213483146\n",
      "\n",
      "[íŠœë‹ëœ ëª¨ë¸ì˜ ë¶„ë¥˜ ë³´ê³ ì„œ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.93      0.86       130\n",
      "           2       0.63      0.33      0.44        36\n",
      "           3       0.57      0.33      0.42        12\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.67      0.53      0.57       178\n",
      "weighted avg       0.75      0.77      0.74       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ìµœì  ëª¨ë¸ë¡œ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\n",
    "tree_pred = best_tree_model.predict(X_test)\n",
    "\n",
    "# ì •í™•ë„ ì¸¡ì •\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"\\níŠœë‹ëœ Decision Tree ëª¨ë¸ì˜ ì •í™•ë„:\", tree_accuracy)\n",
    "\n",
    "# ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„±\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(\"\\n[íŠœë‹ëœ ëª¨ë¸ì˜ ë¶„ë¥˜ ë³´ê³ ì„œ]\")\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4cf7f3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼]\n",
      "ì˜ˆì¸¡ ê²°ê³¼: Q\n",
      "ìƒì¡´ í™•ë¥ : 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ìµœì í™”ëœ ëª¨ë¸ì¸ 'best_tree_model'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "model = best_tree_model\n",
    "\n",
    "result, probability = predict_embarked(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "print(\"\\n[ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼]\")\n",
    "print(\"ì˜ˆì¸¡ ê²°ê³¼:\", result)\n",
    "print(\"ìƒì¡´ í™•ë¥ :\", probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd552b",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "ì •í•´ì§„ ë²”ìœ„ì—ì„œ Hyperparameterë¥¼ **ë¬´ì‘ìœ„**ë¡œ íƒìƒ‰í•´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ê°’ì„ ì°¾ëŠ” ê¸°ë²•\n",
    "- **ì¥ì **: ì†ë„ê°€ Grid Searchë³´ë‹¤ ë¹ ë¥´ë‹¤.\n",
    "- **ë‹¨ì **: ë¬´ì‘ìœ„ë¼ëŠ” í•œê³„ ë•Œë¬¸ì— **ì •í™•ë„ê°€ ë–¨ì–´ì§„ë‹¤**. ë”°ë¼ì„œ Grid Searchë‚˜ Bayesian Optimizationì— ë¹„í•´ ì‚¬ìš© ë¹ˆë„ê°€ ì ë‹¤.\n",
    "\n",
    "[ ì°¸ê³  ]\n",
    "Grid Search ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "~~~\n",
    "RandomizedSearchCV()\n",
    "\n",
    "- estimator: íŠœë‹í•  ëª¨ë¸ ê°ì²´ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- param_distributions: íƒìƒ‰í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ë¶„í¬ ë˜ëŠ” ëª©ë¡ì„ ì‚¬ì „(dictionary) í˜•íƒœë¡œ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- n_iter: ì§€ì •ëœ param_distributionsì—ì„œ ëª‡ ê°œì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œí•˜ì—¬ í…ŒìŠ¤íŠ¸í• ì§€ ê·¸ íšŸìˆ˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- random_state: ê²°ê³¼ì˜ ì¬í˜„ì„±(reproducibility)ì„ ìœ„í•œ íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.\n",
    "\n",
    "- cv: êµì°¨ ê²€ì¦ ë¶„í•  ê°œìˆ˜\n",
    "\n",
    "- scoring: ìµœì  ëª¨ë¸ ì„ íƒì„ ìœ„í•œ í‰ê°€ ì§€í‘œ\n",
    "\n",
    "- n_jobs: ì‚¬ìš©í•  CPU ì½”ì–´ ìˆ˜\n",
    "\n",
    "- verbose: ì§„í–‰ ê³¼ì • ì¶œë ¥ ë©”ì‹œì§€ ì–‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83bd28b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'min_samples_split': 20, 'min_samples_leaf': 2, 'max_depth': 3, 'criterion': 'gini'}\n",
      "ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: 0.7243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# ê¸°ë³¸ Decision Tree ëª¨ë¸ ìƒì„±\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# íŠœë‹í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ í›„ë³´ ê°’ë“¤ ì„¤ì •\n",
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, 20, None], # Noneì€ ê¹Šì´ ì œí•œ ì—†ìŒì„ ì˜ë¯¸\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV ê°ì²´ ìƒì„±\n",
    "# n_iter: ì‹œë„í•  íŒŒë¼ë¯¸í„° ì¡°í•©ì˜ ìˆ˜ (ë§ì„ìˆ˜ë¡ ì¢‹ì€ ì¡°í•©ì„ ì°¾ì„ í™•ë¥ ì´ ë†’ì§€ë§Œ, ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)\n",
    "# cv: 5ê²¹ êµì°¨ê²€ì¦\n",
    "# n_jobs=-1: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  CPU ì½”ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ì†ë„ í–¥ìƒ\n",
    "random_search = RandomizedSearchCV(estimator=tree_model,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=100, # 100ê°œì˜ íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ë¬´ì‘ìœ„ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "                                   cv=5, \n",
    "                                   verbose=1, \n",
    "                                   random_state=42, # ê²°ê³¼ë¥¼ ì¬í˜„í•˜ê¸° ìœ„í•´ random_state ì„¤ì •\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ê¸° ìœ„í•´ ëª¨ë¸ í•™ìŠµ\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ê·¸ë•Œì˜ ìµœê³  ì ìˆ˜ ì¶œë ¥\n",
    "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\", random_search.best_params_)\n",
    "print(f\"ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Random Searchê°€ ì°¾ì€ ìµœì ì˜ ëª¨ë¸ì„ ì €ì¥\n",
    "best_tree_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14879d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "íŠœë‹ëœ Decision Tree ëª¨ë¸ì˜ ì •í™•ë„: 0.7696629213483146\n",
      "\n",
      "[íŠœë‹ëœ ëª¨ë¸ì˜ ë¶„ë¥˜ ë³´ê³ ì„œ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.93      0.86       130\n",
      "           2       0.63      0.33      0.44        36\n",
      "           3       0.57      0.33      0.42        12\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.67      0.53      0.57       178\n",
      "weighted avg       0.75      0.77      0.74       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ìµœì  ëª¨ë¸ë¡œ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±\n",
    "tree_pred = best_tree_model.predict(X_test)\n",
    "\n",
    "# ì •í™•ë„ ì¸¡ì •\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(\"\\níŠœë‹ëœ Decision Tree ëª¨ë¸ì˜ ì •í™•ë„:\", tree_accuracy)\n",
    "\n",
    "# ë¶„ë¥˜ ë³´ê³ ì„œ ìƒì„±\n",
    "tree_report = classification_report(y_test, tree_pred)\n",
    "print(\"\\n[íŠœë‹ëœ ëª¨ë¸ì˜ ë¶„ë¥˜ ë³´ê³ ì„œ]\")\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1ee1dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼]\n",
      "ì˜ˆì¸¡ ê²°ê³¼: Q\n",
      "ìƒì¡´ í™•ë¥ : 0.5555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. íŠœë‹ëœ ìµœì  ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡\n",
    "model = best_tree_model\n",
    "\n",
    "result, probability = predict_embarked(\n",
    "    model, scaler, \n",
    "    survived=1,\n",
    "    pclass=2, sex='female', age=32, \n",
    "    sibsp=1, parch=2, \n",
    "    fare=60, initial='Mrs'\n",
    ")\n",
    "\n",
    "print(\"\\n[ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼]\")\n",
    "print(\"ì˜ˆì¸¡ ê²°ê³¼:\", result)\n",
    "print(\"ìƒì¡´ í™•ë¥ :\", probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45544d",
   "metadata": {},
   "source": [
    "## ëìœ¼ë¡œ...\n",
    "\n",
    "ì´ë²ˆ ì„¸ì…˜ì—ì„œ ë°°ìš´ ëª¨ë¸ë“¤(ë¡œì§€ìŠ¤í‹± íšŒê·€, ì˜ì‚¬ê²°ì •ë‚˜ë¬´, SVM, kNN)ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•˜ì—¬ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”!\n",
    "\n",
    "ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ 1ë“±ì—ê²ŒëŠ” ì†Œì •ì˜ ìƒí’ˆì´ ì§€ê¸‰ë  ì˜ˆì •ì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2800073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08571bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 28 is smaller than n_iter=50. Running 28 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 1000, 'C': np.float64(0.001)}\n",
      "ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: 0.7229\n"
     ]
    }
   ],
   "source": [
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_param_dist = {\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['saga'],\n",
    "    'max_iter': [1000, 5000]\n",
    "}\n",
    "lr_random_search = RandomizedSearchCV(lr_model, lr_param_dist, n_iter=50, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "lr_random_search.fit(X_train, y_train)\n",
    "best_lr_model = lr_random_search.best_estimator_\n",
    "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\", lr_random_search.best_params_)\n",
    "print(f\"ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: {lr_random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43072252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5, 'criterion': 'entropy'}\n",
      "ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: 0.7257\n"
     ]
    }
   ],
   "source": [
    "# ì˜ì‚¬ê²°ì •ë‚˜ë¬´\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_param_dist = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "tree_random_search = RandomizedSearchCV(tree_model, tree_param_dist, n_iter=50, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "tree_random_search.fit(X_train, y_train)\n",
    "best_tree_model = tree_random_search.best_estimator_\n",
    "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\", tree_random_search.best_params_)\n",
    "print(f\"ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: {tree_random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4f147b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'kernel': 'rbf', 'gamma': np.float64(1.0), 'C': np.float64(1.0)}\n",
      "ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: 0.7272\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = SVC(random_state=42, probability=True)\n",
    "svm_param_dist = {\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': np.logspace(-3, 3, 7)\n",
    "}\n",
    "svm_random_search = RandomizedSearchCV(svm_model, svm_param_dist, n_iter=50, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "svm_random_search.fit(X_train, y_train)\n",
    "best_svm_model = svm_random_search.best_estimator_\n",
    "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\", svm_random_search.best_params_)\n",
    "print(f\"ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: {svm_random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3346a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {'weights': 'uniform', 'n_neighbors': 10, 'metric': 'manhattan'}\n",
      "ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: 0.7384\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_param_dist = {\n",
    "    'n_neighbors': range(1, 31),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_random_search = RandomizedSearchCV(knn_model, knn_param_dist, n_iter=50, cv=5, verbose=0, random_state=42, n_jobs=-1)\n",
    "knn_random_search.fit(X_train, y_train)\n",
    "best_knn_model = knn_random_search.best_estimator_\n",
    "print(\"ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\", knn_random_search.best_params_)\n",
    "print(f\"ìµœê³  êµì°¨ê²€ì¦ ì •í™•ë„: {knn_random_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1edca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ìµœì¢… ëª¨ë¸ ì •í™•ë„ ë¹„êµ\n",
      "ë¡œì§€ìŠ¤í‹±íšŒê·€ ì •í™•ë„: 0.7303\n",
      "ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì •í™•ë„: 0.7753\n",
      "SVM ì •í™•ë„: 0.7697\n",
      "kNN ì •í™•ë„: 0.7584\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nìµœì¢… ëª¨ë¸ ì •í™•ë„ ë¹„êµ\")\n",
    "\n",
    "models = {\n",
    "    'ë¡œì§€ìŠ¤í‹±íšŒê·€': best_lr_model,\n",
    "    'ì˜ì‚¬ê²°ì •ë‚˜ë¬´': best_tree_model,\n",
    "    'SVM': best_svm_model,\n",
    "    'kNN': best_knn_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} ì •í™•ë„: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21078d84",
   "metadata": {},
   "source": [
    "## ì˜ì‚¬ê²°ì •ë‚˜ë¬´ê°€ 0.7753ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ì •í™•ë„!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
