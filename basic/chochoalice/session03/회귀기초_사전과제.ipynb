{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d404ba1b",
   "metadata": {},
   "source": [
    "# **1)머신러닝과 모델링**  \n",
    "딥러닝<머신러닝<인공지능  \n",
    "\n",
    "### 1-1)머신러닝  \n",
    "-인공지능의 한 분야  \n",
    "-모델을 학습하여 패턴을 찾아내고 새로운 데이터 예측     \n",
    "1. 지도학습: 라벨이 있는 데이터 학습 >> 예측, 분류  ex) 회귀, 분류   \n",
    "2. 비지도학습: 라벨이 없는 데이터 학습 >> 연관 규칙, 군집  ex) 군집화, 밀도추정, 차원축소   \n",
    "3. 강화학습: 시행착오를 반복하여 정답을 찾는 과정 >> 보상  ex) 알파고    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd3a71",
   "metadata": {},
   "source": [
    "# **2)지도 학습**  \n",
    "### 2-1)지도학습  \n",
    "- 예측값과 정답이 같아지도록 학습  \n",
    "- labeled data  \n",
    "  -trainind data  \n",
    "  -test data  \n",
    "훈련 데이터로 모델 학습, 테스트 데이터로 모델 검증  \n",
    "\n",
    "### 2-2)회귀와 분류  \n",
    "\n",
    "2-2-1)  \n",
    "회귀: 주어진 데이터를 기반으로 정답을 잘 맞추도록 하는 함수  \n",
    "종속변수(반응변수): Y  \n",
    "독립변수(설명변수): X   \n",
    "\n",
    "2-2-2)   \n",
    "분류: 기존 데이터가 어떤 레이블에 속하는지 패턴을 찾은 후 새로운 데이터에 대한 레이블 찾는 것   \n",
    "\n",
    "2-2-3) 회귀와 분류의 차이   \n",
    "-회귀: 데이터가 **연속형** 변수를 예측하기 위해 사용  \n",
    "-분류: 데이터가 **범주형** 변수를 예측하기 위해 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4937b",
   "metadata": {},
   "source": [
    "# **3)선형회귀**  \n",
    "=데이터를 가장 잘 설명하는 회귀선을 찾는 과정  \n",
    "=현재 데이터 요약->미래 값 예측  \n",
    "\n",
    "### 3-1)단순선형회귀분석\n",
    "- 하나의 독립변수만 존재하는 선형 회귀  \n",
    "- y=ax+b를 찾는 과정\n",
    "  -a:회귀계수(기울기)  \n",
    "  -b:y절편  \n",
    "\n",
    "3-1-1) 최소제곱법  \n",
    "- 잔차: 실제값-예측값  \n",
    "- 잔차의 제곱합(RSS)가 최소가 되는 지점으로 최적의 회귀선을 구하는 방식   \n",
    "\n",
    "3-1-2) 경사하강법  \n",
    "- 최소제곱법을 통해 구한 함수가 복잡할 때 사용\n",
    "(???)\n",
    "\n",
    "- 목적함수: 최적화를 위해 오차를 최소화하는 것이 목적인 함수   \n",
    "           모델의 예측이 얼마나 잘 맞는지 평가하는 기준이 됨   \n",
    "- 손실함수: 개별 데이터 샘플에 대한 오차를 측정하는 함수  \n",
    "           예측값과 실제값의 차이 계산     \n",
    "           잔차를 제곱한 뒤 합\n",
    "- 비용함수: 전체 데이터셋에서 평균적인 손실을 측정하는 함수  \n",
    "           손실함수를 모든 데이터 포인트에 대해 계산한 후 평균을 내거나 합산  \n",
    "\n",
    "비용함수를 최소화=목적함수의 최적화 방향  \n",
    "최솟값의 왼쪽에 있는 점은 그래프 기울기 음수(오른쪽 점은 반대)  \n",
    "현재값-미분값  ->  현재값 커짐(오른쪽으로 점 이동)  \n",
    "최솟값에 도달하면 미분값이 0이 되므로 멈춤  \n",
    "\n",
    "- 학습률: '얼만큼'  \n",
    "       -학습률이 작으면 시간이 오래 걸림  \n",
    "       -학습률이 크면 모델이 수렴하지 못하고 발산  \n",
    "\n",
    "- local minima 문제: \n",
    "모든 비용함수가 하나의 최솟값을 가지는 형태는 아님  \n",
    "작은 기울기에서 더 조금씩 움직임  \n",
    "-->>해결법: 모멘텀  \n",
    "이전 기울기와 방향까지 고려할 수 있도록 함  \n",
    "지역 최솟값을 탈출할 수 있게 함  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4054ed",
   "metadata": {},
   "source": [
    "### 3-2)단순선형회귀분석  \n",
    "독립변수가 2개 이상인 경우의 선형회귀  \n",
    "단순회귀분석과 마찬가지로 최소제곱법 사용  \n",
    "\n",
    "3-2-1) 다중공선성  \n",
    "독립변수들 간에 상관관계가 큰 경우 발생  \n",
    "히트맵 혹은 corr() 함수를 통해 상관계수 확인  \n",
    "\n",
    "- j번째 독립변수인 Xj를 종속변수로 하고 나머지 k-1개의 변수를 독립변수로 하여 결정계수 R-square(SSR/SST) 확인  \n",
    "0.8이상이면 가능성 의심  \n",
    "0.9이상이면 심각  \n",
    "- VIF: 분산팽창인자    \n",
    "1/(1-R^2)    \n",
    "5이상이면 의심   \n",
    "10이상이면 심각한 수준   \n",
    "\n",
    "- 다중공선성 대처 방법:  \n",
    "1. 변수제거(변수선택법)  \n",
    "2. 변수 변환: 변수를 더하거나 빼서 새로운 변수 생성  \n",
    "3. 규제 선형 모델 활용: 릿지, 라쏘, 엘라스틱넷 등의 방법을 통해 모델의 복잡도 줄임  \n",
    "4. PCA(주성분분석): 데이터의 차원을 축소, 상관있는 변수들끼리 묶어서 단순화  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7057442",
   "metadata": {},
   "source": [
    "# **4)규제선형모델**  \n",
    "- 과적합 되지 않도록 규제를 가하고자 등장 -> 선형회귀모델: 특성에 곱해지는 계수(기울기)의 크기를 조정하는 것  \n",
    "- 회귀계수가 커지면 특정 독립 변수의 특성에 과하게 의존한다는 의미  \n",
    "\n",
    "*잔차제곱합 RSS=SSE*\n",
    "\n",
    "- 규제선형모델의 종류:  \n",
    "1. L2규제 : W(회귀계수)의 제곱에 대해 페널티를 부여하는 방식, 릿지(Ridge)회귀  \n",
    "2. L1규제 :  W(회귀계수)의 절댓값에 대해 페널티를 부여하는 방식, 라쏘(Lasso) 회귀  \n",
    "3. L2규제 + L1규제 결합 : 엘라스틱넷(Elastic Net) 회귀  \n",
    "\n",
    "### 4-1) 릿지회귀  \n",
    "패널티: 회귀계수의 제곱 -> 큰 회귀계수일수록 강한 패널티 -> 변수 제거 없이 계수 크기 조절 가능  \n",
    "### 4-2) 라쏘회귀  \n",
    "패널티: 회귀계수의 절댓값 -> 비중이 낮은 변수는 사라질 가능성 -> 중요한 변수만 남음  \n",
    "### 4-3) 엘라스틱넷  \n",
    "불필요한 변수 제거, 남은 변수의 영향 조절   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb0df8",
   "metadata": {},
   "source": [
    "# **5)모델평가방법**   \n",
    "\n",
    "### 5-1) 성능평가지표  \n",
    "1. 평균 제곱 오차 (MSE): 잔차 **제곱** 평균, 이상치에 민감  \n",
    "2. 평균 절대 오차 (MAE): 예측값과 관측값 사이의 **절대값** 오차의 평균   \n",
    "\n",
    "*제곱합 SST = SSR + SSE(RSS)*    \n",
    "*자유도 n-1 = k + (n-k-1)*    \n",
    "*MSR = SSR/k*    \n",
    "*MSE = SSE/(n-k-1)*   \n",
    "*표준오차 = 루트 MSE*  \n",
    "\n",
    "### 5-2) 변수 유의성 평가  \n",
    "\n",
    "부분검정  \n",
    "\n",
    "1. t 검정  \n",
    "독립변수의 회귀계수가 유의미한지 검정  \n",
    "t = (추정된 회귀계수-0)/표준오차\n",
    "귀무가설: 회귀계수 = 0 (독립변수가 종속변수에 영향 X)   \n",
    "대립가설: 회귀계수 =/= 0 (독립변수가 종속변수에 영향)   \n",
    "\n",
    "t 분포를 따름 t(n-k-1)  \n",
    "- 검정과정:  \n",
    "  1. t값계산\n",
    "  2. p값 확인 및 판단 \n",
    "     유의수준 0.05 에서 기각 -> 해당 변수는 유의미  \n",
    "\n",
    "t값이 크면 귀무가설을 기각할 가능성 높아짐  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
