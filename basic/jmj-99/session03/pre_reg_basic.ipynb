{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9836f2b",
   "metadata": {},
   "source": [
    "# 회귀 기초 사전 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6dba0",
   "metadata": {},
   "source": [
    "## 머신러닝과 모델링 <BR>\n",
    "### <span style='background-color: #FFF5B1'> **<u>머신러닝과 종류</u>**</span> <BR>\n",
    "- 인공지능의 한 분야  \n",
    "- 모델 학습 → 데이터 예측 or 의사결정을 돕는 기술   \n",
    "<BR>  \n",
    "\n",
    "|  | 정답 | 방식 | 예시 |   \n",
    "| ---- | ---- | ---- | ---- |  \n",
    "| 지도 학습 | 주어짐 | 기존의 정답과 예측값이 같아지도록 기계 학습 | 회귀, 분류 |    \n",
    "| 비지도 학습 | 주어지지 않음 | 데이터 속 패턴 or 데이터 간 유사도를 기계 학습 | 군집화 |    \n",
    "| 강화 학습 | . | 시행착오를 반복해 정답을 찾는 과정 | 알파고 |      \n",
    "\n",
    "\n",
    "** 비지도학습  \n",
    "= 정답이 없는 데이터를 활용해 그 속의 패턴이나 유사도를 기계가 학습하도록 하는 것  \n",
    "= 정답 없이 주어진 데이터로만 학습   \n",
    "= target / label 없이 feature만 있는 데이터  \n",
    "- 마케팅에서 고객 행동 예측 or 고객 세분화에서 활용됨   \n",
    "\n",
    "1. 군집화: 비슷한 데이터를 묶어 큰 단위로 묶기 -> 알고리즘이 식별할 클러스터 수 지정 or 수정 가능   \n",
    "2. 밀도 추정: 데이터 분포 예측   \n",
    "3. 차원 축소: 데이터 차원 축소   \n",
    "\n",
    "  \n",
    "▶ Feature와 Target / Label의 차이  \n",
    "- Feature: 머신러닝 모델 학습 시 사용되는 속성 => 각 피처 = 데이터의 특정 측면  \n",
    "- Label: 머신러닝 모델이 예측해야 하는 정답 혹은 결과값 = 종속 변수 = 목표 변수 (Target Var)   \n",
    "- 머신러닝 모델은 입력으로 feature [독립 변수]를 받아 label [종속 변수]을 예측하는 함수 학습. 이 과정에서 둘 사이의 관계 파악 & 새로운 데이터 정확하게 예측   \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e7e64",
   "metadata": {},
   "source": [
    "### <span style='background-color: #FFF5B1'> **지도 학습**</span> <BR>\n",
    "\n",
    "- 입력 값과 결과 값을 주고 학습 -> 예측값과 정답이 최대한 같아지도록 학습  \n",
    "  \n",
    "(1) 전체 데이터를 훈련 데이터와 테스트 데이터로 분리  \n",
    "&nbsp; - 훈련 데이터: 모델 학습 및 훈련에 사용   \n",
    "&nbsp; - 테스트 데이터: 학습된 모델 검증을 위해 사용   \n",
    "&nbsp; => 데이터를 분리해 훈련 데이터로 학습시킨 모델이 새로운 데이터에 대한 예측을 얼마나 잘 수행하는지 평가하기 위함 [단순암기 방지]\n",
    "\n",
    "(2) 훈련 데이터로 머신러닝 모델 생성   \n",
    "(3) 테스트 데이터로 머신러닝 모델 성능 평가   \n",
    "(4) (2)-(3) 반복    \n",
    "(5) 최종 모델 생성   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527fecb",
   "metadata": {},
   "source": [
    "### <span style='background-color: #FFF5B1'> **회귀와 분류**</span> <BR>\n",
    "  \n",
    "#### 1. 회귀 = 주어진 데이터를 기반으로 정답을 잘 맞추는 함수    \n",
    "- 연속적인 숫자의 값 예측    \n",
    "- 종속 변수가 연속형인 경우   \n",
    "   \n",
    "#### 2. 분류 = 기존 데이터가 어떤 레이블인지 패턴을 알고리즘으로 인지한 후 새로운 데이터의 레이블 판별    \n",
    "- 입력된 데이터를 주어진 항목으로 나눔  \n",
    "- 종속 변수가 범주형인 경우   \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19f1ec2",
   "metadata": {},
   "source": [
    "## 회귀와 모델링 <BR>\n",
    "### <span style='background-color: #FFF5B1'> **회귀**</span> <BR>\n",
    "- 데이터에서 패턴을 찾아 미래 값 예측    \n",
    "<BR>\n",
    "\n",
    "### <span style='background-color: #FFF5B1'> **회귀의 종류**</span> <BR>\n",
    "1. <u>선형회귀</u>  \n",
    "2. 비선형회귀: 독립변수와 종속변수가 비선형 관계인 경우 활용\n",
    "3. 릿지회귀: 모델 설명에 기여하지 못하는 독립변수의 회귀계수를 0에 근접하도록 축소    \n",
    "4. 라쏘회귀: 설명에 기여하지 못하는 독립변수의 회귀계수를 0으로 만듦\n",
    "5. 다항회귀: 독립변수와 종속변수의 관계가 다항식으로 표현\n",
    "6. 기타\n",
    "   \n",
    "▶ 회귀계수 = 회귀 모형에서 독립변수가 변할 때, 종속변수가 평균적으로 얼마나 변하는지 나타내는 값    \n",
    "<BR>\n",
    "\n",
    "### <span style='background-color: #FFF5B1'> **<u>선형 회귀</u>**</span> <BR>\n",
    "- 데이터를 가장 잘 설명하는 회귀선을 찾는 과정\n",
    "    - 회귀선 = 현재 데이터를 요약하고, 미래 값을 예측하는 도구   \n",
    "\n",
    "#### 1. <u>단순 선형 회귀</u>: 데이터를 하나의 독립 변수로 표현 [직선 형태]   \n",
    "- 데이터를 가장 잘 설명하는 직선을 찾는 과정   \n",
    "- y=ax+b에서 a는 회귀계수, b는 y 절편   \n",
    "&nbsp; => 직선을 결정하는 적절한 a와 b를 찾는 과정 => 예측값을 조절하며 잔차를 줄여나가는 과정   \n",
    "\n",
    "&nbsp;  ▶ 잔차 = 실제값과 예측값의 차이   \n",
    "\n",
    "(1) 최소제곱법: 잔차 제곱의 합이 최소가 되는 지점으로 최적의 회귀선을 구하는 방식   \n",
    "&nbsp; => 회귀선과 실제 데이터 간 차이 최소화를 위함   \n",
    "\n",
    "(2) 경사하강법: 함수의 값이 낮아지는 방향으로 독립변수의 값을 변형시키며 함수가 최소값을 갖도록 하는 독립변수 탐색   \n",
    "- (1)과 마찬가지로 a, b를 잘 찾고자 하며 잔차 제곱을 최소화하고자 함 \n",
    "- (1)로 구한 함수가 복잡해 최소값을 구하기 어려운 경우에 사용   \n",
    "&nbsp;  ▶ 목적함수 = 최적화를 위한 오차 최소화가 목적인 함수 => 최적화 대상을 수학적으로 표현      \n",
    "&nbsp;  ▶ 손실함수 = 개별 데이터 샘플에 대해 모델의 오차를 측정하는 함수 => 예측값과 실제값의 차이 계산   \n",
    "&nbsp;  ▶ 비용함수 = 전체 데이터셋의 평균적 손실을 측정하는 함수 => 머신러닝 모델 훈련 시 대부분 비용함수 최적화가 목표       \n",
    "\n",
    "&nbsp; [1] 손실함수    \n",
    "        - 손실 함수 위의 현재값이 최솟값보다 작다면, 기울기가 음수이기 때문에 오른쪽으로 점이 이동   \n",
    "        - 손실 함수 위의 현재값이 최솟값보다 크다면, 기울기가 음수이기 때문에 왼쪽으로 점이 이동   \n",
    "        - 현재값이 최솟값에 도달하면 미분값이 0이 되어, 더 이상 변화하지 않고 멈춤    \n",
    "\n",
    "&nbsp; [2] 학습률    \n",
    "        - 이동하는 크기, 보폭   \n",
    "        - 학습률이 너무 작으면 모델 수렴까지 너무 오래 걸리고, 크다면 수렴하지 못하고 발산하게 됨    \n",
    "        - 학습률 설정은 작은 값부터 시도한 후 그 이후 학습의 속도에 따라 조정하는 것이 좋은    \n",
    "\n",
    "&nbsp; [3] Local Minima 문제    \n",
    "        - 비용 함수가 여러 최솟값을 가질 때는 Local Minima와 Global Minima가 존재하기 때문에 Local Minima에서 빠져나오기 어려움    \n",
    "\n",
    "&nbsp; [4] 모멘텀 = Local Minima 해결     \n",
    "        - 경사하강법을 보완하여 이전의 기울기와 이동 방향을 고려하도록 관성 부여   \n",
    "        - 기울기에 관성을 부여해 작은 기울기는 쉽게 넘어갈 수 있도록 해, Local Minima 탈출 가능   \n",
    "\n",
    "#### 2. <u>다중 선형 회귀</u>: 데이터를 두 개 이상의 독립 변수로 표현    \n",
    "(1) 최소제곱법    \n",
    "   \n",
    "(2) 다중공선성   \n",
    "- 변수가 겹치는 상황, 즉 독립 변수들 간 상관관계가 큰 경우 발생  \n",
    "&nbsp; => 다중공선성이 높은 경우, 종속 변수에 영향을 미치는 독립 변수와 그 정도를 정확하게 구분하기 어려워 회귀 분석의 정확도가 낮아짐     \n",
    "<BR>  \n",
    "\n",
    "&nbsp; [1] 상관계수 (r) \n",
    "        = 변수 간 상관관계의 정도를 수치로 나타낸 것   \n",
    "        - -1 < r < 1  \n",
    "        - -1과 1에 가까울수록 변수 간 상관관계가 높음    \n",
    "        - 히트맵 / corr()로 확인    \n",
    "\n",
    "&nbsp; [2] VIF 지수 [분산 팽창 인수]  \n",
    "        - 회귀 모델의 결정계수를 사용해 계산    \n",
    "        - VIF가 높으면 다중공선성 존재  \n",
    "\n",
    "- 다중공선성 대처   \n",
    "[1] 변수 제거: 독립변수로 사용할 변수 선택    \n",
    "[2] 변수 변환: 변수를 더하거나 빼서 새로운 변수 생성   \n",
    "[3] 규제 선형 모델 활용     \n",
    "[4] PCA [주성분 분석]: 데이터의 차원 축소  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f212a4",
   "metadata": {},
   "source": [
    "### <span style='background-color: #FFF5B1'> **규제 선형 모델**</span> <BR>\n",
    "- 머신러닝 모델이 학습 데이터에 과적합 [학습 데이터에는 완벽히 맞으나, 새로운 데이터에서 성능이 떨어짐] 되지 않도록 규제를 하고자 하는 모델   \n",
    "&nbsp; => 선형 회귀 모델에서는 회귀 계수(W)의 크기를 조정하는 것, 즉 특정 독립 변수에 과하게 의존하지 않도록 조정하는 것      \n",
    "\n",
    "#### 1. 릿지 (L2 규제): W^2에 페널티 부여   \n",
    "- W^2을 페널티로 주기 때문에, 회귀 계수가 클수록 훨씬 강한 페널티를 받음   \n",
    "- 모든 계수가 작아지지만 0이 되지는 않음  \n",
    "&nbsp; => 변수 제거 X   \n",
    "&nbsp; => 모든 변수를 유지하되, 크기를 줄여 과적합 방지    \n",
    "- 예측 변수가 많거나 다중공선성 존재할 때 활용   \n",
    "\n",
    "#### 2. 라쏘 (L1 규제): |W|에 페널티 부여   \n",
    "- |W|을 페널티로 주기 때문에, 회귀 계수의 크기와 상관 없이 모두 같은 페널티를 받음   \n",
    "- 계수가 작았다면 0이 되기도 함    \n",
    "&nbsp; => 비중이 낮았던 변수, 즉 작은 계수는 사라지고 중요한 변수만 선택 가능    \n",
    "- 예측 변수가 많고 그 중 일부만 중요할 때, 간단하게 모델을 해석하고자 할 때    \n",
    "\n",
    "##### 3. 엘라스틱넷 (L1+L2 규제)    \n",
    "- 불필요한 변수는 제거하고, 남은 변수들은 0으로 만들지 않으며 적절한 크기로 유지하는 모델    \n",
    "&nbsp; => 안정적 예측과 변수 제거를 동시에 달성 가능   \n",
    "- 예측 변수 수가 많고, 그 중 중요한 변수를 선택하면서도 다중공선성을 관리하고자 할 때    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf915f5",
   "metadata": {},
   "source": [
    "### <span style='background-color: #FFF5B1'> **<u>모델 평가 방법</u>**</span> <BR>\n",
    "\n",
    "#### 1. 성능 평가 지표       \n",
    "(1) 평균 제곱 오차 [MSE, Mean Square Error]: (오차)^2 의 평균   \n",
    "- 큰 오차에 민감하게 반응 => 이상치에 민감    \n",
    "\n",
    "(2) 평균 절대 오차 [MAE, Mean Absolute Error]: |오차| 의 평균   \n",
    "- 모든 오차를 동일하게 취급 => 이상치가 존재해도 예측 성능 유지 가능     \n",
    "\n",
    "#### 2. 변수 유의성 평가         \n",
    "(1) t 검정: 독립 변수의 회귀 계수가 유의미한지 검정하는 데 사용     \n",
    "&nbsp; [1] 귀무가설 = 회귀계수가 0이다 | 대립가설 = 회귀계수가 0이 아니다   \n",
    "&nbsp; [2] t 값 계산   \n",
    "&nbsp; [3] p-value 확인 및 판단    \n",
    "&nbsp; [4] t값, p-value로 해석   \n",
    "&nbsp; => t값이 크면 귀무가설 기각 가능성이 높고, p-value가 작을수록 종속 변수에 더 큰 영향을 줄 확률이 높음 \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
