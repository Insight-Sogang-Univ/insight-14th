{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e5494a",
   "metadata": {},
   "source": [
    "# 회귀 심화 사전 과제 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01608b",
   "metadata": {},
   "source": [
    "## 복습<br>\n",
    "#### <span style='background-color: #fff5b1'>1. 회귀 개념</span>\n",
    "- 연속적 데이터에서 패턴을 찾아내는 통계적 방법 => 데이터 분석 도구   \n",
    "**<br>종류**<br>\n",
    "- 선형회귀, 비선형 회귀, 릿지 회귀, 라쏘 회귀, 다항 회귀   \n",
    "**<br>활용**<br>\n",
    "- 데이터 요약, 예측, 시계열 모델링, 변수 간 인과관계 발견   \n",
    "**<br>평가 지표**<br>\n",
    "- MSE: (오차)^2의 평균 => 이상치에 민감    \n",
    "- MAEL |오차| 의 평균 => 모든 오차를 동일하게    \n",
    "- R-square: 독립변수가 종속변수를 얼마만큼 설명해 주는지    \n",
    "- Adjusted R-square\n",
    "- AIC\n",
    "- BC (SC) <br>\n",
    "\n",
    "#### <span style='background-color: #fff5b1'>2. 단순/다중선형회귀분석</span>\n",
    "- 본질적으로 같지만, 독립변수의 개수가 다름   \n",
    "**<br>단순선형회귀분석**: 독립변수가 1개<br>\n",
    "**<br>다중선형회귀분석**: 독립변수가 2개 이상<br>\n",
    "\n",
    "#### <span style='background-color: #fff5b1'>3. 최소제곱법=최소자승법=OLS</span>\n",
    "- (잔차)^2의 합을 최소화하는 회귀선을 찾는 방법 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3d269",
   "metadata": {},
   "source": [
    "## 선형회귀<br>\n",
    "#### <u><span style='background-color: #fff5b1'>0. 회귀분석프로세스/span></u>\n",
    "**[사전 검증]**   \n",
    "EDA, 전처리 | 회귀 분석의 기본 가정 6가지 검토<br>\n",
    "**[모델 생성 및 모델 fit]**  \n",
    "회귀 모델 생성, 설정, 학습 | 유의성 검정 (f-검정, t-검정)<br>\n",
    "**[모델 성능 평가]**   \n",
    "R-squared | 회귀 분석 후 검증 가능한 가설 검토<br>\n",
    "**[모델 성능 개선]**   \n",
    "필요 없는 변수 제거 | 비선형 모델 활용 <br>\n",
    "\n",
    "#### <span style='background-color: #fff5b1'>1. 다중선형회귀의 수식적 이해</span>\n",
    "- 관심 있는 종속변수에 영향을 줄 것 같은 여러 설명변수를 채택해 선형적으로 식 작성    \n",
    "- 선형회귀식 = 종속변수에 대한 설명변수의 가중평균    \n",
    "\n",
    "#### <u><span style='background-color: #fff5b1'>2. 다중선형회귀의 기본 가정</span></u>\n",
    "- 선형 회귀를 사용하기 위한 가정이 필요함   <br>\n",
    "\n",
    "**[✅선형성]**   \n",
    "종속변수와 설명변수 간 관계의 선형성: scattor plot으로 검증 가능<br>\n",
    "**[✅독립성]**   \n",
    "각 설명 변수가 서로 선형독립적: 상관계수 / VIF로 확인한 결과 다중공선성이 있다면 변수 제거, 규제 선형 모델, PCA 등으로 대처<br>\n",
    "**[오차항의 평균 = 0]**   \n",
    "실제 값과 예측값 사이의 차이인 오차항의 평균이 0: np.mean(residuals)로 검증 가능<br>\n",
    "**[등분산성]**   \n",
    "오차항의 분산이 일정: 잔차의 도표화 / 검정으로 확인한 결과 오차항의 분산이 일정하지 않은 이분산성이 있는 경우, 일부 구간에서는 오차가 매우 커지는 등 회귀 분석의 결과가 정확하지 않을 수 있음 <br>\n",
    "**[✅오차항은 자기상관X]**   \n",
    "두 변수 간 상관된 정보를 나타내는 지표인 공분산이 항상 0: 공분산이 0이 아닌 경우, 즉 한 변수의 현재 값이 과거 값과 상관관계를 가지는 자기분산이 있는 경우, 이전 데이터의 패턴을 학습해 반복적 오류를 만들 가능성이 높음. Durbin-Watson으로 검증 가능.<br>\n",
    "**[정규성]**   \n",
    "오차항이 정규 분포를 따름: 회귀계수의 신뢰 구간과 p값 계산에 사용되는 공식은 오차항~N 이라는 가정 하에 만들어져, 정규 분포를 따르지 않는다면 결과 해석의 신뢰성이 떨어질 수 있음. Shapiro-Wilk 검증, Q-Q plot으로 검증 가능.<br>\n",
    "   \n",
    "** ✅ : 회귀 분석 전에 검증 가능한 가정<br>\n",
    "\n",
    "#### <u><span style='background-color: #fff5b1'>3. 회귀분석 평가방법</span></u> <br>\n",
    "- 회귀분석 결과가 얼마나 유효한지 평가하기 위해, 회귀선을 데이터와 시각화하거나 통계지표 이용<br>    \n",
    "\n",
    "**[시각화]**   \n",
    "- 회귀선은 데이터 전반을 잘 요약하지만, 여러 회귀선 중 어느 선이 더 데이터를 잘 요약하는지 객관적인 비교는 어려움<br>\n",
    "\n",
    "**[통계지표]**   \n",
    "- R-square과 그를 보완한 지표<br>\n",
    "\n",
    "**[모델의 유의성 검정]**    \n",
    "\n",
    "검정 종류 | 검정 대상 | 목적 | 해석 기준     \n",
    "-------- | -------- | -------- | --------    \n",
    "F-검정 | 전체 모델 | 회귀 모델의 유의미성 | p<0.05면 유의미     \n",
    "T-검정 | 개별 변수 | 특정 독립 변수의 유의미성 | p<0.05면 유의미   \n",
    "\n",
    "- Prob (F-statistic)  \n",
    "    - 회귀 모델이 유의미한가 = 종속 변수와 전체 독립 변수 간 관계가 통계적으로 유의미한지   \n",
    "    - F-statistic의 값이 클수록 모델이 통계적으로 유의미    \n",
    "\n",
    "- T-statistic     \n",
    "    - 독립 변수가 종속 변수에 유의미한 영향을 끼치는가    \n",
    "    - p-값 > |t| 를 판단해 가설 겁정 수행   \n",
    "\n",
    "**[모델의 성능 평가]**   \n",
    "\n",
    "- R-square (결정계수): 회귀 분석에서 모델이 설명하는 데이터의 총 변동 중에서 설명된 비율   \n",
    "    - R^2 = SSR/SST = 1 - (SSE/SST)    \n",
    "    - SSR = 회귀선에 의해 설명되는 편차 | SST = 총 편차 | SSE = 회귀선에 의해 설명되지 않는 편차\n",
    "    - 데이터의 평균을 예측값으로 사용할 때에 비해, 모델을 사용할 때 얼마나 더 정확히 예측하는지 = 모델이 데이터를 얼마나 잘 설명하는지 측정     \n",
    "    - 0과 1 사이의 값    \n",
    "    - 1에 가까울수록 모델이 데이터를 잘 설명     \n",
    "    - 0이면, 모델이 데이터를 전혀 설명하지 못함 (SSE=SST이므로)   \n",
    "\n",
    "- Adjusted R-square: 결정계수가 변수의 개수 증가에 덜 민감하도록 조정한 지표    \n",
    "    - R^2는 독립 변수의 개수가 증가할수록 증가 => 데이터와 큰 관련성 없는 변수를 추가해도 값은 커지기 때문     \n",
    "\n",
    "- AIC, BIC: 정보 기준으로 불리며, 값이 낮을수록 좋다고 평가    \n",
    "    - AIC: BIC에 비해 복잡성에 대한 패널티 작음   \n",
    "    - BIC: AIC보다 엄격한 기준으로, 데이터 양에 따라 더 강한 패널티 부과    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfce3a",
   "metadata": {},
   "source": [
    "## <u>비선형회귀</u><br>\n",
    "- 회귀는 데이터 간의 패턴, 즉 함수 관계를 나타내는 만큼 데이터셋의 분포가 선형적이지 않은 경우에 사용\n",
    "\n",
    "#### <u><span style='background-color: #fff5b1'>1. 다항식 회귀모델</span></u> <br>\n",
    "- 기존 선형 모델에 거듭제곱 항을 추가해 데이터의 곡선적 특성 모델링   \n",
    "- 관계가 직선적이지 않고 곡선을 그리는 경우, 성장률이나 감소율 등 시간에 따라 변화하는 속도가 다른 경우    \n",
    "\n",
    "(+) 선형 모델에 비해 회귀선을 핏하게 그릴 수 있음    \n",
    "(-) 너무 많은 피처를 이용할 때의 과적합 가능성 => 릿지, 라쏘 규제 활용    \n",
    "\n",
    "#### <u><span style='background-color: #fff5b1'>2. 지수 회귀모델</span></u> <br>\n",
    "- 종속 변수가 지수적으로 변화하는 관계를 모델링하는 경우     \n",
    "- 종속 변수에 log 취한 후 선형 회귀 적용      \n",
    "    - Y 값 예측 시, 모델이 예측한 Y 값에 지수함수를 적용해 로그 변환 전의 Y로 변형    \n",
    "- 값이 시간에 따라 지수적으로 증가하거나 감소하는 경우 ex. 기술 발전, 투자 수익률 증가 등     \n",
    "\n",
    "#### <u><span style='background-color: #fff5b1'>3. 로그 회귀모델</span></u> <br>\n",
    "- 종속 변수와 독립 변수 간 관계가 로그 함수를 통해 더 잘 표현되는 경우     \n",
    "- 독립 변수에 log 적용한 후 선형 회귀 적용    \n",
    "    - Y 값 예측 시, 별도의 처리를 하지 않고 그대로 사용 가능    \n",
    "- 데이터가 초기에 빠르게 증가하다가 점점 증가율이 감소하는 경우 ex. 인구 성장, 감염병 확산 등    \n",
    "\n",
    "#### <u><span style='background-color: #fff5b1'>4. 스플라인 회귀모델</span></u> <br>\n",
    "- 데이터를 구간별로 나누고 각 구간에서 다른 선형 / 비선형 함수를 적용하여 예측하는 방식    \n",
    "- 전체 데이터 범위를 구간으로 나누고, 각 구간에 대해 별도의 회귀 모델 적용     \n",
    "    - 구간 경계에서의 연속성 유지가 중요함     \n",
    "- 데이터 패턴이 여러 구간에서 다르게 나타나는 경우 ex. 계절에 따라 판매량이 변하는 소매 데이터 등    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
